---
title: "clusterů aaaKernels pro poznámkový blok Jupyter na Spark v Azure HDInsight | Microsoft Docs"
description: "Další informace o hello jádra PySpark, PySpark3 a Spark pro poznámkový blok Jupyter s clustery Spark v Azure HDInsight k dispozici."
keywords: "Poznámkový blok jupyter na spark, jupyter spark"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="dbce2-104">Jádra pro poznámkový blok Jupyter na clustery Spark v Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="dbce2-105">Clustery HDInsight Spark poskytují jádra, která můžete pomocí poznámkového bloku Jupyter hello na Spark pro testování vašich aplikací.</span><span class="sxs-lookup"><span data-stu-id="dbce2-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="dbce2-106">Jádro je program, který spouští a interpretuje vašeho kódu.</span><span class="sxs-lookup"><span data-stu-id="dbce2-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="dbce2-107">jsou tři jádra Hello:</span><span class="sxs-lookup"><span data-stu-id="dbce2-107">hello three kernels are:</span></span>

- <span data-ttu-id="dbce2-108">**PySpark** – pro aplikace napsané v Python2</span><span class="sxs-lookup"><span data-stu-id="dbce2-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="dbce2-109">**PySpark3** – pro aplikace napsané v Python3</span><span class="sxs-lookup"><span data-stu-id="dbce2-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="dbce2-110">**Spark** – pro aplikace napsané v jazyce Scala</span><span class="sxs-lookup"><span data-stu-id="dbce2-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="dbce2-111">V tomto článku se dozvíte, jak toouse tyto jádra a výhod hello jejich používání.</span><span class="sxs-lookup"><span data-stu-id="dbce2-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="dbce2-112">Požadavky</span><span class="sxs-lookup"><span data-stu-id="dbce2-112">Prerequisites</span></span>

* <span data-ttu-id="dbce2-113">Cluster Apache Spark v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="dbce2-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="dbce2-114">Pokyny najdete v tématu [clusterů vytvořit Apache Spark v Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="dbce2-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="dbce2-115">Vytvoření poznámkového bloku Jupyter v Spark HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="dbce2-116">Z hello [portál Azure](https://portal.azure.com/), otevřete váš cluster.</span><span class="sxs-lookup"><span data-stu-id="dbce2-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="dbce2-117">V tématu [seznamu a zobrazit clustery](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) pokyny hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="dbce2-118">Hello clusteru se otevře v novém okně portálu.</span><span class="sxs-lookup"><span data-stu-id="dbce2-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="dbce2-119">Z hello **rychlé odkazy** klikněte na tlačítko **clusteru řídicí panely** tooopen hello **clusteru řídicí panely** okno.</span><span class="sxs-lookup"><span data-stu-id="dbce2-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="dbce2-120">Pokud nevidíte **rychlé odkazy**, klikněte na tlačítko **přehled** hello levé nabídce v okně hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="dbce2-121">![Poznámkový blok Jupyter na Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Poznámkový blok Jupyter na Spark")</span><span class="sxs-lookup"><span data-stu-id="dbce2-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="dbce2-122">Klikněte na tlačítko **Poznámkový blok Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="dbce2-123">Pokud se zobrazí výzva, zadejte přihlašovací údaje správce hello hello clusteru.</span><span class="sxs-lookup"><span data-stu-id="dbce2-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="dbce2-124">Může také dosáhnout hello Poznámkový blok Jupyter v clusteru Spark pomocí hello otevření následující adresy URL v prohlížeči.</span><span class="sxs-lookup"><span data-stu-id="dbce2-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="dbce2-125">Nahraďte **CLUSTERNAME** s hello název clusteru:</span><span class="sxs-lookup"><span data-stu-id="dbce2-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="dbce2-126">Klikněte na tlačítko **nový**a pak klikněte buď **Pyspark**, **PySpark3**, nebo **Spark** toocreate Poznámkový blok.</span><span class="sxs-lookup"><span data-stu-id="dbce2-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="dbce2-127">Používat hello jádra Spark Scala aplikací jádra PySpark pro Python2 aplikace a PySpark3 jádra pro Python3 aplikace.</span><span class="sxs-lookup"><span data-stu-id="dbce2-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="dbce2-128">![Jádra pro poznámkový blok Jupyter na Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "jádra pro poznámkový blok Jupyter na Spark")</span><span class="sxs-lookup"><span data-stu-id="dbce2-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="dbce2-129">Poznámkový blok se otevře s hello jádra, který jste vybrali.</span><span class="sxs-lookup"><span data-stu-id="dbce2-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="dbce2-130">Výhody používání jádra hello</span><span class="sxs-lookup"><span data-stu-id="dbce2-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="dbce2-131">Zde naleznete několik výhod nového jádra hello pomocí poznámkového bloku Jupyter na clustery Spark HDInsight.</span><span class="sxs-lookup"><span data-stu-id="dbce2-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="dbce2-132">**Předvolby kontexty**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-132">**Preset contexts**.</span></span> <span data-ttu-id="dbce2-133">S **PySpark**, **PySpark3**, nebo hello **Spark** jádra, není nutné tooset kontexty Spark nebo Hive hello explicitně před zahájením práce s vašimi aplikacemi.</span><span class="sxs-lookup"><span data-stu-id="dbce2-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="dbce2-134">Toto jsou k dispozici ve výchozím nastavení.</span><span class="sxs-lookup"><span data-stu-id="dbce2-134">These are available by default.</span></span> <span data-ttu-id="dbce2-135">Tyto kontexty jsou:</span><span class="sxs-lookup"><span data-stu-id="dbce2-135">These contexts are:</span></span>
   
   * <span data-ttu-id="dbce2-136">**sc** – pro kontext Spark</span><span class="sxs-lookup"><span data-stu-id="dbce2-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="dbce2-137">**sqlContext** – pro kontext Hive</span><span class="sxs-lookup"><span data-stu-id="dbce2-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="dbce2-138">Ano nemáte toorun příkazy, jako je třeba hello tooset hello kontexty následující:</span><span class="sxs-lookup"><span data-stu-id="dbce2-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="dbce2-139">sc = SparkContext('yarn-client') sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="dbce2-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="dbce2-140">Místo toho můžete přímo použít hello přednastavení kontexty ve vaší aplikaci.</span><span class="sxs-lookup"><span data-stu-id="dbce2-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="dbce2-141">**Buňky Magic**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-141">**Cell magics**.</span></span> <span data-ttu-id="dbce2-142">Hello jádra PySpark poskytuje některé předdefinované "Magic", které jsou speciální příkazy, které můžete volat s `%%` (například `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="dbce2-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="dbce2-143">příkaz magic Hello musí být první slovo hello v buňce kódu a povolit pro více řádků obsahu.</span><span class="sxs-lookup"><span data-stu-id="dbce2-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="dbce2-144">Hello magic word by měl být hello první slovo v buňce hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="dbce2-145">Přidání nic před hello magic, i komentáře, výsledkem bude chyba.</span><span class="sxs-lookup"><span data-stu-id="dbce2-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="dbce2-146">Další informace o Magic, které najdete v tématu [zde](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="dbce2-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="dbce2-147">Hello následující tabulka uvádí hello různých Magic, které jsou k dispozici prostřednictvím hello jádra.</span><span class="sxs-lookup"><span data-stu-id="dbce2-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="dbce2-148">Magic</span><span class="sxs-lookup"><span data-stu-id="dbce2-148">Magic</span></span> | <span data-ttu-id="dbce2-149">Příklad</span><span class="sxs-lookup"><span data-stu-id="dbce2-149">Example</span></span> | <span data-ttu-id="dbce2-150">Popis</span><span class="sxs-lookup"><span data-stu-id="dbce2-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="dbce2-151">Pomoc</span><span class="sxs-lookup"><span data-stu-id="dbce2-151">help</span></span> |`%%help` |<span data-ttu-id="dbce2-152">Vytvoří tabulku všechny dostupné Magic hello s příklad a popis</span><span class="sxs-lookup"><span data-stu-id="dbce2-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="dbce2-153">Informace o</span><span class="sxs-lookup"><span data-stu-id="dbce2-153">info</span></span> |`%%info` |<span data-ttu-id="dbce2-154">Informace o relaci výstupy pro hello aktuální koncový bod Livy</span><span class="sxs-lookup"><span data-stu-id="dbce2-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="dbce2-155">Konfigurace</span><span class="sxs-lookup"><span data-stu-id="dbce2-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="dbce2-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="dbce2-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="dbce2-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="dbce2-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="dbce2-158">Nakonfiguruje hello parametry pro vytvoření relace.</span><span class="sxs-lookup"><span data-stu-id="dbce2-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="dbce2-159">Hello příznak force (-f) je povinná, pokud relaci již byla vytvořena, což zajistí, že hello relace je vyřadit a vytvořit znovu.</span><span class="sxs-lookup"><span data-stu-id="dbce2-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="dbce2-160">Podívejte se na [/sessions POST na Livy text žádosti](https://github.com/cloudera/livy#request-body) pro seznam platných parametrů.</span><span class="sxs-lookup"><span data-stu-id="dbce2-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="dbce2-161">Parametry musí být předán jako řetězec formátu JSON a musí být na další řádek hello po hello magic, jak je znázorněno v příkladu sloupec hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="dbce2-162">SQL</span><span class="sxs-lookup"><span data-stu-id="dbce2-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="dbce2-163">Provede dotaz Hive proti hello sqlContext.</span><span class="sxs-lookup"><span data-stu-id="dbce2-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="dbce2-164">Pokud hello `-o` parametr se předává, hello výsledek dotazu hello je uchován v hello %% lokální kontext Python jako [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="dbce2-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="dbce2-165">místní</span><span class="sxs-lookup"><span data-stu-id="dbce2-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="dbce2-166">Všechny hello kód v další řádek se spustí místně.</span><span class="sxs-lookup"><span data-stu-id="dbce2-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="dbce2-167">Kód musí být platný kód Python2 i bez ohledu na hello jádra, který používáte.</span><span class="sxs-lookup"><span data-stu-id="dbce2-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="dbce2-168">Ano, i v případě, že jste vybrali **PySpark3** nebo **Spark** jádra při vytváření hello Poznámkový blok, pokud používáte hello `%%local` magic v buňce, dané buňky musí mít pouze platný kód Python2...</span><span class="sxs-lookup"><span data-stu-id="dbce2-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="dbce2-169">Protokoly</span><span class="sxs-lookup"><span data-stu-id="dbce2-169">logs</span></span> |`%%logs` |<span data-ttu-id="dbce2-170">Výstupy hello protokoly pro aktuální relaci Livy hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="dbce2-171">Odstranit</span><span class="sxs-lookup"><span data-stu-id="dbce2-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="dbce2-172">Odstraní konkrétní relace hello aktuální Livy koncového bodu.</span><span class="sxs-lookup"><span data-stu-id="dbce2-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="dbce2-173">Všimněte si, že nelze odstranit hello relace iniciovaného pro hello jádra sám sebe.</span><span class="sxs-lookup"><span data-stu-id="dbce2-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="dbce2-174">Čištění</span><span class="sxs-lookup"><span data-stu-id="dbce2-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="dbce2-175">Odstraní všechny hello relace pro hello aktuální Livy koncový bod, včetně relace tento poznámkový blok.</span><span class="sxs-lookup"><span data-stu-id="dbce2-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="dbce2-176">platnost Hello příznak -f je povinný.</span><span class="sxs-lookup"><span data-stu-id="dbce2-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="dbce2-177">Kromě toho toohello Magic, které jsou přidávány hello jádra PySpark, můžete použít také hello [předdefinované Magic IPython](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), včetně `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="dbce2-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="dbce2-178">Můžete použít hello `%%sh` kouzelná toorun skripty a blok kódu na headnode hello clusteru.</span><span class="sxs-lookup"><span data-stu-id="dbce2-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="dbce2-179">**Automaticky vizualizace**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-179">**Auto visualization**.</span></span> <span data-ttu-id="dbce2-180">Hello **Pyspark** jádra automaticky vizualizuje výstup hello dotazů Hive a SQL.</span><span class="sxs-lookup"><span data-stu-id="dbce2-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="dbce2-181">Můžete zvolit několika různých typů vizualizace včetně tabulky, kruhový, řádku, oblasti, panelu.</span><span class="sxs-lookup"><span data-stu-id="dbce2-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="dbce2-182">Parametry podporovány s hello %% sql magic</span><span class="sxs-lookup"><span data-stu-id="dbce2-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="dbce2-183">Hello `%%sql` magic podporuje různé parametry, které můžete použít toocontrol hello druh výstup, která se zobrazí při spuštění dotazů.</span><span class="sxs-lookup"><span data-stu-id="dbce2-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="dbce2-184">Hello následující tabulka uvádí výstup hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="dbce2-185">Parametr</span><span class="sxs-lookup"><span data-stu-id="dbce2-185">Parameter</span></span> | <span data-ttu-id="dbce2-186">Příklad</span><span class="sxs-lookup"><span data-stu-id="dbce2-186">Example</span></span> | <span data-ttu-id="dbce2-187">Popis</span><span class="sxs-lookup"><span data-stu-id="dbce2-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="dbce2-188">-o</span><span class="sxs-lookup"><span data-stu-id="dbce2-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="dbce2-189">Použijte tento parametr toopersist hello výsledek dotazu hello v hello %% lokální kontext Python, jako [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="dbce2-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="dbce2-190">Hello název proměnné dataframe hello je hello název proměnné, které určíte.</span><span class="sxs-lookup"><span data-stu-id="dbce2-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="dbce2-191">-q</span><span class="sxs-lookup"><span data-stu-id="dbce2-191">-q</span></span> |`-q` |<span data-ttu-id="dbce2-192">Pomocí této tooturn vypnout vizualizace pro hello buňky.</span><span class="sxs-lookup"><span data-stu-id="dbce2-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="dbce2-193">Pokud nechcete, aby tooauto-vizualizovat hello obsah buňky a právě chcete toocapture jej jako dataframe, potom použijte `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="dbce2-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="dbce2-194">Pokud chcete tooturn vypnout vizualizace bez zaznamenávání hello výsledky (například pro spuštění příkazu jazyka SQL, jako je třeba `CREATE TABLE` příkaz), použijte `-q` bez zadání `-o` argument.</span><span class="sxs-lookup"><span data-stu-id="dbce2-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="dbce2-195">-m</span><span class="sxs-lookup"><span data-stu-id="dbce2-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="dbce2-196">Kde **metoda** je buď **trvat** nebo **ukázka** (výchozí hodnota je **trvat**).</span><span class="sxs-lookup"><span data-stu-id="dbce2-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="dbce2-197">Pokud je metoda hello **trvat**, hello jádra vybere elementy shora hello hello výsledek datových sad určeného MAXROWS (popsané dál v této tabulce).</span><span class="sxs-lookup"><span data-stu-id="dbce2-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="dbce2-198">Pokud je metoda hello **ukázka**, hello jádra náhodně ukázky elementy hello datových sad podle příliš`-r` parametr popsána dále v této tabulce.</span><span class="sxs-lookup"><span data-stu-id="dbce2-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="dbce2-199">-r</span><span class="sxs-lookup"><span data-stu-id="dbce2-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="dbce2-200">Zde **ZLOMEK** je číslo s plovoucí desetinnou čárkou mezi 0,0 a 1,0.</span><span class="sxs-lookup"><span data-stu-id="dbce2-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="dbce2-201">Pokud je metoda hello ukázky pro dotaz SQL hello `sample`, pak hello jádra náhodně ukázky hello zadaný podíl hello elementy hello výsledku nastavení za vás.</span><span class="sxs-lookup"><span data-stu-id="dbce2-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="dbce2-202">Například pokud spustíte dotaz SQL s argumenty hello `-m sample -r 0.01`, pak se náhodně vzorkovat 1 % hello výsledek řádků.</span><span class="sxs-lookup"><span data-stu-id="dbce2-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="dbce2-203">**MAXROWS** celočíselná hodnota.</span><span class="sxs-lookup"><span data-stu-id="dbce2-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="dbce2-204">Hello jádra omezuje hello počet řádků, výstup příliš**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="dbce2-205">Pokud **MAXROWS** záporné číslo, jako je **-1**, pak hello počet řádků v sadě výsledků hello není omezen.</span><span class="sxs-lookup"><span data-stu-id="dbce2-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="dbce2-206">**Příklad:**</span><span class="sxs-lookup"><span data-stu-id="dbce2-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="dbce2-207">příkaz Hello výše hello následující:</span><span class="sxs-lookup"><span data-stu-id="dbce2-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="dbce2-208">Vybere všechny záznamy z **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="dbce2-209">Vzhledem k tomu, že používáme - q, vypne automatické vizualizace.</span><span class="sxs-lookup"><span data-stu-id="dbce2-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="dbce2-210">Vzhledem k tomu, že používáme `-m sample -r 0.1 -n 500` ho náhodně ukázky 10 % hello řádků v hello hivesampletable a omezení hello velikost hello výsledek sadu too500 řádků.</span><span class="sxs-lookup"><span data-stu-id="dbce2-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="dbce2-211">Nakonec protože jsme použili `-o query2` navíc šetří hello výstup do dataframe, nazývá **dotaz2**.</span><span class="sxs-lookup"><span data-stu-id="dbce2-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="dbce2-212">Aspekty při použití nové jádra hello</span><span class="sxs-lookup"><span data-stu-id="dbce2-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="dbce2-213">Podle toho, která jádra, které používáte, ponechat poznámkových bloků hello systémem spotřebovává prostředky clusteru hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="dbce2-214">S tyto jádra protože jsou přednastavení kontexty hello, jednoduše ukončení poznámkových bloků hello není hello kontextu ukončit a proto hello prostředky clusteru pokračovat toobe používá.</span><span class="sxs-lookup"><span data-stu-id="dbce2-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="dbce2-215">Doporučeným postupem je toouse hello **zavřít a zastavit** možnost hello poznámkového bloku **souboru** nabídky, když jste dokončili pomocí hello Poznámkový blok, který ukončí kontext hello a pak ukončí hello poznámkového bloku.</span><span class="sxs-lookup"><span data-stu-id="dbce2-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="dbce2-216">Ukázat některé příklady</span><span class="sxs-lookup"><span data-stu-id="dbce2-216">Show me some examples</span></span>

<span data-ttu-id="dbce2-217">Otevřete Poznámkový blok Jupyter, uvidíte dvě složky k dispozici na kořenové úrovni hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="dbce2-218">Hello **PySpark** složka obsahuje ukázkové poznámkových bloků této hello použití nové **Python** jádra.</span><span class="sxs-lookup"><span data-stu-id="dbce2-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="dbce2-219">Hello **Scala** složka obsahuje ukázkové poznámkových bloků této hello použití nové **Spark** jádra.</span><span class="sxs-lookup"><span data-stu-id="dbce2-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="dbce2-220">Můžete otevřít hello **00 - [přečtěte si NEJPRVE] funkce jádra Magic Spark** poznámkového bloku z hello **PySpark** nebo **Spark** složky toolearn o hello různých Magic, které jsou k dispozici.</span><span class="sxs-lookup"><span data-stu-id="dbce2-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="dbce2-221">Můžete také použít jak hello k dispozici v části toolearn složky hello dva další poznámkových bloků ukázka tooachieve různé scénáře použití poznámkové bloky Jupyter s clustery HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="dbce2-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="dbce2-222">Kde jsou uložené poznámkových bloků hello?</span><span class="sxs-lookup"><span data-stu-id="dbce2-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="dbce2-223">Poznámkové bloky Jupyter ukládají toohello účtu úložiště přidruženého k hello clusteru pod hello **/HdiNotebooks** složky.</span><span class="sxs-lookup"><span data-stu-id="dbce2-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="dbce2-224">Poznámkové bloky, textové soubory a složky, které vytvoříte z v rámci Jupyter jsou přístupné z účtu úložiště hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="dbce2-225">Například, pokud používáte Jupyter toocreate složku **Moje_složka** a Poznámkový blok **myfolder/mynotebook.ipynb**, dostanete tento poznámkový blok v `/HdiNotebooks/myfolder/mynotebook.ipynb` v rámci účtu úložiště hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="dbce2-226">Hello zpětné je také nastavena hodnota true, to znamená, pokud nahrát Poznámkový blok přímo tooyour úložiště účet v `/HdiNotebooks/mynotebook1.ipynb`, hello Poznámkový blok je také zobrazit z Jupyter.</span><span class="sxs-lookup"><span data-stu-id="dbce2-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="dbce2-227">Poznámkové bloky zůstat v účtu úložiště hello i po odstranění clusteru hello.</span><span class="sxs-lookup"><span data-stu-id="dbce2-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="dbce2-228">způsob Hello poznámkových bloků se uloží toohello účet úložiště je kompatibilní s HDFS.</span><span class="sxs-lookup"><span data-stu-id="dbce2-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="dbce2-229">Pokud tedy můžete SSH do clusteru hello, které můžete použít soubor příkazy pro správu, jak je znázorněno v následujícím fragmentu kódu hello:</span><span class="sxs-lookup"><span data-stu-id="dbce2-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="dbce2-230">V případě, že nedochází k potížím přístupu k účtu úložiště hello hello clusteru, poznámkových bloků hello jsou také uloženy na hello headnode `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="dbce2-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="dbce2-231">Podporovaný prohlížeč</span><span class="sxs-lookup"><span data-stu-id="dbce2-231">Supported browser</span></span>

<span data-ttu-id="dbce2-232">Poznámkové bloky Jupyter na clustery Spark HDInsight jsou podporovány pouze na Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="dbce2-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="dbce2-233">Váš názor</span><span class="sxs-lookup"><span data-stu-id="dbce2-233">Feedback</span></span>
<span data-ttu-id="dbce2-234">nové jádra Hello jsou v vyvíjející se fáze a bude pro dospělé v čase.</span><span class="sxs-lookup"><span data-stu-id="dbce2-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="dbce2-235">To může znamenat, že rozhraní API může změnit, protože tyto jádra pro dospělé.</span><span class="sxs-lookup"><span data-stu-id="dbce2-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="dbce2-236">Uvítáme jakékoli zpětnou vazbu, která máte při použití těchto nových jádra.</span><span class="sxs-lookup"><span data-stu-id="dbce2-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="dbce2-237">To je užitečné v shaping hello finální verzi nástroje tyto jádra.</span><span class="sxs-lookup"><span data-stu-id="dbce2-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="dbce2-238">Můžete ponechat vaše komentáře nebo názory pod hello **komentáře** oddíl hello dolní části tohoto článku.</span><span class="sxs-lookup"><span data-stu-id="dbce2-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="dbce2-239"><a name="seealso"></a>Viz také</span><span class="sxs-lookup"><span data-stu-id="dbce2-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="dbce2-240">Přehled: Apache Spark v Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="dbce2-241">Scénáře</span><span class="sxs-lookup"><span data-stu-id="dbce2-241">Scenarios</span></span>
* [<span data-ttu-id="dbce2-242">Spark s BI: Provádějte interaktivní analýzy dat pomocí Sparku v HDInsight pomocí nástrojů BI</span><span class="sxs-lookup"><span data-stu-id="dbce2-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="dbce2-243">Spark s Machine Learning: Používejte Spark v HDInsight pro analýzu teploty v budově pomocí dat HVAC</span><span class="sxs-lookup"><span data-stu-id="dbce2-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="dbce2-244">Spark s Machine Learning: používejte Spark v výsledků kontroly potravin toopredict HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="dbce2-245">Datové proudy Spark: Používejte Spark v HDInsight pro sestavení aplikací datových proudů v reálném čase</span><span class="sxs-lookup"><span data-stu-id="dbce2-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="dbce2-246">Analýza protokolu webu pomocí Sparku v HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="dbce2-247">Vytvoření a spouštění aplikací</span><span class="sxs-lookup"><span data-stu-id="dbce2-247">Create and run applications</span></span>
* [<span data-ttu-id="dbce2-248">Vytvoření samostatné aplikace pomocí Scala</span><span class="sxs-lookup"><span data-stu-id="dbce2-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="dbce2-249">Vzdálené spouštění úloh na clusteru Sparku pomocí Livy</span><span class="sxs-lookup"><span data-stu-id="dbce2-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="dbce2-250">Nástroje a rozšíření</span><span class="sxs-lookup"><span data-stu-id="dbce2-250">Tools and extensions</span></span>
* [<span data-ttu-id="dbce2-251">Pomocí modulu plug-in nástroje HDInsight pro IntelliJ IDEA toocreate a odesílání aplikací Spark Scala</span><span class="sxs-lookup"><span data-stu-id="dbce2-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="dbce2-252">Vzdáleně pomocí modulu plug-in nástroje HDInsight pro IntelliJ IDEA toodebug Spark aplikace</span><span class="sxs-lookup"><span data-stu-id="dbce2-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="dbce2-253">Použití poznámkových bloků Zeppelin s clusterem Sparku v HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="dbce2-254">Použití externích balíčků s poznámkovými bloky Jupyter</span><span class="sxs-lookup"><span data-stu-id="dbce2-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="dbce2-255">Do počítače nainstalovat Jupyter a připojte tooan clusteru HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="dbce2-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="dbce2-256">Správa prostředků</span><span class="sxs-lookup"><span data-stu-id="dbce2-256">Manage resources</span></span>
* [<span data-ttu-id="dbce2-257">Správa prostředků hello cluster Apache Spark v Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="dbce2-258">Sledování a ladění úloh spuštěných v clusteru Apache Spark v HDInsight</span><span class="sxs-lookup"><span data-stu-id="dbce2-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

---
title: "Výpočetní kontextu možnosti pro R Server v HDInsight - Azure | Microsoft Docs"
description: "Další informace o různých výpočetních kontextu možnosti dostupné uživatelům s R Server v HDInsight"
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 47f4441612be4f363ba82cc22b09786a6f3bfdc3
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 08/29/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="56e3e-103">Výpočetní kontextu možnosti pro R Server v HDInsight</span><span class="sxs-lookup"><span data-stu-id="56e3e-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="56e3e-104">Microsoft R serverem v Azure HDInsight řídí, jak jsou spouštěny nastavení kontext výpočetní volání.</span><span class="sxs-lookup"><span data-stu-id="56e3e-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="56e3e-105">Tento článek popisuje možnosti, které jsou k dispozici k určení, zda a jak je paralelizovaná provádění málo mezi jader hraniční uzel nebo clusteru HDInsight.</span><span class="sxs-lookup"><span data-stu-id="56e3e-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="56e3e-106">Hraničního uzlu clusteru poskytuje vhodné místo pro připojení ke clusteru a spustit skripty R.</span><span class="sxs-lookup"><span data-stu-id="56e3e-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="56e3e-107">S hraniční uzel máte možnost spuštění parallelized distribuované funkce ScaleR mezi jader hraničního uzlu serveru.</span><span class="sxs-lookup"><span data-stu-id="56e3e-107">With an edge node, you have the option of running the parallelized distributed functions of ScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="56e3e-108">Můžete také spustit je mezi uzly clusteru pomocí ScaleR na Hadoop mapy snížit nebo výpočetní kontexty Spark.</span><span class="sxs-lookup"><span data-stu-id="56e3e-108">You can also run them across the nodes of the cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="56e3e-109">Microsoft R serverem v Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="56e3e-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="56e3e-110">[Microsoft R serverem v Azure HDInsight](hdinsight-hadoop-r-server-overview.md) přináší nejnovější schopnosti pro R na základě analýzy.</span><span class="sxs-lookup"><span data-stu-id="56e3e-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="56e3e-111">Může používat data, která je uložená v kontejneru HDFS ve vaší [objektů Blob v Azure](../storage/common/storage-introduction.md "úložiště objektů Azure Blob") účet úložiště, Data Lake store nebo místního souboru systému Linux.</span><span class="sxs-lookup"><span data-stu-id="56e3e-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="56e3e-112">Vzhledem k tomu, že R Server je založený na R s otevřeným zdrojem, můžete použít na základě R aplikací, které vytvoříte, žádný z balíčků R s otevřeným zdrojem 8000 +.</span><span class="sxs-lookup"><span data-stu-id="56e3e-112">Since R Server is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="56e3e-113">Může také používat rutiny v [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), balíček analýzy velkých objemů dat společnosti Microsoft, který je součástí R Server.</span><span class="sxs-lookup"><span data-stu-id="56e3e-113">They can also use the routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="56e3e-114">Výpočetní kontexty pro hraniční uzel</span><span class="sxs-lookup"><span data-stu-id="56e3e-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="56e3e-115">Obecně platí R skript, který běží v R Server na uzlu edge běží v rámci překladač R v tomto uzlu.</span><span class="sxs-lookup"><span data-stu-id="56e3e-115">In general, an R script that's run in R Server on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="56e3e-116">Výjimky jsou tyto kroky, které volají funkce ScaleR.</span><span class="sxs-lookup"><span data-stu-id="56e3e-116">The exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="56e3e-117">Volání ScaleR spustit ve výpočetním prostředí, který je určen jak nastavit kontext výpočetní ScaleR.</span><span class="sxs-lookup"><span data-stu-id="56e3e-117">The ScaleR calls run in a compute environment that is determined by how you set the ScaleR compute context.</span></span>  <span data-ttu-id="56e3e-118">Když spustíte R skript z hraniční uzel, kontextu výpočetní hodnoty jsou:</span><span class="sxs-lookup"><span data-stu-id="56e3e-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="56e3e-119">místní sekvenční (*'local'*)</span><span class="sxs-lookup"><span data-stu-id="56e3e-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="56e3e-120">místní paralelní (*'localpar'*)</span><span class="sxs-lookup"><span data-stu-id="56e3e-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="56e3e-121">Snižte mapy</span><span class="sxs-lookup"><span data-stu-id="56e3e-121">Map Reduce</span></span>
- <span data-ttu-id="56e3e-122">Spark</span><span class="sxs-lookup"><span data-stu-id="56e3e-122">Spark</span></span>

<span data-ttu-id="56e3e-123">*'Local'* a *'localpar'* možnosti se liší pouze v tom **rxExec** provedení volání.</span><span class="sxs-lookup"><span data-stu-id="56e3e-123">The *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="56e3e-124">Obě provést jiná volání funkce rx paralelní způsobem mezi všechny dostupné jader není uvedeno jinak prostřednictvím použití ScaleR **numCoresToUse** volby, například `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="56e3e-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="56e3e-125">Paralelní provádění možnosti nabízejí optimální výkon.</span><span class="sxs-lookup"><span data-stu-id="56e3e-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="56e3e-126">Následující tabulka shrnuje různé možnosti kontextu výpočetní nastavit, jak jsou vykonány volání:</span><span class="sxs-lookup"><span data-stu-id="56e3e-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="56e3e-127">Výpočetní kontextu</span><span class="sxs-lookup"><span data-stu-id="56e3e-127">Compute context</span></span>  | <span data-ttu-id="56e3e-128">Postup nastavení</span><span class="sxs-lookup"><span data-stu-id="56e3e-128">How to set</span></span>                      | <span data-ttu-id="56e3e-129">Kontext spuštění</span><span class="sxs-lookup"><span data-stu-id="56e3e-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="56e3e-130">Místní sekvenčních</span><span class="sxs-lookup"><span data-stu-id="56e3e-130">Local sequential</span></span> | <span data-ttu-id="56e3e-131">rxSetComputeContext('local')</span><span class="sxs-lookup"><span data-stu-id="56e3e-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="56e3e-132">Provádění paralelizovaná málo napříč jádrech hraničního uzlu serveru, s výjimkou rxExec volání, které jsou prováděny sériově</span><span class="sxs-lookup"><span data-stu-id="56e3e-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="56e3e-133">Místní paralelní</span><span class="sxs-lookup"><span data-stu-id="56e3e-133">Local parallel</span></span>   | <span data-ttu-id="56e3e-134">rxSetComputeContext('localpar')</span><span class="sxs-lookup"><span data-stu-id="56e3e-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="56e3e-135">Provádění paralelizovaná málo napříč jádrech hraničního uzlu serveru</span><span class="sxs-lookup"><span data-stu-id="56e3e-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="56e3e-136">Spark</span><span class="sxs-lookup"><span data-stu-id="56e3e-136">Spark</span></span>            | <span data-ttu-id="56e3e-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="56e3e-137">RxSpark()</span></span>                       | <span data-ttu-id="56e3e-138">Paralelizovaná málo distribuované zpracování prostřednictvím Spark mezi uzly clusteru HDI</span><span class="sxs-lookup"><span data-stu-id="56e3e-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="56e3e-139">Snižte mapy</span><span class="sxs-lookup"><span data-stu-id="56e3e-139">Map Reduce</span></span>       | <span data-ttu-id="56e3e-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="56e3e-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="56e3e-141">Paralelizovaná málo distribuované zpracování prostřednictvím snížit mapy mezi uzly clusteru HDI</span><span class="sxs-lookup"><span data-stu-id="56e3e-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="56e3e-142">Pokyny pro rozhodování v kontextu výpočetní</span><span class="sxs-lookup"><span data-stu-id="56e3e-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="56e3e-143">Která z těchto tří možností zvolíte, které poskytují paralelizovaná málo provádění závisí na povaze práci analýzy, velikost a umístění vašich dat.</span><span class="sxs-lookup"><span data-stu-id="56e3e-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="56e3e-144">Neexistuje žádný jednoduchý vzorec, který zjistíte, které výpočetní kontext, který má použít.</span><span class="sxs-lookup"><span data-stu-id="56e3e-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="56e3e-145">Existují však některé základní zásady, které můžete vybrat správně, nebo aspoň, můžete zúžit vaše volby před spuštěním testu výkonnosti.</span><span class="sxs-lookup"><span data-stu-id="56e3e-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="56e3e-146">Tyto zásady patří:</span><span class="sxs-lookup"><span data-stu-id="56e3e-146">These guiding principles include:</span></span>

- <span data-ttu-id="56e3e-147">Místní systém souborů Linux je rychlejší než HDFS.</span><span class="sxs-lookup"><span data-stu-id="56e3e-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="56e3e-148">Pokud se místní data, a pokud se nachází v XDF se rychlejší opakované analýzy.</span><span class="sxs-lookup"><span data-stu-id="56e3e-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="56e3e-149">Je vhodnější k vysílání datového proudu malé množství dat ze zdroje dat text.</span><span class="sxs-lookup"><span data-stu-id="56e3e-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="56e3e-150">Pokud větší množství dat, se ji převeďte XDF před analýzou.</span><span class="sxs-lookup"><span data-stu-id="56e3e-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="56e3e-151">Nezvladatelné pro velmi velké objemy dat se stane režií při kopírování nebo streamování dat k uzlu edge pro analýzu.</span><span class="sxs-lookup"><span data-stu-id="56e3e-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="56e3e-152">Spark je rychlejší než mapy snížit pro analýzu v Hadoop.</span><span class="sxs-lookup"><span data-stu-id="56e3e-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="56e3e-153">Zadané tyto zásady, následující části nabízí některé zásady pro výběr výpočetní kontextu.</span><span class="sxs-lookup"><span data-stu-id="56e3e-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="56e3e-154">Místní</span><span class="sxs-lookup"><span data-stu-id="56e3e-154">Local</span></span>
* <span data-ttu-id="56e3e-155">Pokud množství dat k analýze je malá a nevyžaduje opakovanou analýzu, pak Streamovat ho přímo do rutiny analysis pomocí *'local'* nebo *'localpar'*.</span><span class="sxs-lookup"><span data-stu-id="56e3e-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="56e3e-156">Pokud množství dat k analýze je malá nebo středně velký a vyžaduje opakovanou analýzu, pak zkopírujte ho do místního systému souborů, importujte je do XDF a analyzujte ji prostřednictvím *'local'* nebo *'localpar'*.</span><span class="sxs-lookup"><span data-stu-id="56e3e-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="56e3e-157">Hadoop, Spark</span><span class="sxs-lookup"><span data-stu-id="56e3e-157">Hadoop Spark</span></span>
* <span data-ttu-id="56e3e-158">Pokud je velké množství dat k analýze, pak ho importovat do Spark DataFrame pomocí **RxHiveData** nebo **RxParquetData**, nebo XDF v HDFS (Pokud úložiště je problém) a analyzujte ji pomocí Spark výpočetní kontext.</span><span class="sxs-lookup"><span data-stu-id="56e3e-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="56e3e-159">Snižte Hadoop mapy</span><span class="sxs-lookup"><span data-stu-id="56e3e-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="56e3e-160">Použijte kontext mapy snížit výpočetní pouze v případě, že narazíte na problém s nepřekonatelnou s kontextem výpočtů Spark vzhledem k tomu, že je obecně pomalejší.</span><span class="sxs-lookup"><span data-stu-id="56e3e-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="56e3e-161">Vložené nápovědu k rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="56e3e-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="56e3e-162">Další informace a příklady ScaleR výpočetní kontexty najdete v tématu vložený nápovědy v R na metodu rxSetComputeContext, například:</span><span class="sxs-lookup"><span data-stu-id="56e3e-162">For more information and examples of ScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="56e3e-163">Můžete se také podívat na "[ScaleR distribuované Průvodce Computing](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)", je k dispozici z [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server na webu MSDN") knihovny.</span><span class="sxs-lookup"><span data-stu-id="56e3e-163">You can also refer to the “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from the [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="56e3e-164">Další kroky</span><span class="sxs-lookup"><span data-stu-id="56e3e-164">Next steps</span></span>
<span data-ttu-id="56e3e-165">V tomto článku jste se dozvěděli o možnostech, které jsou k dispozici k určení, zda a jak je paralelizovaná provádění málo mezi jader hraniční uzel nebo clusteru HDInsight.</span><span class="sxs-lookup"><span data-stu-id="56e3e-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="56e3e-166">Další informace o tom, jak používat R Server s clustery HDInsight, naleznete v následujících tématech:</span><span class="sxs-lookup"><span data-stu-id="56e3e-166">To learn more about how to use R Server with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="56e3e-167">Přehled R Server pro Hadoop</span><span class="sxs-lookup"><span data-stu-id="56e3e-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="56e3e-168">Začínáme s R Server pro Hadoop</span><span class="sxs-lookup"><span data-stu-id="56e3e-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="56e3e-169">Přidání serveru Rstudia do HDInsight (Pokud není při vytváření clusteru přidat)</span><span class="sxs-lookup"><span data-stu-id="56e3e-169">Add RStudio Server to HDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* [<span data-ttu-id="56e3e-170">Možnosti služby Azure Storage pro R Server ve službě HDInsight</span><span class="sxs-lookup"><span data-stu-id="56e3e-170">Azure Storage options for R Server on HDInsight</span></span>](hdinsight-hadoop-r-server-storage.md)


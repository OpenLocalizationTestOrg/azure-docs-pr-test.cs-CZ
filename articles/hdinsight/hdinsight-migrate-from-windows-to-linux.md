---
title: "Migrace z HDInsight se systémem Windows do HDInsight se systémem Linux - Azure | Microsoft Docs"
description: "Informace o migraci z clusteru HDInsight se systémem Windows do clusteru HDInsight se systémem Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 35e80efe27081cd43243f488fa60447b76a20c32
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 08/03/2017
---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a><span data-ttu-id="1a4cc-103">Migrace z clusteru HDInsight se systémem Windows do clusteru se systémem Linux</span><span class="sxs-lookup"><span data-stu-id="1a4cc-103">Migrate from a Windows-based HDInsight cluster to a Linux-based cluster</span></span>

<span data-ttu-id="1a4cc-104">Tento dokument poskytuje podrobné informace o rozdílech mezi HDInsight v systému Windows a Linux a pokyny k migraci existujících úloh do clusteru se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-104">This document provides details on the differences between HDInsight on Windows and Linux, and guidance on how to migrate existing workloads to a Linux-based cluster.</span></span>

<span data-ttu-id="1a4cc-105">Zatímco HDInsight se systémem Windows poskytuje snadný způsob, jak používat Hadoop v cloudu, musíte při migraci do clusteru se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-105">While Windows-based HDInsight provides an easy way to use Hadoop in the cloud, you may need to migrate to a Linux-based cluster.</span></span> <span data-ttu-id="1a4cc-106">Chcete-li například využít výhod systémem Linux nástroje a technologie, které jsou požadovány pro vaše řešení.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-106">For example, to take advantage of Linux-based tools and technologies that are required for your solution.</span></span> <span data-ttu-id="1a4cc-107">Celou řadu věcí v ekosystému Hadoop jsou vyvinuté na systémy Linux a nemusí být k dispozici pro použití s HDInsight se systémem Windows.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-107">Many things in the Hadoop ecosystem are developed on Linux-based systems, and may not be available for use with Windows-based HDInsight.</span></span> <span data-ttu-id="1a4cc-108">Mnoho knihy, videa a další materiály školení předpokládá, že používáte systém Linux, při práci s Hadoop.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-108">Additionally, many books, videos, and other training material assume that you are using a Linux system when working with Hadoop.</span></span>

> [!NOTE]
> <span data-ttu-id="1a4cc-109">Clustery HDInsight dlouhodobé podporu Ubuntu (LTS) použít jako operační systém pro uzly v clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-109">HDInsight clusters use Ubuntu long-term support (LTS) as the operating system for the nodes in the cluster.</span></span> <span data-ttu-id="1a4cc-110">Informace o verzi Ubuntu s HDInsight, společně s další informace o správě verzí součásti, najdete v části [HDInsight verze součástí](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-110">For information on the version of Ubuntu available with HDInsight, along with other component versioning information, see [HDInsight component versions](hdinsight-component-versioning.md).</span></span>

## <a name="migration-tasks"></a><span data-ttu-id="1a4cc-111">Úlohy migrace</span><span class="sxs-lookup"><span data-stu-id="1a4cc-111">Migration tasks</span></span>

<span data-ttu-id="1a4cc-112">Tady je obecný postup pro migraci.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-112">The general workflow for migration is as follows.</span></span>

![Diagram pracovního postupu migrace](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. <span data-ttu-id="1a4cc-114">Přečtěte si každá část tohoto dokumentu pochopit změny, které může být potřeba při migraci do clusteru se systémem Linux existující pracovní postup, úlohy, atd.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-114">Read each section of this document to understand changes that may be required when migrating your existing workflow, jobs, etc. to a Linux-based cluster.</span></span>

2. <span data-ttu-id="1a4cc-115">Vytvoření clusteru se systémem Linux jako prostředí testovací a kvalita záruky.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-115">Create a Linux-based cluster as a test/quality assurance environment.</span></span> <span data-ttu-id="1a4cc-116">Další informace týkající se vytvoření clusteru se systémem Linux najdete v tématu [vytvořit systémem Linux clusterů v HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-116">For more information on creating a Linux-based cluster, see [Create Linux-based clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span></span>

3. <span data-ttu-id="1a4cc-117">Zkopírujte existující úlohy, zdroje dat a jímky do nového prostředí.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-117">Copy existing jobs, data sources, and sinks to the new environment.</span></span>

4. <span data-ttu-id="1a4cc-118">Provádění testů pro ověření a ujistěte se, že vaše úlohy fungují v novém clusteru podle očekávání.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-118">Perform validation testing to make sure that your jobs work as expected on the new cluster.</span></span>

<span data-ttu-id="1a4cc-119">Jakmile si ověříte, že vše funguje podle očekávání, naplánujte dobu odstávky migrace.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-119">Once you have verified that everything works as expected, schedule downtime for the migration.</span></span> <span data-ttu-id="1a4cc-120">Během této výpadky proveďte následující akce:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-120">During this downtime, perform the following actions:</span></span>

1. <span data-ttu-id="1a4cc-121">Zálohujte všechna přechodný data uložená místně na uzlech clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-121">Back up any transient data stored locally on the cluster nodes.</span></span> <span data-ttu-id="1a4cc-122">Například pokud máte data uložená přímo na hlavního uzlu.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-122">For example, if you have data stored directly on a head node.</span></span>

2. <span data-ttu-id="1a4cc-123">Odstranění clusteru systému Windows.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-123">Delete the Windows-based cluster.</span></span>

3. <span data-ttu-id="1a4cc-124">Vytvořte cluster se systémem Linux pomocí stejné výchozí úložiště dat, které používá clusteru systému Windows.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-124">Create a Linux-based cluster using the same default data store that the Windows-based cluster used.</span></span> <span data-ttu-id="1a4cc-125">Do clusteru se systémem Linux můžete pokračovat v práci s existující provozní data.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-125">The Linux-based cluster can continue working against your existing production data.</span></span>

4. <span data-ttu-id="1a4cc-126">Importujte přechodný data, která jste zálohovali.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-126">Import any transient data you backed up.</span></span>

5. <span data-ttu-id="1a4cc-127">Spuštění úlohy nebo pokračovat ve zpracovávání pomocí nového clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-127">Start jobs/continue processing using the new cluster.</span></span>

### <a name="copy-data-to-the-test-environment"></a><span data-ttu-id="1a4cc-128">Zkopírujte data do testovacího prostředí</span><span class="sxs-lookup"><span data-stu-id="1a4cc-128">Copy data to the test environment</span></span>

<span data-ttu-id="1a4cc-129">Existuje mnoho způsobů zkopírovat data a úlohy, ale dva popsaných v této části jsou nejjednodušší metody, které se přímo přesunout soubory do clusteru s podporou testovací.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-129">There are many methods to copy the data and jobs, however the two discussed in this section are the simplest methods to directly move files to a test cluster.</span></span>

#### <a name="hdfs-copy"></a><span data-ttu-id="1a4cc-130">HDFS kopie</span><span class="sxs-lookup"><span data-stu-id="1a4cc-130">HDFS copy</span></span>

<span data-ttu-id="1a4cc-131">Použijte následující postup ke zkopírování dat z clusteru výroby pro testovací cluster.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-131">Use the following steps to copy data from the production cluster to the test cluster.</span></span> <span data-ttu-id="1a4cc-132">Tyto kroky používají `hdfs dfs` nástroj, který se dodává s HDInsight.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-132">These steps use the `hdfs dfs` utility that is included with HDInsight.</span></span>

1. <span data-ttu-id="1a4cc-133">Najít úložiště informace o účtu a výchozí kontejner pro existující cluster.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-133">Find the storage account and default container information for your existing cluster.</span></span> <span data-ttu-id="1a4cc-134">Následující příklad používá prostředí PowerShell pro načtení těchto informací:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-134">The following example uses PowerShell to retrieve this information:</span></span>

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. <span data-ttu-id="1a4cc-135">Pokud chcete vytvořit testovací prostředí, postupujte podle kroků v vytvořit systémem Linux clusterů v HDInsight dokumentu.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-135">To create a test environment, follow the steps in the Create Linux-based clusters in HDInsight document.</span></span> <span data-ttu-id="1a4cc-136">Zastavit před vytvořením clusteru a místo toho vyberte **volitelné konfiguraci**.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-136">Stop before creating the cluster, and instead select **Optional Configuration**.</span></span>

3. <span data-ttu-id="1a4cc-137">V okně volitelné konfiguraci vyberte **propojených účtech Storage**.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-137">From the Optional Configuration blade, select **Linked Storage Accounts**.</span></span>

4. <span data-ttu-id="1a4cc-138">Vyberte **přidejte klíč k úložišti**a po zobrazení výzvy vyberte účet úložiště, které vrátil skript prostředí PowerShell v kroku 1.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-138">Select **Add a storage key**, and when prompted, select the storage account that was returned by the PowerShell script in step 1.</span></span> <span data-ttu-id="1a4cc-139">Klikněte na tlačítko **vyberte** v každém okně.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-139">Click **Select** on each blade.</span></span> <span data-ttu-id="1a4cc-140">Nakonec vytvořte cluster.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-140">Finally, create the cluster.</span></span>

5. <span data-ttu-id="1a4cc-141">Po vytvoření clusteru připojit se pomocí **SSH.**</span><span class="sxs-lookup"><span data-stu-id="1a4cc-141">Once the cluster has been created, connect to it using **SSH.**</span></span> <span data-ttu-id="1a4cc-142">Další informace najdete v tématu [Použití SSH se službou HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-142">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

6. <span data-ttu-id="1a4cc-143">Z relace SSH použijte následující příkaz pro kopírování souborů z propojený účet úložiště pro nový výchozí účet úložiště.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-143">From the SSH session, use the following command to copy files from the linked storage account to the new default storage account.</span></span> <span data-ttu-id="1a4cc-144">Nahraďte KONTEJNERU informace o kontejneru vrácený prostředí PowerShell.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-144">Replace CONTAINER with the container information returned by PowerShell.</span></span> <span data-ttu-id="1a4cc-145">Nahraďte __účet__ s názvem účtu.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-145">Replace __ACCOUNT__ with the account name.</span></span> <span data-ttu-id="1a4cc-146">Cesta k datům nahraďte cestu k souboru data.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-146">Replace the path to data with the path to a data file.</span></span>

    ```bash
    hdfs dfs -cp wasb://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > <span data-ttu-id="1a4cc-147">Pokud strukturu adresáře, který obsahuje data neexistuje v testovacím prostředí, můžete vytvořit pomocí následujícího příkazu:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-147">If the directory structure that contains the data does not exist on the test environment, you can create it using the following command:</span></span>

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    <span data-ttu-id="1a4cc-148">`-p` Přepínač umožňuje vytvoření všechny adresáře v cestě.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-148">The `-p` switch enables the creation of all directories in  the path.</span></span>

#### <a name="direct-copy-between-blobs-in-azure-storage"></a><span data-ttu-id="1a4cc-149">Přímé kopírování mezi objekty BLOB ve službě Azure Storage</span><span class="sxs-lookup"><span data-stu-id="1a4cc-149">Direct copy between blobs in Azure Storage</span></span>

<span data-ttu-id="1a4cc-150">Alternativně můžete chtít použít `Start-AzureStorageBlobCopy` rutiny Azure Powershellu zkopírovat objekty BLOB mezi účty úložiště mimo HDInsight.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-150">Alternatively, you may want to use the `Start-AzureStorageBlobCopy` Azure PowerShell cmdlet to copy blobs between storage accounts outside of HDInsight.</span></span> <span data-ttu-id="1a4cc-151">Další informace najdete v tématu jak spravovat části objektů BLOB služby Azure pomocí Azure powershellu s Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-151">For more information, see the How to manage Azure Blobs section of Using Azure PowerShell with Azure Storage.</span></span>

## <a name="client-side-technologies"></a><span data-ttu-id="1a4cc-152">Technologie na straně klienta</span><span class="sxs-lookup"><span data-stu-id="1a4cc-152">Client-side technologies</span></span>

<span data-ttu-id="1a4cc-153">Klientské technologie, jako [rutin prostředí Azure PowerShell](/powershell/azureps-cmdlets-docs), [rozhraní příkazového řádku Azure](../cli-install-nodejs.md), nebo [.NET SDK pro Hadoop](https://hadoopsdk.codeplex.com/) pokračovat v práci clusterech se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-153">Client-side technologies such as [Azure PowerShell cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), or the [.NET SDK for Hadoop](https://hadoopsdk.codeplex.com/) continue to work Linux-based clusters.</span></span> <span data-ttu-id="1a4cc-154">Tyto technologie spoléhají na REST API, která jsou stejné napříč oba typy clusteru operačního systému.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-154">These technologies rely on REST APIs that are the same across both cluster OS types.</span></span>

## <a name="server-side-technologies"></a><span data-ttu-id="1a4cc-155">Technologie na straně serveru</span><span class="sxs-lookup"><span data-stu-id="1a4cc-155">Server-side technologies</span></span>

<span data-ttu-id="1a4cc-156">Následující tabulka obsahuje pokyny k migraci serverové komponenty, které jsou specifické pro systém Windows.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-156">The following table provides guidance on migrating server-side components that are Windows-specific.</span></span>

| <span data-ttu-id="1a4cc-157">Pokud použijete tuto technologii...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-157">If you are using this technology...</span></span> | <span data-ttu-id="1a4cc-158">Tato akce trvat...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-158">Take this action...</span></span> |
| --- | --- |
| <span data-ttu-id="1a4cc-159">**Prostředí PowerShell** (skripty na straně serveru, včetně akcí skriptů používají při vytváření clusteru)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-159">**PowerShell** (server-side scripts, including Script Actions used during cluster creation)</span></span> |<span data-ttu-id="1a4cc-160">Přepisování jako skripty Bash.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-160">Rewrite as Bash scripts.</span></span> <span data-ttu-id="1a4cc-161">Pro skript akce, najdete v části [HDInsight se systémem Linux přizpůsobit pomocí akcí skriptů](hdinsight-hadoop-customize-cluster-linux.md) a [vývoj akcí pro HDInsight se systémem Linux skriptů](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-161">For Script Actions, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span> |
| <span data-ttu-id="1a4cc-162">**Rozhraní příkazového řádku Azure** (skripty na straně serveru)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-162">**Azure CLI** (server-side scripts)</span></span> |<span data-ttu-id="1a4cc-163">Zatímco Azure CLI je k dispozici v systému Linux, nepochází předem nainstalovaná o hlavních uzlech clusteru HDInsight.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-163">While the Azure CLI is available on Linux, it does not come pre-installed on the HDInsight cluster head nodes.</span></span> <span data-ttu-id="1a4cc-164">Další informace o instalaci rozhraní příkazového řádku Azure najdete v tématu [Začínáme s Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-164">For more information on installing the Azure CLI, see [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span></span> |
| <span data-ttu-id="1a4cc-165">**Součásti rozhraní .NET**</span><span class="sxs-lookup"><span data-stu-id="1a4cc-165">**.NET components**</span></span> |<span data-ttu-id="1a4cc-166">Rozhraní .NET je podporována v HDInsight se systémem Linux prostřednictvím [Mono](https://mono-project.com).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-166">.NET is supported on Linux-based HDInsight through [Mono](https://mono-project.com).</span></span> <span data-ttu-id="1a4cc-167">Další informace najdete v tématu [řešení migrovat .NET HDInsight se systémem Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-167">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span> |
| <span data-ttu-id="1a4cc-168">**Součásti Win32 nebo jiné technologie pouze pro systém Windows**</span><span class="sxs-lookup"><span data-stu-id="1a4cc-168">**Win32 components or other Windows-only technology**</span></span> |<span data-ttu-id="1a4cc-169">Pokyny, závisí na součásti nebo technologii.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-169">Guidance depends on the component or technology.</span></span> <span data-ttu-id="1a4cc-170">Bude pravděpodobně možné najít na verzi, která je kompatibilní s Linuxem, nebo budete muset najít alternativní řešení nebo přepsání této součásti.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-170">You may be able to find a version that is compatible with Linux, or you may need to find an alternate solution or rewrite this component.</span></span> |

> [!IMPORTANT]
> <span data-ttu-id="1a4cc-171">Správa HDInsight SDK není plně kompatibilní se Mono.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-171">The HDInsight management SDK is not fully compatible with Mono.</span></span> <span data-ttu-id="1a4cc-172">Nepoužívejte jako součást řešení nasazené v tuto chvíli ke clusteru HDInsight.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-172">It should not be used as part of solutions deployed to the HDInsight cluster at this time.</span></span>

## <a name="cluster-creation"></a><span data-ttu-id="1a4cc-173">Vytvoření clusteru</span><span class="sxs-lookup"><span data-stu-id="1a4cc-173">Cluster creation</span></span>

<span data-ttu-id="1a4cc-174">Tato část obsahuje informace o rozdíly ve vytváření clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-174">This section provides information on differences in cluster creation.</span></span>

### <a name="ssh-user"></a><span data-ttu-id="1a4cc-175">SSH uživatele</span><span class="sxs-lookup"><span data-stu-id="1a4cc-175">SSH User</span></span>

<span data-ttu-id="1a4cc-176">Clustery HDInsight se systémem Linux pomocí **Secure Shell (SSH)** protokol poskytnout vzdálený přístup k uzlům clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-176">Linux-based HDInsight clusters use the **Secure Shell (SSH)** protocol to provide remote access to the cluster nodes.</span></span> <span data-ttu-id="1a4cc-177">Na rozdíl od clustery založené na vzdálené plochy pro Windows neposkytují většině klientů SSH v grafickém uživatelském rozhraní.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-177">Unlike Remote Desktop for Windows-based clusters, most SSH clients do not provide a graphical user experience.</span></span> <span data-ttu-id="1a4cc-178">Místo toho klientů SSH zadejte příkazový řádek, který slouží ke spuštění příkazů v clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-178">Instead, SSH clients provide a command line that allows you to run commands on the cluster.</span></span> <span data-ttu-id="1a4cc-179">Někteří klienti (například [MobaXterm](http://mobaxterm.mobatek.net/)) zadejte Prohlížeč systému grafické souboru kromě vzdáleného příkazového řádku.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-179">Some clients (such as [MobaXterm](http://mobaxterm.mobatek.net/)) provide a graphical file system browser in addition to a remote command line.</span></span>

<span data-ttu-id="1a4cc-180">Při vytváření clusteru, je třeba zadat uživatel SSH a buď **heslo** nebo **certifikátu veřejného klíče** pro ověřování.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-180">During cluster creation, you must provide an SSH user and either a **password** or **public key certificate** for authentication.</span></span>

<span data-ttu-id="1a4cc-181">Doporučujeme používat certifikát veřejného klíče, jako je bezpečnější než použití hesla.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-181">We recommend using Public key certificate, as it is more secure than using a password.</span></span> <span data-ttu-id="1a4cc-182">Ověřování pomocí certifikátu funguje tak, že generování podepsaný pár veřejného a privátního klíče a pak poskytuje veřejný klíč při vytvoření clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-182">Certificate authentication works by generating a signed public/private key pair, then providing the public key when creating the cluster.</span></span> <span data-ttu-id="1a4cc-183">Při připojování k serveru pomocí protokolu SSH, poskytuje privátní klíč na straně klienta pro připojení.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-183">When connecting to the server using SSH, the private key on the client provides authentication for the connection.</span></span>

<span data-ttu-id="1a4cc-184">Další informace najdete v tématu [Použití SSH se službou HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-184">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

### <a name="cluster-customization"></a><span data-ttu-id="1a4cc-185">Přizpůsobení clusteru</span><span class="sxs-lookup"><span data-stu-id="1a4cc-185">Cluster customization</span></span>

<span data-ttu-id="1a4cc-186">**Skript akce** použít s clustery se systémem Linux musí být napsaný ve skriptu Bash.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-186">**Script Actions** used with Linux-based clusters must be written in Bash script.</span></span> <span data-ttu-id="1a4cc-187">I když skriptových akcí můžete použít při vytváření clusteru, clustery se systémem Linux se mohou být použité k přizpůsobení až po clusteru a spuštěná.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-187">While Script Actions can be used during cluster creation, for Linux-based clusters they can also be used to perform customization after a cluster is up and running.</span></span> <span data-ttu-id="1a4cc-188">Další informace najdete v tématu [HDInsight se systémem Linux přizpůsobit pomocí akcí skriptů](hdinsight-hadoop-customize-cluster-linux.md) a [vývoj akcí pro HDInsight se systémem Linux skriptů](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-188">For more information, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

<span data-ttu-id="1a4cc-189">Další přizpůsobení funkcí je **bootstrap**.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-189">Another customization feature is **bootstrap**.</span></span> <span data-ttu-id="1a4cc-190">Pro clustery systému Windows tato funkce umožňuje zadat umístění další knihovny pro použití s Hive.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-190">For Windows clusters, this feature allows you to specify the location of additional libraries for use with Hive.</span></span> <span data-ttu-id="1a4cc-191">Po vytvoření clusteru, jsou automaticky dostupné pro použití s dotazy Hive, aniž by bylo nutné použít tyto knihovny `ADD JAR`.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-191">After cluster creation, these libraries are automatically available for use with Hive queries without the need to use `ADD JAR`.</span></span>

<span data-ttu-id="1a4cc-192">Spuštění funkce pro clustery se systémem Linux neposkytuje tuto funkci.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-192">The Bootstrap feature for Linux-based clusters does not provide this functionality.</span></span> <span data-ttu-id="1a4cc-193">Místo toho použijte akce skriptu, které jsou dokumentovány v článku [přidat Hive knihovny při vytváření clusteru](hdinsight-hadoop-add-hive-libraries.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-193">Instead, use script action documented in [Add Hive libraries during cluster creation](hdinsight-hadoop-add-hive-libraries.md).</span></span>

### <a name="virtual-networks"></a><span data-ttu-id="1a4cc-194">Virtuální sítě</span><span class="sxs-lookup"><span data-stu-id="1a4cc-194">Virtual Networks</span></span>

<span data-ttu-id="1a4cc-195">HDInsight se systémem Windows clusterů funguje jenom s klasické virtuální sítě, zatímco clustery HDInsight se systémem Linux vyžadují virtuální sítě Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-195">Windows-based HDInsight clusters only work with Classic Virtual Networks, while Linux-based HDInsight clusters require Resource Manager Virtual Networks.</span></span> <span data-ttu-id="1a4cc-196">Pokud máte v klasické virtuální síti, která clusteru Linux HDInsight musí připojit k prostředkům, najdete v části [připojení klasickou virtuální síť k virtuální síti Resource Manager](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-196">If you have resources in a Classic Virtual Network that the Linux-HDInsight cluster must connect to, see [Connecting a Classic Virtual Network to a Resource Manager Virtual Network](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span></span>

<span data-ttu-id="1a4cc-197">Další informace o požadavky na konfiguraci pro použití virtuálních sítí Azure s HDInsight naleznete v tématu [HDInsight rozšířit možnosti pomocí virtuální sítě](hdinsight-extend-hadoop-virtual-network.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-197">For more information on configuration requirements for using Azure Virtual Networks with HDInsight, see [Extend HDInsight capabilities by using a Virtual Network](hdinsight-extend-hadoop-virtual-network.md).</span></span>

## <a name="management-and-monitoring"></a><span data-ttu-id="1a4cc-198">Monitorování a správa</span><span class="sxs-lookup"><span data-stu-id="1a4cc-198">Management and monitoring</span></span>

<span data-ttu-id="1a4cc-199">Mnoho webových uživatelská možná zneužil s HDInsight se systémem Windows, jako je historie úlohy nebo uživatelského rozhraní Yarn, jsou k dispozici prostřednictvím Ambari.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-199">Many of the web UIs you may have used with Windows-based HDInsight, such as Job History or Yarn UI, are available through Ambari.</span></span> <span data-ttu-id="1a4cc-200">Kromě toho zobrazení Ambari Hive poskytuje způsob, jak spouštět dotazy Hive pomocí webového prohlížeče.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-200">In addition, the Ambari Hive View provides a way to run Hive queries using your web browser.</span></span> <span data-ttu-id="1a4cc-201">Webové uživatelské rozhraní Ambari je k dispozici v clusterech se systémem Linux v https://CLUSTERNAME.azurehdinsight.net.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-201">The Ambari Web UI is available on Linux-based clusters at https://CLUSTERNAME.azurehdinsight.net.</span></span>

<span data-ttu-id="1a4cc-202">Další informace o práci s Ambari najdete v následujících dokumentech:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-202">For more information on working with Ambari, see the following documents:</span></span>

* [<span data-ttu-id="1a4cc-203">Ambari Web</span><span class="sxs-lookup"><span data-stu-id="1a4cc-203">Ambari Web</span></span>](hdinsight-hadoop-manage-ambari.md)
* [<span data-ttu-id="1a4cc-204">Ambari REST API</span><span class="sxs-lookup"><span data-stu-id="1a4cc-204">Ambari REST API</span></span>](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a><span data-ttu-id="1a4cc-205">Ambari výstrahy</span><span class="sxs-lookup"><span data-stu-id="1a4cc-205">Ambari Alerts</span></span>

<span data-ttu-id="1a4cc-206">Ambari má upozornění systému, který zjistí potenciální problémy s clusterem.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-206">Ambari has an alert system that can tell you of potential problems with the cluster.</span></span> <span data-ttu-id="1a4cc-207">Výstrahy se zobrazují jako red nebo žlutou položek ve webovém uživatelském rozhraní Ambari, ale můžete také načíst přes rozhraní REST API.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-207">Alerts appear as red or yellow entries in the Ambari Web UI, however you can also retrieve them through the REST API.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="1a4cc-208">Výstrahy Ambari označuje, zda *může* se jednat o problém není že v něm *je* problém.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-208">Ambari alerts indicate that there *may* be a problem, not that there *is* a problem.</span></span> <span data-ttu-id="1a4cc-209">Například můžete obdržet oznámení, že nejsou k dispozici HiveServer2, i když je k němu přístup normálně.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-209">For example, you may receive an alert that HiveServer2 cannot be accessed, even though you can access it normally.</span></span>
>
> <span data-ttu-id="1a4cc-210">Mnoho výstrah jsou implementované jako dotazy na bázi intervalů pro služby a očekávat odpovědi v určitém časovém rámci.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-210">Many alerts are implemented as interval-based queries against a service, and expect a response within a specific time frame.</span></span> <span data-ttu-id="1a4cc-211">Takže upozornění nemusí nutně znamenat, že služba je mimo provoz, stejně to nevrátila výsledky v očekávané časovém rámci.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-211">So the alert doesn't necessarily mean that the service is down, just that it didn't return results within the expected time frame.</span></span>

<span data-ttu-id="1a4cc-212">Byste měli zvážit, zda výstrahu projevuje po delší dobu, nebo zrcadlí uživatele problémy, které byla nahlášena před provedením akce na něm.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-212">You should evaluate whether an alert has been occurring for an extended period, or mirrors user problems that have been reported before taking action on it.</span></span>

## <a name="file-system-locations"></a><span data-ttu-id="1a4cc-213">Umístění systému souborů</span><span class="sxs-lookup"><span data-stu-id="1a4cc-213">File system locations</span></span>

<span data-ttu-id="1a4cc-214">Systém souborů clusteru Linux rozložená jinak než clustery HDInsight se systémem Windows.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-214">The Linux cluster file system is laid out differently than Windows-based HDInsight clusters.</span></span> <span data-ttu-id="1a4cc-215">Následující tabulku použijte k vyhledání běžně používané soubory.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-215">Use the following table to find commonly used files.</span></span>

| <span data-ttu-id="1a4cc-216">Je nutné nalézt...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-216">I need to find...</span></span> | <span data-ttu-id="1a4cc-217">Je umístěný...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-217">It is located...</span></span> |
| --- | --- |
| <span data-ttu-id="1a4cc-218">Konfigurace</span><span class="sxs-lookup"><span data-stu-id="1a4cc-218">Configuration</span></span> |<span data-ttu-id="1a4cc-219">`/etc`.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-219">`/etc`.</span></span> <span data-ttu-id="1a4cc-220">Například `/etc/hadoop/conf/core-site.xml`.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-220">For example, `/etc/hadoop/conf/core-site.xml`</span></span> |
| <span data-ttu-id="1a4cc-221">Soubory protokolu</span><span class="sxs-lookup"><span data-stu-id="1a4cc-221">Log files</span></span> |`/var/logs` |
| <span data-ttu-id="1a4cc-222">Hortonworks Data Platform (HDP)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-222">Hortonworks Data Platform (HDP)</span></span> |<span data-ttu-id="1a4cc-223">`/usr/hdp`. Existují dva adresáře tady, ten, který je aktuální verze softwaru HDP a `current`.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-223">`/usr/hdp`.There are two directories located here, one that is the current HDP version and `current`.</span></span> <span data-ttu-id="1a4cc-224">`current` Adresář obsahuje symbolické odkazy na soubory a adresáře, které jsou umístěné v adresáři číslo verze.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-224">The `current` directory contains symbolic links to files and directories located in the version number directory.</span></span> <span data-ttu-id="1a4cc-225">`current` Adresář je zadaný jako pohodlný způsob přístupu k souborům HDP od změní se číslo verze jako softwaru HDP za verzi aktualizovat.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-225">The `current` directory is provided as a convenient way of accessing HDP files since the version number changes as the HDP version is updated.</span></span> |
| <span data-ttu-id="1a4cc-226">hadoop streaming.jar</span><span class="sxs-lookup"><span data-stu-id="1a4cc-226">hadoop-streaming.jar</span></span> |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

<span data-ttu-id="1a4cc-227">Obecně platí Pokud znáte název souboru, můžete použít následující příkaz z relace SSH najít cestu k souboru:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-227">In general, if you know the name of the file, you can use the following command from an SSH session to find the file path:</span></span>

    find / -name FILENAME 2>/dev/null

<span data-ttu-id="1a4cc-228">Můžete také použít zástupné znaky s názvem souboru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-228">You can also use wildcards with the file name.</span></span> <span data-ttu-id="1a4cc-229">Například `find / -name *streaming*.jar 2>/dev/null` vrací cestu k soubory jar obsahující slovo "streamování jako součást názvu souboru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-229">For example, `find / -name *streaming*.jar 2>/dev/null` returns the path to any jar files that contain the word 'streaming' as part of the file name.</span></span>

## <a name="hive-pig-and-mapreduce"></a><span data-ttu-id="1a4cc-230">Hive, Pig a MapReduce</span><span class="sxs-lookup"><span data-stu-id="1a4cc-230">Hive, Pig, and MapReduce</span></span>

<span data-ttu-id="1a4cc-231">Pig a MapReduce úlohy jsou podobné v clusterech se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-231">Pig and MapReduce workloads are similar on Linux-based clusters.</span></span> <span data-ttu-id="1a4cc-232">Ale clustery HDInsight se systémem Linux můžete vytvořit pomocí novější verze systému Hadoop, Hive a Pig.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-232">However, Linux-based HDInsight clusters can be created using newer versions of Hadoop, Hive, and Pig.</span></span> <span data-ttu-id="1a4cc-233">Tyto rozdíly verze může znamenat změny v jak vaše stávající řešení funkce.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-233">These version differences may introduce changes in how your existing solutions function.</span></span> <span data-ttu-id="1a4cc-234">Další informace o verzích součásti, které jsou zahrnuté do HDInsight naleznete v tématu [Správa verzí komponenty HDInsight](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-234">For more information on the versions of components included with HDInsight, see [HDInsight component versioning](hdinsight-component-versioning.md).</span></span>

<span data-ttu-id="1a4cc-235">HDInsight se systémem Linux neposkytuje funkce vzdálené plochy.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-235">Linux-based HDInsight does not provide remote desktop functionality.</span></span> <span data-ttu-id="1a4cc-236">Místo toho můžete SSH vzdálené připojení k hlavnímu uzlu clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-236">Instead, you can use SSH to remotely connect to the cluster head nodes.</span></span> <span data-ttu-id="1a4cc-237">Další informace najdete v následujících dokumentech:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-237">For more information, see the following documents:</span></span>

* [<span data-ttu-id="1a4cc-238">Použijte Hive pomocí protokolu SSH</span><span class="sxs-lookup"><span data-stu-id="1a4cc-238">Use Hive with SSH</span></span>](hdinsight-hadoop-use-hive-ssh.md)
* [<span data-ttu-id="1a4cc-239">Použijte Pig s SSH</span><span class="sxs-lookup"><span data-stu-id="1a4cc-239">Use Pig with SSH</span></span>](hdinsight-hadoop-use-pig-ssh.md)
* [<span data-ttu-id="1a4cc-240">Používání nástroje MapReduce pomocí protokolu SSH</span><span class="sxs-lookup"><span data-stu-id="1a4cc-240">Use MapReduce with SSH</span></span>](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a><span data-ttu-id="1a4cc-241">Hive</span><span class="sxs-lookup"><span data-stu-id="1a4cc-241">Hive</span></span>

> [!IMPORTANT]
> <span data-ttu-id="1a4cc-242">Pokud chcete použít externí metaúložiště Hive, byste měli zálohovat metaúložiště před jeho použitím s HDInsight se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-242">If you use an external Hive metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="1a4cc-243">HDInsight se systémem Linux je k dispozici novější verze Hive, který může mít nekompatibilitu s metaúložiště vytvořené pomocí dřívějších verzí.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-243">Linux-based HDInsight is available with newer versions of Hive, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="1a4cc-244">Následující graf obsahuje pokyny k migraci vašich úloh Hive.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-244">The following chart provides guidance on migrating your Hive workloads.</span></span>

| <span data-ttu-id="1a4cc-245">V systému Windows použít...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-245">On Windows-based, I use...</span></span> | <span data-ttu-id="1a4cc-246">Na základě Linux...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-246">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="1a4cc-247">**Hive Editor**</span><span class="sxs-lookup"><span data-stu-id="1a4cc-247">**Hive Editor**</span></span> |[<span data-ttu-id="1a4cc-248">Zobrazení Ambari Hive</span><span class="sxs-lookup"><span data-stu-id="1a4cc-248">Hive View in Ambari</span></span>](hdinsight-hadoop-use-hive-ambari-view.md) |
| <span data-ttu-id="1a4cc-249">`set hive.execution.engine=tez;`Chcete-li povolit Tez</span><span class="sxs-lookup"><span data-stu-id="1a4cc-249">`set hive.execution.engine=tez;` to enable Tez</span></span> |<span data-ttu-id="1a4cc-250">Tez je výchozí modul provádění pro clustery se systémem Linux, takže příkaz set již není potřeba.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-250">Tez is the default execution engine for Linux-based clusters, so the set statement is no longer needed.</span></span> |
| <span data-ttu-id="1a4cc-251">Uživatelem definované funkce jazyka C#</span><span class="sxs-lookup"><span data-stu-id="1a4cc-251">C# user-defined functions</span></span> | <span data-ttu-id="1a4cc-252">Informace o ověřování součásti C# s HDInsight se systémem Linux najdete v tématu [řešení migrovat .NET HDInsight se systémem Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-252">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="1a4cc-253">CMD soubory nebo skripty na serveru vyvolána jako součást úlohy Hive</span><span class="sxs-lookup"><span data-stu-id="1a4cc-253">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="1a4cc-254">pomocí skriptů Bash</span><span class="sxs-lookup"><span data-stu-id="1a4cc-254">use Bash scripts</span></span> |
| <span data-ttu-id="1a4cc-255">`hive`příkaz z vzdálené plochy</span><span class="sxs-lookup"><span data-stu-id="1a4cc-255">`hive` command from remote desktop</span></span> |<span data-ttu-id="1a4cc-256">Použití [Beeline](hdinsight-hadoop-use-hive-beeline.md) nebo [Hive z relace SSH](hdinsight-hadoop-use-hive-ssh.md)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-256">Use [Beeline](hdinsight-hadoop-use-hive-beeline.md) or [Hive from an SSH session](hdinsight-hadoop-use-hive-ssh.md)</span></span> |

### <a name="pig"></a><span data-ttu-id="1a4cc-257">Pig</span><span class="sxs-lookup"><span data-stu-id="1a4cc-257">Pig</span></span>

| <span data-ttu-id="1a4cc-258">V systému Windows použít...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-258">On Windows-based, I use...</span></span> | <span data-ttu-id="1a4cc-259">Na základě Linux...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-259">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="1a4cc-260">Uživatelem definované funkce jazyka C#</span><span class="sxs-lookup"><span data-stu-id="1a4cc-260">C# user-defined functions</span></span> | <span data-ttu-id="1a4cc-261">Informace o ověřování součásti C# s HDInsight se systémem Linux najdete v tématu [řešení migrovat .NET HDInsight se systémem Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-261">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="1a4cc-262">CMD soubory nebo skripty na serveru vyvolána jako součást úlohy Pig</span><span class="sxs-lookup"><span data-stu-id="1a4cc-262">CMD files or scripts on the server invoked as part of a Pig job</span></span> |<span data-ttu-id="1a4cc-263">pomocí skriptů Bash</span><span class="sxs-lookup"><span data-stu-id="1a4cc-263">use Bash scripts</span></span> |

### <a name="mapreduce"></a><span data-ttu-id="1a4cc-264">MapReduce</span><span class="sxs-lookup"><span data-stu-id="1a4cc-264">MapReduce</span></span>

| <span data-ttu-id="1a4cc-265">V systému Windows použít...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-265">On Windows-based, I use...</span></span> | <span data-ttu-id="1a4cc-266">Na základě Linux...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-266">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="1a4cc-267">C# mapper a reduktorem součásti</span><span class="sxs-lookup"><span data-stu-id="1a4cc-267">C# mapper and reducer components</span></span> | <span data-ttu-id="1a4cc-268">Informace o ověřování součásti C# s HDInsight se systémem Linux najdete v tématu [řešení migrovat .NET HDInsight se systémem Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-268">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="1a4cc-269">CMD soubory nebo skripty na serveru vyvolána jako součást úlohy Hive</span><span class="sxs-lookup"><span data-stu-id="1a4cc-269">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="1a4cc-270">pomocí skriptů Bash</span><span class="sxs-lookup"><span data-stu-id="1a4cc-270">use Bash scripts</span></span> |

## <a name="oozie"></a><span data-ttu-id="1a4cc-271">Oozie</span><span class="sxs-lookup"><span data-stu-id="1a4cc-271">Oozie</span></span>

> [!IMPORTANT]
> <span data-ttu-id="1a4cc-272">Pokud chcete použít externí metaúložiště Oozie, byste měli zálohovat metaúložiště před jeho použitím s HDInsight se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-272">If you use an external Oozie metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="1a4cc-273">HDInsight se systémem Linux je k dispozici novější verze Oozie, který může mít nekompatibilitu s metaúložiště vytvořené pomocí dřívějších verzí.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-273">Linux-based HDInsight is available with newer versions of Oozie, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="1a4cc-274">Pracovní postupy Oozie prostředí akce povolit.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-274">Oozie workflows allow shell actions.</span></span> <span data-ttu-id="1a4cc-275">Spustit příkazy příkazového řádku pomocí prostředí akce výchozí prostředí pro operační systém.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-275">Shell actions use the default shell for the operating system to run command-line commands.</span></span> <span data-ttu-id="1a4cc-276">Pokud máte Oozie pracovní postupy, které jsou závislé na prostředí systému Windows, musí přepsat s pracovními postupy k závisí na prostředí shell Linux (Bash).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-276">If you have Oozie workflows that rely on the Windows shell, you must rewrite the workflows to rely on the Linux shell environment (Bash).</span></span> <span data-ttu-id="1a4cc-277">Další informace o používání prostředí akce s Oozie najdete v tématu [rozšíření akce prostředí Oozie](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-277">For more information on using shell actions with Oozie, see [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span></span>

<span data-ttu-id="1a4cc-278">Pokud máte Oozie pracovní postupy, které jsou závislé na aplikací v C# vyvolat prostřednictvím akce prostředí, musíte ověřit tyto aplikace v prostředí Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-278">If you have Oozie workflows that rely on C# applications invoked through shell actions, you must validate these applications in a Linux environment.</span></span> <span data-ttu-id="1a4cc-279">Další informace najdete v tématu [řešení migrovat .NET HDInsight se systémem Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-279">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span>

## <a name="storm"></a><span data-ttu-id="1a4cc-280">Storm</span><span class="sxs-lookup"><span data-stu-id="1a4cc-280">Storm</span></span>

| <span data-ttu-id="1a4cc-281">V systému Windows použít...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-281">On Windows-based, I use...</span></span> | <span data-ttu-id="1a4cc-282">Na základě Linux...</span><span class="sxs-lookup"><span data-stu-id="1a4cc-282">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="1a4cc-283">Řídicí panel Storm</span><span class="sxs-lookup"><span data-stu-id="1a4cc-283">Storm Dashboard</span></span> |<span data-ttu-id="1a4cc-284">Řídicí panel Storm není k dispozici.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-284">The Storm Dashboard is not available.</span></span> <span data-ttu-id="1a4cc-285">V tématu [topologií nasazení a správa Storm v HDInsight se systémem Linux](hdinsight-storm-deploy-monitor-topology-linux.md) pro způsoby, jak odeslat topologie</span><span class="sxs-lookup"><span data-stu-id="1a4cc-285">See [Deploy and Manage Storm topologies on Linux-based HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) for ways to submit topologies</span></span> |
| <span data-ttu-id="1a4cc-286">Storm uživatelského rozhraní</span><span class="sxs-lookup"><span data-stu-id="1a4cc-286">Storm UI</span></span> |<span data-ttu-id="1a4cc-287">Uživatelské rozhraní Storm je k dispozici na https://CLUSTERNAME.azurehdinsight.net/stormui</span><span class="sxs-lookup"><span data-stu-id="1a4cc-287">The Storm UI is available at https://CLUSTERNAME.azurehdinsight.net/stormui</span></span> |
| <span data-ttu-id="1a4cc-288">Visual Studio k vytvoření, nasazení a správě jazyka C# nebo hybridní topologie</span><span class="sxs-lookup"><span data-stu-id="1a4cc-288">Visual Studio to create, deploy, and manage C# or hybrid topologies</span></span> |<span data-ttu-id="1a4cc-289">Visual Studio můžete použít k vytvoření, nasazení a správě jazyka C# (SCP.NET) nebo hybridní topologie na Storm se systémem Linux v HDInsight clustery, které jsou vytvořené po 10/28/2016.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-289">Visual Studio can be used to create, deploy, and manage C# (SCP.NET) or hybrid topologies on Linux-based Storm on HDInsight clusters created after 10/28/2016.</span></span> |

## <a name="hbase"></a><span data-ttu-id="1a4cc-290">HBase</span><span class="sxs-lookup"><span data-stu-id="1a4cc-290">HBase</span></span>

<span data-ttu-id="1a4cc-291">V clusterech se systémem Linux, znode nadřazeného prvku pro HBase je `/hbase-unsecure`.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-291">On Linux-based clusters, the znode parent for HBase is `/hbase-unsecure`.</span></span> <span data-ttu-id="1a4cc-292">Tuto hodnotu lze nastavte v konfiguraci pro jakéhokoli Java klienta aplikace, které používají nativní API HBase Java.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-292">Set this value in the configuration for any Java client applications that use native HBase Java API.</span></span>

<span data-ttu-id="1a4cc-293">V tématu [sestavení aplikace založené na jazyce Java HBase](hdinsight-hbase-build-java-maven.md) pro příklad klienta, který nastavuje tuto hodnotu.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-293">See [Build a Java-based HBase application](hdinsight-hbase-build-java-maven.md) for an example client that sets this value.</span></span>

## <a name="spark"></a><span data-ttu-id="1a4cc-294">Spark</span><span class="sxs-lookup"><span data-stu-id="1a4cc-294">Spark</span></span>

<span data-ttu-id="1a4cc-295">Clustery Spark nebyly k dispozici v clusterech Windows verzi Preview.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-295">Spark clusters were available on Windows-clusters during preview.</span></span> <span data-ttu-id="1a4cc-296">Spark GA je dostupná jenom s clustery se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-296">Spark GA is only available with Linux-based clusters.</span></span> <span data-ttu-id="1a4cc-297">Neexistuje cesta migrace z clusteru se systémem Windows Spark preview do clusteru se systémem Linux Spark verze.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-297">There is no migration path from a Windows-based Spark preview cluster to a release Linux-based Spark cluster.</span></span>

## <a name="known-issues"></a><span data-ttu-id="1a4cc-298">Známé problémy</span><span class="sxs-lookup"><span data-stu-id="1a4cc-298">Known issues</span></span>

### <a name="azure-data-factory-custom-net-activities"></a><span data-ttu-id="1a4cc-299">Azure Data Factory vlastních aktivit rozhraní .NET</span><span class="sxs-lookup"><span data-stu-id="1a4cc-299">Azure Data Factory custom .NET activities</span></span>

<span data-ttu-id="1a4cc-300">Azure Data Factory vlastních aktivit .NET nejsou aktuálně podporovány na clusterech HDInsight se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-300">Azure Data Factory custom .NET activities are not currently supported on Linux-based HDInsight clusters.</span></span> <span data-ttu-id="1a4cc-301">Místo toho používejte jednu z následujících metod k implementaci vlastních aktivit v rámci vašeho kanálu ADF.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-301">Instead, you should use one of the following methods to implement custom activities as part of your ADF pipeline.</span></span>

* <span data-ttu-id="1a4cc-302">Spuštění aktivity rozhraní .NET ve fondu Azure Batch.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-302">Execute .NET activities on Azure Batch pool.</span></span> <span data-ttu-id="1a4cc-303">Použití Azure Batch propojené služby části najdete [použít vlastní aktivity v kanálu Azure Data Factory](../data-factory/data-factory-use-custom-activities.md)</span><span class="sxs-lookup"><span data-stu-id="1a4cc-303">See the Use Azure Batch linked service section of [Use custom activities in an Azure Data Factory pipeline](../data-factory/data-factory-use-custom-activities.md)</span></span>
* <span data-ttu-id="1a4cc-304">Implementujte aktivitu jako činnost MapReduce.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-304">Implement the activity as a MapReduce activity.</span></span> <span data-ttu-id="1a4cc-305">Další informace najdete v tématu [vyvolání MapReduce programy z datové továrny](../data-factory/data-factory-map-reduce.md).</span><span class="sxs-lookup"><span data-stu-id="1a4cc-305">For more information, see [Invoke MapReduce Programs from Data Factory](../data-factory/data-factory-map-reduce.md).</span></span>

### <a name="line-endings"></a><span data-ttu-id="1a4cc-306">Konce řádků</span><span class="sxs-lookup"><span data-stu-id="1a4cc-306">Line endings</span></span>

<span data-ttu-id="1a4cc-307">Konce řádků na systémy Windows se obvykle používá Line FEED, při systémy Linux používat LF.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-307">In general, line endings on Windows-based systems use CRLF, while Linux-based systems use LF.</span></span> <span data-ttu-id="1a4cc-308">Pokud vytvořit, nebo očekávat, data s Line FEED konce řádků, musíte upravit producenti nebo příjemci pro práci s ukončuje řádku LF.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-308">If you produce, or expect, data with CRLF line endings, you may need to modify the producers or consumers to work with the LF line ending.</span></span>

<span data-ttu-id="1a4cc-309">Například použití Azure PowerShell k dotazu HDInsight v clusteru se systémem Windows vrací data s Line FEED.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-309">For example, using Azure PowerShell to query HDInsight on a Windows-based cluster returns data with CRLF.</span></span> <span data-ttu-id="1a4cc-310">Stejný dotaz s clusterem se systémem Linux vrátí LF.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-310">The same query with a Linux-based cluster returns LF.</span></span> <span data-ttu-id="1a4cc-311">Měli byste otestovat Pokud chcete zobrazit, pokud ukončuje řádku způsobí, že problém s vaší solutuion před migrací do clusteru se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-311">You should test to see if the line ending causes a problem with your solutuion before migrating to a Linux-based cluster.</span></span>

<span data-ttu-id="1a4cc-312">Pokud máte skripty, které jsou provedeny přímo na uzly clusteru Linux, byste měli vždycky používat LF jako ukončování řádků.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-312">If you have scripts that are executed directly on the Linux-cluster nodes, you should always use LF as the line ending.</span></span> <span data-ttu-id="1a4cc-313">Pokud používáte Line FEED, může se zobrazí chyby při spuštění skriptů v clusteru se systémem Linux.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-313">If you use CRLF, you may see errors when running the scripts on a Linux-based cluster.</span></span>

<span data-ttu-id="1a4cc-314">Pokud víte, že tyto skripty neobsahují řetězce s embedded znaky CR, můžete hromadně změňte konce řádků pomocí jedné z následujících metod:</span><span class="sxs-lookup"><span data-stu-id="1a4cc-314">If you know that the scripts do not contain strings with embedded CR characters, you can bulk change the line endings using one of the following methods:</span></span>

* <span data-ttu-id="1a4cc-315">**Před nahráním do clusteru**: použijte následující příkazy prostředí PowerShell a změňte konce řádků z Line FEED na LF před nahráním skript do clusteru.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-315">**Before uploading to the cluster**: Use the following PowerShell statements to change the line endings from CRLF to LF before uploading the script to the cluster.</span></span>

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* <span data-ttu-id="1a4cc-316">**Po nahrání do clusteru**: použijte následující příkaz z relace SSH do clusteru se systémem Linux a upravte skript.</span><span class="sxs-lookup"><span data-stu-id="1a4cc-316">**After uploading to the cluster**: Use the following command from an SSH session to the Linux-based cluster to modify the script.</span></span>

    ```bash
    hdfs dfs -get wasb:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasb:///path/to/script.py
    ```

## <a name="next-steps"></a><span data-ttu-id="1a4cc-317">Další kroky</span><span class="sxs-lookup"><span data-stu-id="1a4cc-317">Next Steps</span></span>

* [<span data-ttu-id="1a4cc-318">Naučte se vytvářet clustery HDInsight se systémem Linux</span><span class="sxs-lookup"><span data-stu-id="1a4cc-318">Learn how to create Linux-based HDInsight clusters</span></span>](hdinsight-hadoop-provision-linux-clusters.md)
* [<span data-ttu-id="1a4cc-319">Použití SSH se připojit k HDInsight</span><span class="sxs-lookup"><span data-stu-id="1a4cc-319">Use SSH to connect to HDInsight</span></span>](hdinsight-hadoop-linux-use-ssh-unix.md)
* [<span data-ttu-id="1a4cc-320">Spravovat cluster se systémem Linux pomocí nástroje Ambari</span><span class="sxs-lookup"><span data-stu-id="1a4cc-320">Manage a Linux-based cluster using Ambari</span></span>](hdinsight-hadoop-manage-ambari.md)

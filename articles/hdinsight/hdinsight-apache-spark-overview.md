---
title: "Představujeme Spark v Azure HDInsight | Dokumentace Microsoftu"
description: "Tento článek představuje Spark ve službě HDInsight a různé scénáře, ve kterých můžete použít cluster Sparku ve službě HDInsight."
keywords: "co je apache spark, cluster spark, představujeme spark, spark ve službě hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="9a0ed-104">Představujeme Spark ve službě HDInsight</span><span class="sxs-lookup"><span data-stu-id="9a0ed-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="9a0ed-105">Tento článek obsahuje úvod do Sparku ve službě HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="9a0ed-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> je opensource paralelní framework pro zpracování, který podporuje zpracování v paměti pro zvýšení výkonu velkých objemů dat analytických aplikací.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="9a0ed-107">Cluster Spark v prostředí HDInsight je kompatibilní s úložištěm Azure Storage (WASB) a také se službou Azure Data Lake Store, takže svá stávající data uložená v Azure můžete v tomto clusteru snadno zpracovat.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="9a0ed-108">Když vytvoříte cluster Spark v HDInsight, vytvoříte výpočetní prostředky Azure s nainstalovaným a nakonfigurovaným Sparkem.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="9a0ed-109">Vytvoření clusteru Spark v HDInsight trvá pouze asi deset minut.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="9a0ed-110">Data, která se zpracují, jsou uložená v úložišti Azure Storage nebo ve službě Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="9a0ed-111">Další informace najdete v tématu [Použití Azure Storage s HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="9a0ed-112">**Pokud chcete ve službě HDInsight vytvořit cluster Spark**, přečtěte si téma [Rychlý start: Vytvoření clusteru Spark v HDInsight a spuštění interaktivního dotazu pomocí Jupyteru](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="9a0ed-113">Co je Apache Spark ve službě Azure HDInsight?</span><span class="sxs-lookup"><span data-stu-id="9a0ed-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="9a0ed-114">Clustery Spark v prostředí HDInsight nabízejí plně spravovanou službu Spark.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="9a0ed-115">Tady najdete výhody, které přináší vytvoření clusteru Spark v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="9a0ed-116">Funkce</span><span class="sxs-lookup"><span data-stu-id="9a0ed-116">Feature</span></span> | <span data-ttu-id="9a0ed-117">Popis</span><span class="sxs-lookup"><span data-stu-id="9a0ed-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="9a0ed-118">Snadné vytváření clusterů Spark</span><span class="sxs-lookup"><span data-stu-id="9a0ed-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="9a0ed-119">Během několika minut můžete vytvořit nový cluster Spark v HDInsight pomocí portálu Azure Portal, Azure PowerShellu nebo sady SDK rozhraní .NET HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="9a0ed-120">Viz [Začínáme s clusterem Spark v HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="9a0ed-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="9a0ed-121">Snadné používání</span><span class="sxs-lookup"><span data-stu-id="9a0ed-121">Ease of use</span></span> |<span data-ttu-id="9a0ed-122">Součástí clusteru Spark v prostředí HDInsight jsou poznámkové bloky Jupyter a Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="9a0ed-123">Můžete je použít pro interaktivní zpracování dat a vizualizaci.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="9a0ed-124">Rozhraní REST API</span><span class="sxs-lookup"><span data-stu-id="9a0ed-124">REST APIs</span></span> |<span data-ttu-id="9a0ed-125">Clustery Spark v HDInsight zahrnují [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), server úloh Spart založený na rozhraní REST API, který slouží ke vzdálenému odesílání a monitorování úloh.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="9a0ed-126">Podpora pro Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="9a0ed-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="9a0ed-127">Cluster Spark ve službě HDInsight můžete nakonfigurovat tak, aby používal Azure Data Lake Store jako další úložiště i jako primární úložiště (pouze s clustery HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="9a0ed-128">Další informace o Data Lake Store naleznete v tématu [Přehled o Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="9a0ed-129">Integrace se službami Azure</span><span class="sxs-lookup"><span data-stu-id="9a0ed-129">Integration with Azure services</span></span> |<span data-ttu-id="9a0ed-130">Cluster Spark v HDInsight se dodává s konektorem k Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="9a0ed-131">Zákazníci mohou vytvářet aplikace streamování pomocí Event Hubs navíc ke službě [Kafka](http://kafka.apache.org/), která je již k dispozici jako součást Spark.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="9a0ed-132">Podpora pro R Server</span><span class="sxs-lookup"><span data-stu-id="9a0ed-132">Support for R Server</span></span> | <span data-ttu-id="9a0ed-133">R Server můžete nastavit v clusteru HDInsight Spark ke spuštění distribuovaných R výpočtů s rychlostmi dohodnutými s clusterem Spark.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="9a0ed-134">Další informace naleznete v tématu [Začínáme používat R Server v HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="9a0ed-135">Integrace v prostředí IDE třetích stran</span><span class="sxs-lookup"><span data-stu-id="9a0ed-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="9a0ed-136">Služba HDInsight přináší moduly plug-in pro prostředí IDE, jako je IntelliJ IDEA a Eclipse, díky kterým můžete vytvářet a odesílat aplikace do clusteru Spart v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="9a0ed-137">Další informace najdete v tématu [Použití sady Azure Toolkit pro IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) a [Použití sady Azure Toolkit pro Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="9a0ed-138">Počet souběžných dotazů</span><span class="sxs-lookup"><span data-stu-id="9a0ed-138">Concurrent Queries</span></span> |<span data-ttu-id="9a0ed-139">Clustery Spark v HDInsight podporují souběžné dotazy.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="9a0ed-140">To umožňuje sdílení stejných prostředků clusteru pro více dotazů od jednoho uživatele nebo více dotazů od různých uživatelů a aplikací.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="9a0ed-141">Ukládání do mezipaměti na SSD</span><span class="sxs-lookup"><span data-stu-id="9a0ed-141">Caching on SSDs</span></span> |<span data-ttu-id="9a0ed-142">Data do mezipaměti můžete ukládat volitelně buď do paměti nebo na SSD disky připojené k uzlům clusteru.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="9a0ed-143">Ukládání do paměti poskytuje nejlepší výkon dotazů, ale může být nákladné; ukládání na SSD poskytuje skvělou možnost pro zlepšení výkonu dotazů, aniž by bylo nutné vytvořit cluster velikosti, která je potřeba pro umístění celé datové sady do paměti.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="9a0ed-144">Integrace s nástroji BI</span><span class="sxs-lookup"><span data-stu-id="9a0ed-144">Integration with BI Tools</span></span> |<span data-ttu-id="9a0ed-145">Clustery Spark pro HDInsight nabízí konektory pro nástroje BI, například [Power BI](http://www.powerbi.com/) a [Tableau](http://www.tableau.com/products/desktop) pro analýzu dat.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="9a0ed-146">Předem zavedené knihovny Anaconda</span><span class="sxs-lookup"><span data-stu-id="9a0ed-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="9a0ed-147">Clustery Spark na HDInsight přichází s předinstalovanými knihovnami Anaconda.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="9a0ed-148">[Anaconda](http://docs.continuum.io/anaconda/) poskytuje téměř 200 knihoven pro machine learning, analýzy dat, vizualizace atd.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="9a0ed-149">Škálovatelnost</span><span class="sxs-lookup"><span data-stu-id="9a0ed-149">Scalability</span></span> |<span data-ttu-id="9a0ed-150">Ačkoli můžete určit počet uzlů v clusteru během vytváření, můžete chtít zvětšit nebo zmenšit cluster tak, aby odpovídal pracovnímu vytížení.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="9a0ed-151">Všechny clustery HDInsight umožňují změnit počet uzlů v clusteru.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="9a0ed-152">Navíc clustery Spark můžete vyřadit bez ztráty dat, protože všechna data jsou uložená v Azure Storage nebo ve službě Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="9a0ed-153">Nepřetržitá podpora</span><span class="sxs-lookup"><span data-stu-id="9a0ed-153">24/7 Support</span></span> |<span data-ttu-id="9a0ed-154">Clustery Spark v HDInsight přináší nepřetržitou podporu napříč celou podnikovou sítí a SLA, která zajišťuje 99,9% dostupnost.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="9a0ed-155">Jaké jsou případy použití pro Spark v HDInsight?</span><span class="sxs-lookup"><span data-stu-id="9a0ed-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="9a0ed-156">Clustery Spark v HDInsight podporují následující klíčové scénáře.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="9a0ed-157">Interaktivní analýzu dat a BI</span><span class="sxs-lookup"><span data-stu-id="9a0ed-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="9a0ed-158">Podívejte se na kurz</span><span class="sxs-lookup"><span data-stu-id="9a0ed-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="9a0ed-159">Apache Spark v HDInsight ukládá data do úložiště Azure Storage nebo služby Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="9a0ed-160">Obchodní specialisté a osoby provádějící klíčová rozhodnutí analyzují a vytváří z těchto dat sestavy a používají Microsoft Power BI pro vytváření interaktivních sestav z analyzovaných dat.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="9a0ed-161">Analytici mohou začínat z nestrukturovaných / částečně strukturovaných dat v úložišti clusteru, definovat schéma pro data s využitím poznámkových bloků a následně vytvořit modely dat pomocí Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="9a0ed-162">Clustery Spark v HDInsight podporují také různé nástroje třetích stran pro BI, například Tableau. Představují tak ideální platformu pro analytiky dat, obchodní specialisty a osoby provádějící klíčová rozhodnutí.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="9a0ed-163">Spark Machine Learning</span><span class="sxs-lookup"><span data-stu-id="9a0ed-163">Spark Machine Learning</span></span>
[<span data-ttu-id="9a0ed-164">Podívejte se na kurz: předpovídání teplot sestavení pomocí dat HVAC</span><span class="sxs-lookup"><span data-stu-id="9a0ed-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="9a0ed-165">Podívejte se na kurz: předpovídání výsledků kontroly potravin</span><span class="sxs-lookup"><span data-stu-id="9a0ed-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="9a0ed-166">Systém Apache Spark je vybavený knihovnou [MLlib](http://spark.apache.org/mllib/) pro strojové učení, jejímž základem je Spark a kterou můžete používat z clusteru Spark v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="9a0ed-167">Cluster Spark v HDInsight obsahuje Anacondu, distribuci jazyka Python s různými balíčky pro strojové učení.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="9a0ed-168">Spojte tyto možnosti s vestavěnou podporou pro poznámkové bloky Jupyter a Zeppelin a máte nejmodernější prostředí pro tvorbu machine learning aplikací.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="9a0ed-169">Vysílání datových proudů a analýza dat v reálném čase ve Sparku</span><span class="sxs-lookup"><span data-stu-id="9a0ed-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="9a0ed-170">Podívejte se na kurz</span><span class="sxs-lookup"><span data-stu-id="9a0ed-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="9a0ed-171">Clustery Spark v HDInsight nabízí bohatou podporu pro vytváření řešení pro analýzu v reálném čase.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="9a0ed-172">Zatímco Spark již obsahuje konektory pro načítání dat z mnoha zdrojů, například soketů Kafka, Flume, Twitter, ZeroMQ nebo TCP, Spark v HDInsight přidává prvotřídní podporu pro příjem dat z Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="9a0ed-173">Event Hubs je nejpoužívanější službou řazení front v Azure.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="9a0ed-174">Díky připravené podpoře pro službu Event Hubs představují clustery Spark v HDInsight ideální platformu pro vytvoření kanálu k analýze dat v reálném čase.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="9a0ed-175"><a name="next-steps"></a>Jaké součásti jsou zahrnuté v clusteru Spark?</span><span class="sxs-lookup"><span data-stu-id="9a0ed-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="9a0ed-176">Součástí clusterů Spark v HDInsight jsou následující komponenty, které jsou v nich k dispozici ve výchozím nastavení.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="9a0ed-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="9a0ed-178">Obsahuje Spark Core, Spark SQL, rozhraní API pro vysílání datového proudu Spark, GraphX a MLlib.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="9a0ed-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="9a0ed-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="9a0ed-180">Livy</span><span class="sxs-lookup"><span data-stu-id="9a0ed-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="9a0ed-181">Poznámkový blok Jupyter</span><span class="sxs-lookup"><span data-stu-id="9a0ed-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="9a0ed-182">Poznámkový blok Zeppelin</span><span class="sxs-lookup"><span data-stu-id="9a0ed-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="9a0ed-183">Clustery Spark v HDInsight také poskytují [ovladač ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) pro připojení ke clusterům Spark v HDInsight z nástrojů BI, například Microsoft Power BI a Tableau.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="9a0ed-184">Kde mám začít?</span><span class="sxs-lookup"><span data-stu-id="9a0ed-184">Where do I start?</span></span>
<span data-ttu-id="9a0ed-185">Začněte tak, že vytvoříte cluster Spark v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9a0ed-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="9a0ed-186">Přečtěte si téma [Rychlý začátek: Vytvoření clusteru Spark v HDInsight v Linuxu a spuštění interaktivního dotazu pomocí Jupyteru](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="9a0ed-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="9a0ed-187">Další kroky</span><span class="sxs-lookup"><span data-stu-id="9a0ed-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="9a0ed-188">Scénáře</span><span class="sxs-lookup"><span data-stu-id="9a0ed-188">Scenarios</span></span>
* [<span data-ttu-id="9a0ed-189">Spark s BI: Provádějte interaktivní analýzy dat pomocí Sparku v HDInsight pomocí nástrojů BI</span><span class="sxs-lookup"><span data-stu-id="9a0ed-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="9a0ed-190">Spark s Machine Learning: Používejte Spark v HDInsight pro analýzu teploty v budově pomocí dat HVAC</span><span class="sxs-lookup"><span data-stu-id="9a0ed-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="9a0ed-191">Spark s Machine Learning: Používejte Spark v HDInsight k předpovědím výsledků kontrol potravin</span><span class="sxs-lookup"><span data-stu-id="9a0ed-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="9a0ed-192">Datové proudy Spark: Používejte Spark v HDInsight pro sestavení aplikací datových proudů v reálném čase</span><span class="sxs-lookup"><span data-stu-id="9a0ed-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="9a0ed-193">Analýza protokolu webu pomocí Sparku v HDInsight</span><span class="sxs-lookup"><span data-stu-id="9a0ed-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="9a0ed-194">Vytvoření a spouštění aplikací</span><span class="sxs-lookup"><span data-stu-id="9a0ed-194">Create and run applications</span></span>
* [<span data-ttu-id="9a0ed-195">Vytvoření samostatné aplikace pomocí Scala</span><span class="sxs-lookup"><span data-stu-id="9a0ed-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="9a0ed-196">Vzdálené spouštění úloh na clusteru Sparku pomocí Livy</span><span class="sxs-lookup"><span data-stu-id="9a0ed-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="9a0ed-197">Nástroje a rozšíření</span><span class="sxs-lookup"><span data-stu-id="9a0ed-197">Tools and extensions</span></span>
* [<span data-ttu-id="9a0ed-198">Modul plug-in nástroje HDInsight pro IntelliJ IDEA pro vytvoření a odesílání aplikací Spark Scala</span><span class="sxs-lookup"><span data-stu-id="9a0ed-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="9a0ed-199">Použití modulu plug-in nástroje HDInsight pro IntelliJ IDEA pro vzdálené ladění aplikací Spark</span><span class="sxs-lookup"><span data-stu-id="9a0ed-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="9a0ed-200">Použití poznámkových bloků Zeppelin s clusterem Sparku v HDInsight</span><span class="sxs-lookup"><span data-stu-id="9a0ed-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="9a0ed-201">Jádra dostupná pro poznámkový blok Jupyter v clusteru Sparku pro HDInsight</span><span class="sxs-lookup"><span data-stu-id="9a0ed-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="9a0ed-202">Použití externích balíčků s poznámkovými bloky Jupyter</span><span class="sxs-lookup"><span data-stu-id="9a0ed-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="9a0ed-203">Instalace Jupyteru do počítače a připojení ke clusteru HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="9a0ed-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="9a0ed-204">Správa prostředků</span><span class="sxs-lookup"><span data-stu-id="9a0ed-204">Manage resources</span></span>
* [<span data-ttu-id="9a0ed-205">Správa prostředků v clusteru Apache Spark v Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="9a0ed-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="9a0ed-206">Sledování a ladění úloh spuštěných v clusteru Apache Spark v HDInsight</span><span class="sxs-lookup"><span data-stu-id="9a0ed-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="9a0ed-207">[Známé problémy systému Apache Spark v Azure HDInsight](hdinsight-apache-spark-known-issues.md)</span><span class="sxs-lookup"><span data-stu-id="9a0ed-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>

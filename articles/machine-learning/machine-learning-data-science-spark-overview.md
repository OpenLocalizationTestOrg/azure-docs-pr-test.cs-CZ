---
title: "Přehled vědecké zpracování dat pomocí Spark v Azure HDInsight | Microsoft Docs"
description: "Sada nástrojů Spark MLlib přináší značné strojové učení modelování funkcí, které distribuovaném prostředí HDInsight."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="fd65b-103">Přehled vědecké zpracování dat pomocí Spark v Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd65b-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="fd65b-104">Tato sada témata ukazuje způsob použití HDInsight Spark pro dokončení běžné úkoly vědecké účely data jako přijímání dat, funkce analýzy, modelování a vyhodnocení modelu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="fd65b-105">Data použitá je ukázka 2013 NYC taxíkem služební cestě a tarif datové sady.</span><span class="sxs-lookup"><span data-stu-id="fd65b-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="fd65b-106">Modely vytvářeny zahrnují logistic a lineární regrese, náhodné doménové struktury a přechodu boosted stromy.</span><span class="sxs-lookup"><span data-stu-id="fd65b-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="fd65b-107">Témata také ukazují, jak k uložení těchto modelů v Azure blob storage (WASB) a jak stanovení skóre a vyhodnotit jejich prediktivní výkonu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="fd65b-108">Pokročilejší témata zahrnují, jak může být modely Trénink pomocí sweeping křížové ověření a technologie hyper parametr.</span><span class="sxs-lookup"><span data-stu-id="fd65b-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="fd65b-109">Toto přehledové téma také odkazuje na témata, která popisují, jak nastavit, které potřebujete k dokončení kroků v návody zadaný cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="fd65b-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="fd65b-110">Spark a MLlib</span><span class="sxs-lookup"><span data-stu-id="fd65b-110">Spark and MLlib</span></span>
<span data-ttu-id="fd65b-111">[Spark](http://spark.apache.org/) zpracovává představuje rozhraní open-source paralelní zpracování, které podporuje v paměti pro zvýšení výkonu velkých objemů dat analytických aplikací.</span><span class="sxs-lookup"><span data-stu-id="fd65b-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="fd65b-112">Modul zpracování Spark je vytvořené pro rychlost, snadné použití a sofistikované analytics.</span><span class="sxs-lookup"><span data-stu-id="fd65b-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="fd65b-113">Možnosti v paměti distribuované výpočtů Spark díky správnou volbu pro iterativní algoritmy použité v machine learning a grafů výpočty.</span><span class="sxs-lookup"><span data-stu-id="fd65b-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="fd65b-114">[MLlib](http://spark.apache.org/mllib/) je modelování Spark škálovatelné machine learning knihovny, která přináší algoritmické funkce, které tento distribuovaném prostředí.</span><span class="sxs-lookup"><span data-stu-id="fd65b-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="fd65b-115">Spark v HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd65b-115">HDInsight Spark</span></span>
<span data-ttu-id="fd65b-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) je nabídku Azure hostované Spark open source.</span><span class="sxs-lookup"><span data-stu-id="fd65b-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="fd65b-117">Zahrnuje taky podporu **poznámkové bloky Jupyter PySpark** na clusteru Spark, která se může spustit interaktivních dotazů Spark SQL pro transformaci, filtrování a vizualizace dat uložených v Azure BLOB (WASB).</span><span class="sxs-lookup"><span data-stu-id="fd65b-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="fd65b-118">PySpark je rozhraní API jazyka Python pro Spark.</span><span class="sxs-lookup"><span data-stu-id="fd65b-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="fd65b-119">Fragmenty kódu, které poskytují řešení a zobrazit relevantní pozemků k vizualizaci dat zde spustit v poznámkové bloky Jupyter nainstalovat na clusteru Spark.</span><span class="sxs-lookup"><span data-stu-id="fd65b-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="fd65b-120">Modelování kroky v těchto tématech obsahovat kód, který ukazuje, jak cvičení, hodnocení, uložit a používat každý typ modelu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="fd65b-121">Instalační program: Clustery Spark a poznámkové bloky Jupyter</span><span class="sxs-lookup"><span data-stu-id="fd65b-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="fd65b-122">Kroky instalace a kódu jsou uvedené v tomto názorném postupu pro používání HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="fd65b-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="fd65b-123">Ale poznámkové bloky Jupyter jsou k dispozici pro clustery HDInsight Spark 1.6 a Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="fd65b-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="fd65b-124">Popis poznámkových bloků a odkazy na ně jsou součástí [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) úložiště Githubu, které je obsahují.</span><span class="sxs-lookup"><span data-stu-id="fd65b-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="fd65b-125">Kromě toho kód sem a v propojených poznámkových bloků je obecný a by měla fungovat v jakémkoliv clusteru Spark.</span><span class="sxs-lookup"><span data-stu-id="fd65b-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="fd65b-126">Pokud nepoužíváte HDInsight Spark, může být mírně lišit od co je tady uvedené kroky nastavení a Správa clusteru.</span><span class="sxs-lookup"><span data-stu-id="fd65b-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="fd65b-127">Pro větší pohodlí si zde jsou uvedeny odkazy na poznámkové bloky Jupyter pro Spark 1.6 (musí být spuštěny v jádra pySpark Poznámkový blok Jupyter serveru) a 2.0 Spark (Chcete-li spustit v jádru pySpark3 Poznámkový blok Jupyter serveru):</span><span class="sxs-lookup"><span data-stu-id="fd65b-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="fd65b-128">Spark 1.6 poznámkových bloků</span><span class="sxs-lookup"><span data-stu-id="fd65b-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="fd65b-129">Tyto poznámkových bloků se mají spustit v jádra pySpark serveru poznámkového bloku Jupyter.</span><span class="sxs-lookup"><span data-stu-id="fd65b-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="fd65b-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): poskytuje informace o tom, jak provést zkoumání dat, modelování a vyhodnocování se několik různých algoritmů.</span><span class="sxs-lookup"><span data-stu-id="fd65b-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="fd65b-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): obsahuje témata v poznámkovém bloku #1 a modelu vývoj pomocí hyperparameter ladění a křížové ověření.</span><span class="sxs-lookup"><span data-stu-id="fd65b-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="fd65b-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): ukazuje, jak zprovoznit model uložené v clusterech prostředí HDInsight pomocí Pythonu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="fd65b-133">Spark 2.0 poznámkových bloků</span><span class="sxs-lookup"><span data-stu-id="fd65b-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="fd65b-134">Tyto poznámkových bloků se mají spustit v jádru pySpark3 serveru poznámkového bloku Jupyter.</span><span class="sxs-lookup"><span data-stu-id="fd65b-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="fd65b-135">[Spark2.0-pySpark3-Machine-Learning-data-Science-Spark-Advanced-data-Exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Tento soubor obsahuje informace o tom, jak provést zkoumání dat, modelování a vyhodnocování v rámci Spark 2.0 clusterů pomocí cesty NYC taxíkem a tarif sady dat popsané [zde](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="fd65b-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="fd65b-136">Tento poznámkový blok, může být to dobrý výchozí bod pro zkoumání rychle kód, který jsme připravili pro Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="fd65b-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="fd65b-137">Podrobnější Poznámkový blok analyzuje data taxíkem NYC, naleznete další poznámkového bloku v tomto seznamu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="fd65b-138">Najdete v poznámkách k následující tento seznam porovnávající tyto poznámkových bloků.</span><span class="sxs-lookup"><span data-stu-id="fd65b-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="fd65b-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): Tento soubor ukazuje, jak provést data wrangling (Spark SQL a dataframe operations), zkoumání, modelování a vyhodnocování pomocí cesty NYC taxíkem a tarif sady dat popsané [zde](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="fd65b-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="fd65b-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): Tento soubor ukazuje, jak provést data wrangling (Spark SQL a dataframe operations), zkoumání, modelování a vyhodnocování pomocí známých letecká společnost na čas odeslání datové sady z 2011 a 2012.</span><span class="sxs-lookup"><span data-stu-id="fd65b-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="fd65b-141">Jsme integrované letecká společnost datovou sadu s daty počasí letiště (např. větru, teploty, výška atd.) před modelování, takže tyto funkce počasí můžou být součástí modelu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="fd65b-142">Datová sada letecká společnost byl přidán do poznámkových bloků Spark 2.0 abychom vám lépe předvedli použití algoritmů klasifikace.</span><span class="sxs-lookup"><span data-stu-id="fd65b-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="fd65b-143">V následujících tématech informace o letecká společnost v době odeslání datovou sadu a počasí datové sady:</span><span class="sxs-lookup"><span data-stu-id="fd65b-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="fd65b-144">Letecká společnost na čas odeslání dat: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="fd65b-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="fd65b-145">Data o počasí letiště: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="fd65b-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="fd65b-146">Poznámkové bloky Spark 2.0 na NYC taxíkem a letecká společnost letu zpoždění-sady dat může trvat 10 minut nebo déle ke spuštění (v závislosti na velikosti vašeho clusteru HDI).</span><span class="sxs-lookup"><span data-stu-id="fd65b-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="fd65b-147">První poznámkového bloku v seznamu nahoře zobrazí mnoho aspektů zkoumání dat, vizualizace a ML školení v poznámkovém bloku, který zabere to méně času se spouští s nižší vzorkovat NYC datové sady, ve kterém byly soubory taxíkem a tarif předem připojený k modelu: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) tento poznámkový blok trvá mnohem kratší dobu dokončit (v minutách 2-3) a může být dobrou výchozí bod pro rychle prohlížení kódu uvádíme Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="fd65b-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="fd65b-148">Pokyny v operationalization Spark 2.0 model a model spotřeby pro vyhodnocování najdete v tématu [Spark 1.6 dokumentu o spotřebě](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) příklad osnovy kroky.</span><span class="sxs-lookup"><span data-stu-id="fd65b-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="fd65b-149">Pokud chcete použít tento na Spark 2.0, nahraďte soubor kód Python s [tento soubor](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="fd65b-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="fd65b-150">Požadavky</span><span class="sxs-lookup"><span data-stu-id="fd65b-150">Prerequisites</span></span>
<span data-ttu-id="fd65b-151">Následující postupy se vztahují k Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="fd65b-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="fd65b-152">Pro verzi Spark 2.0 použijte poznámkových bloků popsané a propojené s dříve.</span><span class="sxs-lookup"><span data-stu-id="fd65b-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="fd65b-153">1 musíte mít předplatné Azure.</span><span class="sxs-lookup"><span data-stu-id="fd65b-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="fd65b-154">Pokud není již nemáte, přečtěte si téma [získání bezplatné zkušební verze Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="fd65b-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="fd65b-155">2. budete potřebovat cluster Spark 1.6 k dokončení tohoto názorného postupu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="fd65b-156">Pokud chcete vytvořit, postupujte podle pokynů uvedených v [Začínáme: Vytvořte Apache Spark v Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="fd65b-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="fd65b-157">Typ clusteru a verze je určené z **vybrat typ clusteru** nabídky.</span><span class="sxs-lookup"><span data-stu-id="fd65b-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Konfigurace clusteru](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="fd65b-159">Téma, které ukazuje, jak k dokončení úloh pro proces vědecké účely začátku do konce dat použít Scala spíše než Python, najdete v článku [vědecké zpracování dat pomocí Spark v Azure Scala](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="fd65b-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="fd65b-160">Data taxíkem NYC 2013</span><span class="sxs-lookup"><span data-stu-id="fd65b-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="fd65b-161">Data NYC taxíkem cesty je přibližně 20 GB komprimované hodnot oddělených čárkami (CSV) souborů (nekomprimovaným ~ 48 GB), skládající se z více než 173 milionů jednotlivých cest a tarify placené pro každou cestu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="fd65b-162">Každý záznam cestě zahrnuje vybrat nahoru a odkládací umístění a čas, číslo licence anonymizovaná hackerský (ovladač) a číslo Medailon (taxi na jedinečné id).</span><span class="sxs-lookup"><span data-stu-id="fd65b-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="fd65b-163">Data obsahuje všechny služebních cest v roku 2013 a je dostupné pro každý měsíc následující dvě datové sady:</span><span class="sxs-lookup"><span data-stu-id="fd65b-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="fd65b-164">CSV soubory 'trip_data' obsahují podrobnosti o cestě, například na počtu cestujících, vyzvednutí a body dropoff dojít doba trvání a délka cesty.</span><span class="sxs-lookup"><span data-stu-id="fd65b-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="fd65b-165">Tady je několik ukázkových záznamů:</span><span class="sxs-lookup"><span data-stu-id="fd65b-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="fd65b-166">CSV soubory 'trip_fare' obsahují podrobnosti o tarif placené pro každou cestu, například typ platby, velikost tarif, příplatek a daně, tipy a mýtné a celkovou velikost placené.</span><span class="sxs-lookup"><span data-stu-id="fd65b-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="fd65b-167">Tady je několik ukázkových záznamů:</span><span class="sxs-lookup"><span data-stu-id="fd65b-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="fd65b-168">Jsme prováděné ukázku 0,1 % těchto souborů a připojené k cesta\_dat a cesty\_jízdenky CVS soubory do jedné datové sady sloužící jako vstupní datové sady pro účely tohoto postupu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="fd65b-169">Jedinečný klíč pro připojení k cestě\_dat a cesty\_tarif se skládá z pole: medailonu, hackerský\_licence a vyzvednutí\_data a času.</span><span class="sxs-lookup"><span data-stu-id="fd65b-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="fd65b-170">Každý záznam datová sada obsahuje následující atributy představující NYC taxíkem cesty:</span><span class="sxs-lookup"><span data-stu-id="fd65b-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="fd65b-171">Pole</span><span class="sxs-lookup"><span data-stu-id="fd65b-171">Field</span></span> | <span data-ttu-id="fd65b-172">Stručný popis</span><span class="sxs-lookup"><span data-stu-id="fd65b-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="fd65b-173">Medailon</span><span class="sxs-lookup"><span data-stu-id="fd65b-173">medallion</span></span> |<span data-ttu-id="fd65b-174">Anonymizovaná taxíkem Medailon (taxi jedinečné id)</span><span class="sxs-lookup"><span data-stu-id="fd65b-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="fd65b-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="fd65b-175">hack_license</span></span> |<span data-ttu-id="fd65b-176">Anonymizovaná číslo licence Hackney znaků CR</span><span class="sxs-lookup"><span data-stu-id="fd65b-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="fd65b-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="fd65b-177">vendor_id</span></span> |<span data-ttu-id="fd65b-178">Id dodavatele taxíkem</span><span class="sxs-lookup"><span data-stu-id="fd65b-178">Taxi vendor id</span></span> |
| <span data-ttu-id="fd65b-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="fd65b-179">rate_code</span></span> |<span data-ttu-id="fd65b-180">Míra taxíkem NYC tarif</span><span class="sxs-lookup"><span data-stu-id="fd65b-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="fd65b-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="fd65b-181">store_and_fwd_flag</span></span> |<span data-ttu-id="fd65b-182">Úložiště a předat dál příznak</span><span class="sxs-lookup"><span data-stu-id="fd65b-182">Store and forward flag</span></span> |
| <span data-ttu-id="fd65b-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="fd65b-183">pickup_datetime</span></span> |<span data-ttu-id="fd65b-184">Vyzvednutí datum a čas</span><span class="sxs-lookup"><span data-stu-id="fd65b-184">Pick up date & time</span></span> |
| <span data-ttu-id="fd65b-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="fd65b-185">dropoff_datetime</span></span> |<span data-ttu-id="fd65b-186">Dropoff datum a čas</span><span class="sxs-lookup"><span data-stu-id="fd65b-186">Dropoff date & time</span></span> |
| <span data-ttu-id="fd65b-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="fd65b-187">pickup_hour</span></span> |<span data-ttu-id="fd65b-188">Vyzvedne, až hodinu</span><span class="sxs-lookup"><span data-stu-id="fd65b-188">Pick up hour</span></span> |
| <span data-ttu-id="fd65b-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="fd65b-189">pickup_week</span></span> |<span data-ttu-id="fd65b-190">Vyzvednutí týden v roce</span><span class="sxs-lookup"><span data-stu-id="fd65b-190">Pick up week of the year</span></span> |
| <span data-ttu-id="fd65b-191">den v týdnu</span><span class="sxs-lookup"><span data-stu-id="fd65b-191">weekday</span></span> |<span data-ttu-id="fd65b-192">Den v týdnu (rozsah 1-7)</span><span class="sxs-lookup"><span data-stu-id="fd65b-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="fd65b-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="fd65b-193">passenger_count</span></span> |<span data-ttu-id="fd65b-194">Počet cestujících v cestě taxíkem</span><span class="sxs-lookup"><span data-stu-id="fd65b-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="fd65b-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="fd65b-195">trip_time_in_secs</span></span> |<span data-ttu-id="fd65b-196">Času v sekundách</span><span class="sxs-lookup"><span data-stu-id="fd65b-196">Trip time in seconds</span></span> |
| <span data-ttu-id="fd65b-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="fd65b-197">trip_distance</span></span> |<span data-ttu-id="fd65b-198">Vzdálenost služební cestě, kterou urazit v miles</span><span class="sxs-lookup"><span data-stu-id="fd65b-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="fd65b-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="fd65b-199">pickup_longitude</span></span> |<span data-ttu-id="fd65b-200">Vyzvednutí zeměpisná délka</span><span class="sxs-lookup"><span data-stu-id="fd65b-200">Pick up longitude</span></span> |
| <span data-ttu-id="fd65b-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="fd65b-201">pickup_latitude</span></span> |<span data-ttu-id="fd65b-202">Vyzvednutí zeměpisná šířka</span><span class="sxs-lookup"><span data-stu-id="fd65b-202">Pick up latitude</span></span> |
| <span data-ttu-id="fd65b-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="fd65b-203">dropoff_longitude</span></span> |<span data-ttu-id="fd65b-204">Zeměpisná délka Dropoff</span><span class="sxs-lookup"><span data-stu-id="fd65b-204">Dropoff longitude</span></span> |
| <span data-ttu-id="fd65b-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="fd65b-205">dropoff_latitude</span></span> |<span data-ttu-id="fd65b-206">Zeměpisná šířka Dropoff</span><span class="sxs-lookup"><span data-stu-id="fd65b-206">Dropoff latitude</span></span> |
| <span data-ttu-id="fd65b-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="fd65b-207">direct_distance</span></span> |<span data-ttu-id="fd65b-208">Přímá vzdálenost mezi vybrat nahoru a dropoff umístění</span><span class="sxs-lookup"><span data-stu-id="fd65b-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="fd65b-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="fd65b-209">payment_type</span></span> |<span data-ttu-id="fd65b-210">Typ platby (certifikační autority, platební karty atd.)</span><span class="sxs-lookup"><span data-stu-id="fd65b-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="fd65b-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="fd65b-211">fare_amount</span></span> |<span data-ttu-id="fd65b-212">Tarif částka v</span><span class="sxs-lookup"><span data-stu-id="fd65b-212">Fare amount in</span></span> |
| <span data-ttu-id="fd65b-213">Příplatek.</span><span class="sxs-lookup"><span data-stu-id="fd65b-213">surcharge</span></span> |<span data-ttu-id="fd65b-214">Příplatek.</span><span class="sxs-lookup"><span data-stu-id="fd65b-214">Surcharge</span></span> |
| <span data-ttu-id="fd65b-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="fd65b-215">mta_tax</span></span> |<span data-ttu-id="fd65b-216">Daň prostředí MTA</span><span class="sxs-lookup"><span data-stu-id="fd65b-216">Mta tax</span></span> |
| <span data-ttu-id="fd65b-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="fd65b-217">tip_amount</span></span> |<span data-ttu-id="fd65b-218">Velikost tipu</span><span class="sxs-lookup"><span data-stu-id="fd65b-218">Tip amount</span></span> |
| <span data-ttu-id="fd65b-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="fd65b-219">tolls_amount</span></span> |<span data-ttu-id="fd65b-220">Velikost mýtné</span><span class="sxs-lookup"><span data-stu-id="fd65b-220">Tolls amount</span></span> |
| <span data-ttu-id="fd65b-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="fd65b-221">total_amount</span></span> |<span data-ttu-id="fd65b-222">Celková velikost</span><span class="sxs-lookup"><span data-stu-id="fd65b-222">Total amount</span></span> |
| <span data-ttu-id="fd65b-223">vysypávány</span><span class="sxs-lookup"><span data-stu-id="fd65b-223">tipped</span></span> |<span data-ttu-id="fd65b-224">Šikmý (0 nebo 1 – Ne nebo Ano)</span><span class="sxs-lookup"><span data-stu-id="fd65b-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="fd65b-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="fd65b-225">tip_class</span></span> |<span data-ttu-id="fd65b-226">Tip – třída (0: 0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > 20)</span><span class="sxs-lookup"><span data-stu-id="fd65b-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="fd65b-227">Spustí kód z poznámkového bloku Jupyter v clusteru Spark</span><span class="sxs-lookup"><span data-stu-id="fd65b-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="fd65b-228">Můžete spustit poznámkového bloku Jupyter z portálu Azure.</span><span class="sxs-lookup"><span data-stu-id="fd65b-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="fd65b-229">Najít váš cluster Spark na řídicím panelu a klikněte na něj na stránce Správa zadejte pro váš cluster.</span><span class="sxs-lookup"><span data-stu-id="fd65b-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="fd65b-230">Otevřete Poznámkový blok přidruženého k clusteru Spark klikněte na **řídicí panely clusteru** -> **Poznámkový blok Jupyter** .</span><span class="sxs-lookup"><span data-stu-id="fd65b-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Řídicí panely clusteru](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="fd65b-232">Můžete také vyhledat ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** pro přístup k Jupyter Notebooks.</span><span class="sxs-lookup"><span data-stu-id="fd65b-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="fd65b-233">Nahraďte název vlastní cluster CLUSTERNAME součástí tuto adresu URL.</span><span class="sxs-lookup"><span data-stu-id="fd65b-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="fd65b-234">Potřebujete heslo pro váš účet správce pro přístup k poznámkových bloků.</span><span class="sxs-lookup"><span data-stu-id="fd65b-234">You need the password for your admin account to access the notebooks.</span></span>

![Procházet poznámkové bloky Jupyter](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="fd65b-236">Vyberte PySpark zobrazíte adresář, který obsahuje několik příkladů předem zabalené poznámkových bloků, které používají rozhraní API PySpark. Jsou k dispozici v poznámkových bloků, které obsahují ukázky kódu pro tuto sadu Spark tématu [Githubu](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="fd65b-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="fd65b-237">Můžete nahrát poznámkových bloků přímo z [Githubu](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) server Poznámkový blok Jupyter v clusteru Spark.</span><span class="sxs-lookup"><span data-stu-id="fd65b-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="fd65b-238">Na domovské stránce vaší Jupyter, klikněte na **nahrát** tlačítko na pravou část obrazovky.</span><span class="sxs-lookup"><span data-stu-id="fd65b-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="fd65b-239">Otevře se Průzkumník souborů.</span><span class="sxs-lookup"><span data-stu-id="fd65b-239">It opens a file explorer.</span></span> <span data-ttu-id="fd65b-240">Zde můžete vložte adresu URL GitHub (nezpracovaná obsah) poznámkového bloku a klikněte na tlačítko **otevřete**.</span><span class="sxs-lookup"><span data-stu-id="fd65b-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="fd65b-241">Zobrazí název souboru v seznamu souborů Jupyter s **nahrát** tlačítko znovu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="fd65b-242">Klikněte na tlačítko to **nahrát** tlačítko.</span><span class="sxs-lookup"><span data-stu-id="fd65b-242">Click this **Upload** button.</span></span> <span data-ttu-id="fd65b-243">Nyní jste importovali poznámkového bloku.</span><span class="sxs-lookup"><span data-stu-id="fd65b-243">Now you have imported the notebook.</span></span> <span data-ttu-id="fd65b-244">Opakováním těchto kroků nahrajte jiných poznámkových bloků z tohoto návodu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="fd65b-245">Můžete kliknout pravým tlačítkem odkazů na prohlížeč a vyberte **Kopírovat odkaz** k získání adresy URL githubu nezpracovaná obsahu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="fd65b-246">Tuto adresu URL můžete vložit do Jupyter nahrát soubor explorer dialogových oken.</span><span class="sxs-lookup"><span data-stu-id="fd65b-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="fd65b-247">Nyní můžete:</span><span class="sxs-lookup"><span data-stu-id="fd65b-247">Now you can:</span></span>

* <span data-ttu-id="fd65b-248">Zobrazit kód klikněte poznámkového bloku.</span><span class="sxs-lookup"><span data-stu-id="fd65b-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="fd65b-249">Spusťte jednotlivých buněk tak, že stisknete **zadejte SHIFT**.</span><span class="sxs-lookup"><span data-stu-id="fd65b-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="fd65b-250">Kliknutím na spustit celý poznámkový blok **buňky** -> **spustit**.</span><span class="sxs-lookup"><span data-stu-id="fd65b-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="fd65b-251">Použijte automatické vizualizace dotazů.</span><span class="sxs-lookup"><span data-stu-id="fd65b-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="fd65b-252">Jádra PySpark automaticky vizualizuje výstup dotazy SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="fd65b-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="fd65b-253">Nyní máte možnost vybrat z několika různých typů vizualizace (tabulky, kruhový, řádku, oblasti nebo panelu) pomocí **typ** tlačítka nabídky v poznámkovém bloku:</span><span class="sxs-lookup"><span data-stu-id="fd65b-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Křivka ROC logistic regression pro obecný přístup](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="fd65b-255">Co dále?</span><span class="sxs-lookup"><span data-stu-id="fd65b-255">What's next?</span></span>
<span data-ttu-id="fd65b-256">Teď, když jsou vytvořeny pomocí clusteru služby HDInsight Spark a odeslali Jupyter notebooks, jste připraveni na témata, které odpovídají tři poznámkových bloků PySpark spolupracovat.</span><span class="sxs-lookup"><span data-stu-id="fd65b-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="fd65b-257">Ukazují jak prozkoumat vaše data a jak vytvářet a využívat modelů.</span><span class="sxs-lookup"><span data-stu-id="fd65b-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="fd65b-258">Poznámkový blok pro zkoumání a modelování pokročilé data ukazuje, jak křížového ověřování, technologie hyper parametr komínů, zahrnout a vyhodnocení modelu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="fd65b-259">**Zkoumání dat a modelování pomocí Spark:** prozkoumat datovou sadu a vytvářet, stanovení skóre a vyhodnotit strojového učení modely projdete [vytvořit binární klasifikace a regrese modely dat pomocí Spark MLlib sady toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) tématu.</span><span class="sxs-lookup"><span data-stu-id="fd65b-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="fd65b-260">**Model spotřeby:** další postupy skóre pro klasifikaci a regrese modely, které jsou vytvořené v tomto tématu najdete v tématu [skóre a vyhodnocení modelů learning vytvořené Spark počítač](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="fd65b-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="fd65b-261">**Křížové ověření a hyperparameter (vymetání) komínů**: najdete v části [Advanced zkoumání dat a modelování pomocí Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) na tom, jak může být modely Trénink pomocí (vymetání) křížové ověření a technologie hyper parametr komínů</span><span class="sxs-lookup"><span data-stu-id="fd65b-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>


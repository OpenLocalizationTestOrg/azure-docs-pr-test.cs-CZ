---
title: "aaaAzure Data Lake Store Spark výkonu ladění pokyny pro | Microsoft Docs"
description: "Ladění pravidla výkonu Spark Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: da1d172e9cb1199ad95605ea1718e78559f79650
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 10/06/2017
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="3a9c9-103">Pokyny pro Spark v HDInsight a Azure Data Lake Store optimalizace výkonu</span><span class="sxs-lookup"><span data-stu-id="3a9c9-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="3a9c9-104">Při ladění výkonu na Spark, je nutné tooconsider hello počet aplikací, které budou spuštěny v clusteru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-104">When tuning performance on Spark, you need tooconsider hello number of apps that will be running on your cluster.</span></span>  <span data-ttu-id="3a9c9-105">Ve výchozím nastavení, můžete spustit 4 aplikace souběžně na clusteru HDI (Poznámka: hello výchozí nastavení je subjektu toochange).</span><span class="sxs-lookup"><span data-stu-id="3a9c9-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: hello default setting is subject toochange).</span></span>  <span data-ttu-id="3a9c9-106">Můžete rozhodnout toouse méně aplikace, můžete přepsat výchozí nastavení hello a použít více hello clusteru pro tyto aplikace.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-106">You may decide toouse fewer apps so you can override hello default settings and use more of hello cluster for those apps.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="3a9c9-107">Požadavky</span><span class="sxs-lookup"><span data-stu-id="3a9c9-107">Prerequisites</span></span>

* <span data-ttu-id="3a9c9-108">**Předplatné Azure**.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-108">**An Azure subscription**.</span></span> <span data-ttu-id="3a9c9-109">Viz [Získání bezplatné zkušební verze Azure](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="3a9c9-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="3a9c9-110">**Účet Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="3a9c9-111">Návod, jak jeden, viz toocreate [Začínáme s Azure Data Lake Store](data-lake-store-get-started-portal.md)</span><span class="sxs-lookup"><span data-stu-id="3a9c9-111">For instructions on how toocreate one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span></span>
* <span data-ttu-id="3a9c9-112">**Azure HDInsight cluster** s tooa přístup k účtu Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-112">**Azure HDInsight cluster** with access tooa Data Lake Store account.</span></span> <span data-ttu-id="3a9c9-113">V tématu [vytvoření clusteru HDInsight s Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="3a9c9-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="3a9c9-114">Ujistěte se, že povolení vzdálené plochy pro hello clusteru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-114">Make sure you enable Remote Desktop for hello cluster.</span></span>
* <span data-ttu-id="3a9c9-115">**Spuštění clusteru Spark v Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-115">**Running Spark cluster on Azure Data Lake Store**.</span></span>  <span data-ttu-id="3a9c9-116">Další informace najdete v tématu [data tooanalyze clusteru používejte HDInsight Spark v Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span><span class="sxs-lookup"><span data-stu-id="3a9c9-116">For more information, see [Use HDInsight Spark cluster tooanalyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span></span>
* <span data-ttu-id="3a9c9-117">**Ladění pokyny na ADLS výkonu**.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-117">**Performance tuning guidelines on ADLS**.</span></span>  <span data-ttu-id="3a9c9-118">Obecný výkon koncepty, najdete v části [Data Lake Store výkonu ladění pokyny](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span><span class="sxs-lookup"><span data-stu-id="3a9c9-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span></span> 

## <a name="parameters"></a><span data-ttu-id="3a9c9-119">Parametry</span><span class="sxs-lookup"><span data-stu-id="3a9c9-119">Parameters</span></span>

<span data-ttu-id="3a9c9-120">Při spuštění úlohy Spark, zde jsou hello nejdůležitější nastavení, které mohou být na ADLS ujít tooincrease výkon:</span><span class="sxs-lookup"><span data-stu-id="3a9c9-120">When running Spark jobs, here are hello most important settings that can be tuned tooincrease performance on ADLS:</span></span>

* <span data-ttu-id="3a9c9-121">**Poče vykonavatelů** -hello počet souběžných úloh, které mohou být provedeny.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-121">**Num-executors** - hello number of concurrent tasks that can be executed.</span></span>

* <span data-ttu-id="3a9c9-122">**Paměť vykonavatele** -hello množství paměti přidělené tooeach vykonavatele.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-122">**Executor-memory** - hello amount of memory allocated tooeach executor.</span></span>

* <span data-ttu-id="3a9c9-123">**Vykonavatele jader** -tooeach vykonavatele přidělené hello počet jader.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-123">**Executor-cores** - hello number of cores allocated tooeach executor.</span></span>                     

<span data-ttu-id="3a9c9-124">**Poče vykonavatelů** Num vykonavatelů nastaví hello maximální počet úkolů, které můžou běžet souběžně.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-124">**Num-executors** Num-executors will set hello maximum number of tasks that can run in parallel.</span></span>  <span data-ttu-id="3a9c9-125">skutečný počet úloh, které může běžet paralelně Hello ohraničená hello prostředky paměti a procesoru k dispozici v clusteru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-125">hello actual number of tasks that can run in parallel is bounded by hello memory and CPU resources available in your cluster.</span></span>

<span data-ttu-id="3a9c9-126">**Paměť vykonavatele** jde hello množství paměti přidělené tooeach vykonavatele.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-126">**Executor-memory** This is hello amount of memory that is being allocated tooeach executor.</span></span>  <span data-ttu-id="3a9c9-127">Hello paměti potřebné pro každé vykonavatele je závislá na hello úlohy.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-127">hello memory needed for each executor is dependent on hello job.</span></span>  <span data-ttu-id="3a9c9-128">Pro komplexní operace hello paměti musí toobe vyšší.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-128">For complex operations, hello memory needs toobe higher.</span></span>  <span data-ttu-id="3a9c9-129">Pro jednoduché operace, jako je ke čtení a zápisu bude nižší požadavky na paměť.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-129">For simple operations like read and write, memory requirements will be lower.</span></span>  <span data-ttu-id="3a9c9-130">Hello množství paměti pro každý vykonavatele lze zobrazit v Ambari.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-130">hello amount of memory for each executor can be viewed in Ambari.</span></span>  <span data-ttu-id="3a9c9-131">V Ambari přejděte tooSpark a zobrazit kartu konfigurací hello.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-131">In Ambari, navigate tooSpark and view hello Configs tab.</span></span>  

<span data-ttu-id="3a9c9-132">**Vykonavatele jader** to nastaví hello množství jader použitou na vykonavatele, který určuje hello počet paralelních vláken, která lze spustit na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-132">**Executor-cores** This sets hello amount of cores used per executor, which determines hello number of parallel threads that can be run per executor.</span></span>  <span data-ttu-id="3a9c9-133">Například pokud prováděcí modul jader = 2, pak každý vykonavatele můžete spustit 2 paralelní úlohy v vykonavatele hello.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in hello executor.</span></span>  <span data-ttu-id="3a9c9-134">Hello vykonavatele jader potřeby budou závislé na hello úlohy.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-134">hello executor-cores needed will be dependent on hello job.</span></span>  <span data-ttu-id="3a9c9-135">Úlohy náročnými vstupně-výstupní operace nevyžadují velké množství paměti na jeden úkol, každý vykonavatele může zpracovat více paralelních úloh.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span></span>

<span data-ttu-id="3a9c9-136">Ve výchozím nastavení jsou definovány dvě virtuální YARN jádra pro každou počet fyzických jader při spuštění Spark v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span></span>  <span data-ttu-id="3a9c9-137">Toto číslo poskytuje vhodné rovnováhy concurrecy a množství kontext přepínání z více vláken.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span></span>  

## <a name="guidance"></a><span data-ttu-id="3a9c9-138">Doprovodné materiály</span><span class="sxs-lookup"><span data-stu-id="3a9c9-138">Guidance</span></span>

<span data-ttu-id="3a9c9-139">Při spouštění Spark toowork analytické úlohy s daty v Data Lake Store, doporučujeme použít hello nejnovější HDInsight verze tooget hello nejlepší výkon s Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-139">While running Spark analytic workloads toowork with data in Data Lake Store, we recommend that you use hello most recent HDInsight version tooget hello best performance with Data Lake Store.</span></span> <span data-ttu-id="3a9c9-140">Když vaše úlohy více vstupně-výstupní operace náročné na prostředky, může být určité parametry nakonfigurované tooimprove výkonu.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-140">When your job is more I/O intensive, then certain parameters can be configured tooimprove performance.</span></span>  <span data-ttu-id="3a9c9-141">Azure Data Lake Store je platforma vysoce škálovatelné úložiště, která dokáže zpracovat vysoké propustnosti.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span></span>  <span data-ttu-id="3a9c9-142">Pokud úloha hello obsahuje především pro čtení nebo zápisu, pak zvýšení souběžnosti pro vstupně-výstupních operací tooand z Azure Data Lake Store může zvýšit výkon.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-142">If hello job mainly consists of read or writes, then increasing concurrency for I/O tooand from Azure Data Lake Store could increase performance.</span></span>

<span data-ttu-id="3a9c9-143">Existuje několik souběžnosti tooincrease obecné způsoby pro úlohy náročné vstupně-výstupní operace.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-143">There are a few general ways tooincrease concurrency for I/O intensive jobs.</span></span>

<span data-ttu-id="3a9c9-144">**Krok 1: Určení, kolik aplikace běží v clusteru** – byste měli vědět, kolik aplikací jsou spuštěné v clusteru hello včetně hello stávající.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on hello cluster including hello current one.</span></span>  <span data-ttu-id="3a9c9-145">Hello výchozí hodnoty pro každý Spark předpokládá nastavení, které jsou 4 současné spuštění aplikace.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-145">hello default values for each Spark setting assumes that there are 4 apps running concurrently.</span></span>  <span data-ttu-id="3a9c9-146">Proto bude mít pouze 25 % hello clusteru k dispozici pro každou aplikaci.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-146">Therefore, you will only have 25% of hello cluster available for each app.</span></span>  <span data-ttu-id="3a9c9-147">tooget lepší výkon, můžete přepsat výchozí hodnoty hello změnou hello počet vykonavatelů.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-147">tooget better performance, you can override hello defaults by changing hello number of executors.</span></span>  

<span data-ttu-id="3a9c9-148">**Krok 2: Nastavení vykonavatele paměti** – hello nejprve thing tooset je vykonavatele paměti hello.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-148">**Step 2: Set executor-memory** – hello first thing tooset is hello executor-memory.</span></span>  <span data-ttu-id="3a9c9-149">paměť Hello budou závislé na se toorun probíhající úlohy hello.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-149">hello memory will be dependent on hello job that you are going toorun.</span></span>  <span data-ttu-id="3a9c9-150">Přidělování paměti prováděcího modulu, může zvýšit souběžnost.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-150">You can increase concurrency by allocating less memory per executor.</span></span>  <span data-ttu-id="3a9c9-151">Pokud se zobrazí mimo výjimky paměti při spuštění vaší úlohy, měli byste zvýšit hello hodnotu tohoto parametru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-151">If you see out of memory exceptions when you run your job, then you should increase hello value for this parameter.</span></span>  <span data-ttu-id="3a9c9-152">Jeden alternativní je tooget více paměti pomocí clusteru, který má vyšší objemy paměti nebo zvýšení hello velikost clusteru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-152">One alternative is tooget more memory by using a cluster that has higher amounts of memory or increasing hello size of your cluster.</span></span>  <span data-ttu-id="3a9c9-153">Více paměti povolí další vykonavatelů toobe používá, což znamená další souběžnosti.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-153">More memory will enable more executors toobe used, which means more concurrency.</span></span>

<span data-ttu-id="3a9c9-154">**Krok 3: Nastavte vykonavatele jader** – pro vstupně-výstupní operace náročné úlohy, které nemají komplexních operací, je dobré toostart s velký počet jader vykonavatele tooincrease hello počet paralelních úloh za prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good toostart with a high number of executor-cores tooincrease hello number of parallel tasks per executor.</span></span>  <span data-ttu-id="3a9c9-155">Nastavení vykonavatele jader too4 je dobré spustit.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-155">Setting executor-cores too4 is a good start.</span></span>   

    executor-cores = 4
<span data-ttu-id="3a9c9-156">Zvýšením počtu hello vykonavatele jader vám poskytne další paralelismus tak můžete experimentovat s jinou vykonavatele jader.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-156">Increasing hello number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span></span>  <span data-ttu-id="3a9c9-157">Pro úlohy, které mají složitějších operací by měly snížit hello počet jader na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-157">For jobs that have more complex operations, you should reduce hello number of cores per executor.</span></span>  <span data-ttu-id="3a9c9-158">Pokud vykonavatele jader je nastavena na hodnotu vyšší než 4, pak uvolňování paměti může stát neefektivní a snížit výkon.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span></span>

<span data-ttu-id="3a9c9-159">**Krok 4: Určení množství paměti YARN v clusteru** – tyto informace jsou k dispozici v Ambari.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span></span>  <span data-ttu-id="3a9c9-160">Přejděte tooYARN a zobrazit kartu konfigurací hello.  v tomto okně se zobrazí Hello YARN paměti.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-160">Navigate tooYARN and view hello Configs tab.  hello YARN memory is displayed in this window.</span></span>  
<span data-ttu-id="3a9c9-161">Poznámka: když jste v okně hello, uvidíte také hello výchozí YARN kontejneru velikost.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-161">Note: while you are in hello window, you can also see hello default YARN container size.</span></span>  <span data-ttu-id="3a9c9-162">Hello YARN kontejneru velikost je hello stejné jako paměť na vykonavatele parametru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-162">hello YARN container size is hello same as memory per executor paramter.</span></span>

    Total YARN memory = nodes * YARN memory per node
<span data-ttu-id="3a9c9-163">**Krok 5: Vypočítat num vykonavatelů**</span><span class="sxs-lookup"><span data-stu-id="3a9c9-163">**Step 5: Calculate num-executors**</span></span>

<span data-ttu-id="3a9c9-164">**Vypočítat omezení paměti** -parametr num vykonavatelů hello je omezena paměti nebo procesoru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-164">**Calculate memory constraint** - hello num-executors parameter is constrained either by memory or by CPU.</span></span>  <span data-ttu-id="3a9c9-165">omezení paměti Hello je určen podle hello množství dostupné paměti YARN pro vaši aplikaci.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-165">hello memory constraint is determined by hello amount of available YARN memory for your application.</span></span>  <span data-ttu-id="3a9c9-166">Měli byste trvat celkové paměti YARN a vydělte vykonavatele paměti.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-166">You should take total YARN memory and divide that by executor-memory.</span></span>  <span data-ttu-id="3a9c9-167">omezení Hello musí toobe zrušte škálovat pro hello počet aplikací, takže jsme dělit hello počet aplikací.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-167">hello constraint needs toobe de-scaled for hello number of apps so we divide by hello number of apps.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
<span data-ttu-id="3a9c9-168">**Výpočet procesoru omezení** -hello omezení procesoru se počítá jako hello celkový počet jader virtuální dělený hello počet jader na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-168">**Calculate CPU constraint** - hello CPU constraint is calculated as hello total virtual cores divided by hello number of cores per executor.</span></span>  <span data-ttu-id="3a9c9-169">Existují 2 virtuální jádra pro každou počet fyzických jader.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-169">There are 2 virtual cores for each physical core.</span></span>  <span data-ttu-id="3a9c9-170">Podobně jako omezení paměti toohello, máme dělení podle hello počet aplikací.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-170">Similar toohello memory constraint, we have divide by hello number of apps.</span></span>

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
<span data-ttu-id="3a9c9-171">**Nastavit počet vykonavatelů** – hello num vykonavatelů parametru se určuje odebráním hello minimální hello paměti omezení a omezení hello procesoru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-171">**Set num-executors** – hello num-executors parameter is determined by taking hello minimum of hello memory constraint and hello CPU constraint.</span></span> 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
<span data-ttu-id="3a9c9-172">Nastavení vyššího počtu num vykonavatelů nemusí se nutně zvýšit výkon.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-172">Setting a higher number of num-executors does not necessarily increase performance.</span></span>  <span data-ttu-id="3a9c9-173">Měli byste zvážit přidání další vykonavatelů přidá, velmi starat se pro každý další vykonavatele, který může potenciálně snížit výkon.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-173">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span></span>  <span data-ttu-id="3a9c9-174">Poče vykonavatelů ohraničená hello prostředky clusteru.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-174">Num-executors is bounded by hello cluster resources.</span></span>    

## <a name="example-calculation"></a><span data-ttu-id="3a9c9-175">Příklad výpočtu</span><span class="sxs-lookup"><span data-stu-id="3a9c9-175">Example Calculation</span></span>

<span data-ttu-id="3a9c9-176">Řekněme, že máte aktuálně skládá z 8 D4v2 uzly clusteru, který je spuštěný 2 aplikace včetně hello, kterou budou toorun.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-176">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including hello one you are going toorun.</span></span>  

<span data-ttu-id="3a9c9-177">**Krok 1: Určení, kolik aplikace běží v clusteru** – víte, že máte 2 aplikace v clusteru, včetně hello jeden budete toorun.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-177">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including hello one you are going toorun.</span></span>  

<span data-ttu-id="3a9c9-178">**Krok 2: Nastavení vykonavatele paměti** – v tomto příkladu jsme určit, že bude 6 GB paměti vykonavatele dostatečná pro úlohy náročné vstupně-výstupních operací.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-178">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span></span>  

    executor-memory = 6GB
<span data-ttu-id="3a9c9-179">**Krok 3: Nastavte vykonavatele jader** – vzhledem k tomu, že je to úlohy náročné vstupně-výstupních operací, jsme můžete nastavit počet jader pro každý too4 vykonavatele hello.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-179">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set hello number of cores for each executor too4.</span></span>  <span data-ttu-id="3a9c9-180">Nastavení jader na vykonavatele toolarger než 4 může způsobit problémy s kolekce paměti.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-180">Setting cores per executor toolarger than 4 may cause garbage collection problems.</span></span>  

    executor-cores = 4
<span data-ttu-id="3a9c9-181">**Krok 4: Určení množství paměti YARN v clusteru** – jsme přejděte tooAmbari toofind si, že má každý D4v2 25 GB paměti YARN.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-181">**Step 4: Determine amount of YARN memory in cluster** – We navigate tooAmbari toofind out that each D4v2 has 25GB of YARN memory.</span></span>  <span data-ttu-id="3a9c9-182">Vzhledem k tomu, že je 8 uzlů, dostupná paměť YARN hello se násobí hodnotou 8.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-182">Since there are 8 nodes, hello available YARN memory is multiplied by 8.</span></span>

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
<span data-ttu-id="3a9c9-183">**Krok 5: Vypočítat num vykonavatelů** – hello num vykonavatelů parametru se určuje odebráním hello minimální hello paměti omezení a omezení procesoru hello dělený hello # aplikace běžící na Spark.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-183">**Step 5: Calculate num-executors** – hello num-executors parameter is determined by taking hello minimum of hello memory constraint and hello CPU constraint divided by hello # of apps running on Spark.</span></span>    

<span data-ttu-id="3a9c9-184">**Vypočítat omezení paměti** – počítá se jako celkové paměti YARN hello dělený hello paměť na vykonavatele omezení paměti hello.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-184">**Calculate memory constraint** – hello memory constraint is calculated as hello total YARN memory divided by hello memory per executor.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
<span data-ttu-id="3a9c9-185">**Výpočet procesoru omezení** -hello omezení procesoru se počítá jako hello yarn celkový počet jader dělený hello počet jader na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="3a9c9-185">**Calculate CPU constraint** - hello CPU constraint is calculated as hello total yarn cores divided by hello number of cores per executor.</span></span>
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
<span data-ttu-id="3a9c9-186">**Sada num vykonavatelů**</span><span class="sxs-lookup"><span data-stu-id="3a9c9-186">**Set num-executors**</span></span>

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    


---
title: "Ladění pravidla výkonu Spark Azure Data Lake Store | Microsoft Docs"
description: "Ladění pravidla výkonu Spark Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: 2109744fb7ffdfafb7a86bbea355e119718af099
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 07/11/2017
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="a0b96-103">Pokyny pro Spark v HDInsight a Azure Data Lake Store optimalizace výkonu</span><span class="sxs-lookup"><span data-stu-id="a0b96-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="a0b96-104">Při ladění výkonu na Spark, budete muset vzít v úvahu počet aplikací, které budou spuštěny v clusteru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-104">When tuning performance on Spark, you need to consider the number of apps that will be running on your cluster.</span></span>  <span data-ttu-id="a0b96-105">Ve výchozím nastavení, můžete spustit 4 aplikace souběžně na clusteru HDI (Poznámka: ve výchozím nastavení se může změnit).</span><span class="sxs-lookup"><span data-stu-id="a0b96-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: the default setting is subject to change).</span></span>  <span data-ttu-id="a0b96-106">Můžete rozhodnout pro použití méně aplikací, abyste mohli přepíší výchozí nastavení a použít více clusteru pro tyto aplikace.</span><span class="sxs-lookup"><span data-stu-id="a0b96-106">You may decide to use fewer apps so you can override the default settings and use more of the cluster for those apps.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="a0b96-107">Požadavky</span><span class="sxs-lookup"><span data-stu-id="a0b96-107">Prerequisites</span></span>

* <span data-ttu-id="a0b96-108">**Předplatné Azure**.</span><span class="sxs-lookup"><span data-stu-id="a0b96-108">**An Azure subscription**.</span></span> <span data-ttu-id="a0b96-109">Viz [Získání bezplatné zkušební verze Azure](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="a0b96-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="a0b96-110">**Účet Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="a0b96-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="a0b96-111">Pokyny o tom, jak vytvořit najdete v tématu [Začínáme s Azure Data Lake Store](data-lake-store-get-started-portal.md)</span><span class="sxs-lookup"><span data-stu-id="a0b96-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span></span>
* <span data-ttu-id="a0b96-112">**Azure HDInsight cluster** s přístupem k účtu Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="a0b96-112">**Azure HDInsight cluster** with access to a Data Lake Store account.</span></span> <span data-ttu-id="a0b96-113">V tématu [vytvoření clusteru HDInsight s Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="a0b96-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="a0b96-114">Ujistěte se, že povolení vzdálené plochy pro cluster.</span><span class="sxs-lookup"><span data-stu-id="a0b96-114">Make sure you enable Remote Desktop for the cluster.</span></span>
* <span data-ttu-id="a0b96-115">**Spuštění clusteru Spark v Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="a0b96-115">**Running Spark cluster on Azure Data Lake Store**.</span></span>  <span data-ttu-id="a0b96-116">Další informace najdete v tématu [clusteru používejte HDInsight Spark k analýze dat v Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span><span class="sxs-lookup"><span data-stu-id="a0b96-116">For more information, see [Use HDInsight Spark cluster to analyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span></span>
* <span data-ttu-id="a0b96-117">**Ladění pokyny na ADLS výkonu**.</span><span class="sxs-lookup"><span data-stu-id="a0b96-117">**Performance tuning guidelines on ADLS**.</span></span>  <span data-ttu-id="a0b96-118">Obecný výkon koncepty, najdete v části [Data Lake Store výkonu ladění pokyny](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span><span class="sxs-lookup"><span data-stu-id="a0b96-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span></span> 

## <a name="parameters"></a><span data-ttu-id="a0b96-119">Parametry</span><span class="sxs-lookup"><span data-stu-id="a0b96-119">Parameters</span></span>

<span data-ttu-id="a0b96-120">Při spuštění úlohy Spark, zde jsou nejdůležitější nastavení, která lze ladit a zvyšuje výkon na ADLS:</span><span class="sxs-lookup"><span data-stu-id="a0b96-120">When running Spark jobs, here are the most important settings that can be tuned to increase performance on ADLS:</span></span>

* <span data-ttu-id="a0b96-121">**Poče vykonavatelů** -počet souběžných úloh, které mohou být provedeny.</span><span class="sxs-lookup"><span data-stu-id="a0b96-121">**Num-executors** - The number of concurrent tasks that can be executed.</span></span>

* <span data-ttu-id="a0b96-122">**Paměť vykonavatele** -množství paměti přidělené pro každý prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-122">**Executor-memory** - The amount of memory allocated to each executor.</span></span>

* <span data-ttu-id="a0b96-123">**Vykonavatele jader** -počet jader přidělené každý prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-123">**Executor-cores** - The number of cores allocated to each executor.</span></span>                     

<span data-ttu-id="a0b96-124">**Poče vykonavatelů** Num vykonavatelů Nastaví maximální počet úkolů, které můžou běžet souběžně.</span><span class="sxs-lookup"><span data-stu-id="a0b96-124">**Num-executors** Num-executors will set the maximum number of tasks that can run in parallel.</span></span>  <span data-ttu-id="a0b96-125">Skutečný počet úloh, které může běžet paralelně ohraničená paměti a prostředky procesoru, které jsou k dispozici v clusteru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-125">The actual number of tasks that can run in parallel is bounded by the memory and CPU resources available in your cluster.</span></span>

<span data-ttu-id="a0b96-126">**Paměť vykonavatele** Toto je množství paměti přidělené ke každé prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-126">**Executor-memory** This is the amount of memory that is being allocated to each executor.</span></span>  <span data-ttu-id="a0b96-127">Paměti potřebné pro každé vykonavatele je závislá na úlohu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-127">The memory needed for each executor is dependent on the job.</span></span>  <span data-ttu-id="a0b96-128">Paměť pro komplexní operace, musí být vyšší.</span><span class="sxs-lookup"><span data-stu-id="a0b96-128">For complex operations, the memory needs to be higher.</span></span>  <span data-ttu-id="a0b96-129">Pro jednoduché operace, jako je ke čtení a zápisu bude nižší požadavky na paměť.</span><span class="sxs-lookup"><span data-stu-id="a0b96-129">For simple operations like read and write, memory requirements will be lower.</span></span>  <span data-ttu-id="a0b96-130">Velikost paměti pro každý vykonavatele lze zobrazit v Ambari.</span><span class="sxs-lookup"><span data-stu-id="a0b96-130">The amount of memory for each executor can be viewed in Ambari.</span></span>  <span data-ttu-id="a0b96-131">V Ambari přejděte na Spark a zobrazit kartu konfigurací.</span><span class="sxs-lookup"><span data-stu-id="a0b96-131">In Ambari, navigate to Spark and view the Configs tab.</span></span>  

<span data-ttu-id="a0b96-132">**Vykonavatele jader** to Nastaví množství jader použitou na prováděcího modulu, která určuje počet paralelních vláken, která lze spustit na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-132">**Executor-cores** This sets the amount of cores used per executor, which determines the number of parallel threads that can be run per executor.</span></span>  <span data-ttu-id="a0b96-133">Například pokud prováděcí modul jader = 2, pak každý vykonavatele můžete spustit 2 paralelní úlohy v prováděcí modul.</span><span class="sxs-lookup"><span data-stu-id="a0b96-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in the executor.</span></span>  <span data-ttu-id="a0b96-134">Jádrech vykonavatele potřeby budou závislé na úlohu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-134">The executor-cores needed will be dependent on the job.</span></span>  <span data-ttu-id="a0b96-135">Úlohy náročnými vstupně-výstupní operace nevyžadují velké množství paměti na jeden úkol, každý vykonavatele může zpracovat více paralelních úloh.</span><span class="sxs-lookup"><span data-stu-id="a0b96-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span></span>

<span data-ttu-id="a0b96-136">Ve výchozím nastavení jsou definovány dvě virtuální YARN jádra pro každou počet fyzických jader při spuštění Spark v HDInsight.</span><span class="sxs-lookup"><span data-stu-id="a0b96-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span></span>  <span data-ttu-id="a0b96-137">Toto číslo poskytuje vhodné rovnováhy concurrecy a množství kontext přepínání z více vláken.</span><span class="sxs-lookup"><span data-stu-id="a0b96-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span></span>  

## <a name="guidance"></a><span data-ttu-id="a0b96-138">Doprovodné materiály</span><span class="sxs-lookup"><span data-stu-id="a0b96-138">Guidance</span></span>

<span data-ttu-id="a0b96-139">Při spouštění Spark analytické úlohy pro práci s daty v Data Lake Store, doporučujeme pomocí nejnovější verze HDInsight získáte nejlepší výkon s Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="a0b96-139">While running Spark analytic workloads to work with data in Data Lake Store, we recommend that you use the most recent HDInsight version to get the best performance with Data Lake Store.</span></span> <span data-ttu-id="a0b96-140">Když vaše úlohy více vstupně-výstupní operace náročné na prostředky, můžete určité parametry nakonfigurované ke zlepšení výkonu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-140">When your job is more I/O intensive, then certain parameters can be configured to improve performance.</span></span>  <span data-ttu-id="a0b96-141">Azure Data Lake Store je platforma vysoce škálovatelné úložiště, která dokáže zpracovat vysoké propustnosti.</span><span class="sxs-lookup"><span data-stu-id="a0b96-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span></span>  <span data-ttu-id="a0b96-142">Pokud úloha obsahuje především pro čtení nebo zápisu, pak zvýšení souběžnosti pro vstupy/výstupy do a z Azure Data Lake Store může zvýšit výkon.</span><span class="sxs-lookup"><span data-stu-id="a0b96-142">If the job mainly consists of read or writes, then increasing concurrency for I/O to and from Azure Data Lake Store could increase performance.</span></span>

<span data-ttu-id="a0b96-143">Chcete-li zvýšit souběžnost úloh intenzivním vstupně-výstupních operací několik obecné způsoby.</span><span class="sxs-lookup"><span data-stu-id="a0b96-143">There are a few general ways to increase concurrency for I/O intensive jobs.</span></span>

<span data-ttu-id="a0b96-144">**Krok 1: Určení, kolik aplikace běží v clusteru** – byste měli vědět, kolik aplikací jsou spuštěné v clusteru, včetně aktuální.</span><span class="sxs-lookup"><span data-stu-id="a0b96-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on the cluster including the current one.</span></span>  <span data-ttu-id="a0b96-145">Výchozí hodnoty pro každý Spark předpokládá nastavení, které jsou 4 současné spuštění aplikace.</span><span class="sxs-lookup"><span data-stu-id="a0b96-145">The default values for each Spark setting assumes that there are 4 apps running concurrently.</span></span>  <span data-ttu-id="a0b96-146">Proto bude mít pouze 25 % clusteru k dispozici pro každou aplikaci.</span><span class="sxs-lookup"><span data-stu-id="a0b96-146">Therefore, you will only have 25% of the cluster available for each app.</span></span>  <span data-ttu-id="a0b96-147">Chcete-li získat lepší výkon, můžete přepsat výchozí hodnoty tak, že změníte počet vykonavatelů.</span><span class="sxs-lookup"><span data-stu-id="a0b96-147">To get better performance, you can override the defaults by changing the number of executors.</span></span>  

<span data-ttu-id="a0b96-148">**Krok 2: Nastavení vykonavatele paměti** – první věc, kterou chcete nastavit je vykonavatele paměti.</span><span class="sxs-lookup"><span data-stu-id="a0b96-148">**Step 2: Set executor-memory** – the first thing to set is the executor-memory.</span></span>  <span data-ttu-id="a0b96-149">Paměť budou závislé na úlohy, které chcete spustit.</span><span class="sxs-lookup"><span data-stu-id="a0b96-149">The memory will be dependent on the job that you are going to run.</span></span>  <span data-ttu-id="a0b96-150">Přidělování paměti prováděcího modulu, může zvýšit souběžnost.</span><span class="sxs-lookup"><span data-stu-id="a0b96-150">You can increase concurrency by allocating less memory per executor.</span></span>  <span data-ttu-id="a0b96-151">Pokud se zobrazí mimo výjimky paměti při spuštění vaší úlohy, měli byste zvýšit hodnotu tohoto parametru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-151">If you see out of memory exceptions when you run your job, then you should increase the value for this parameter.</span></span>  <span data-ttu-id="a0b96-152">Jeden alternativou je získat více paměti pomocí clusteru, který má vyšší objemy paměti nebo zvýšení velikosti vašeho clusteru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-152">One alternative is to get more memory by using a cluster that has higher amounts of memory or increasing the size of your cluster.</span></span>  <span data-ttu-id="a0b96-153">Více paměti povolí další vykonavatelů má používat, což znamená, že další souběžnosti.</span><span class="sxs-lookup"><span data-stu-id="a0b96-153">More memory will enable more executors to be used, which means more concurrency.</span></span>

<span data-ttu-id="a0b96-154">**Krok 3: Nastavte vykonavatele jader** – pro vstupně-výstupních operací náročné úlohy, které nemají komplexních operací, je vhodné začínat velký počet vykonavatele jader a zvýšit počet paralelních úloh za prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good to start with a high number of executor-cores to increase the number of parallel tasks per executor.</span></span>  <span data-ttu-id="a0b96-155">Nastavení vykonavatele jader na 4 je dobré spustit.</span><span class="sxs-lookup"><span data-stu-id="a0b96-155">Setting executor-cores to 4 is a good start.</span></span>   

    executor-cores = 4
<span data-ttu-id="a0b96-156">Zvýšení počtu jader vykonavatele vám poskytne další paralelismus tak můžete experimentovat s jinou vykonavatele jader.</span><span class="sxs-lookup"><span data-stu-id="a0b96-156">Increasing the number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span></span>  <span data-ttu-id="a0b96-157">Pro úlohy, které mají složitějších operací by měly snížit počet jader na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-157">For jobs that have more complex operations, you should reduce the number of cores per executor.</span></span>  <span data-ttu-id="a0b96-158">Pokud vykonavatele jader je nastavena na hodnotu vyšší než 4, pak uvolňování paměti může stát neefektivní a snížit výkon.</span><span class="sxs-lookup"><span data-stu-id="a0b96-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span></span>

<span data-ttu-id="a0b96-159">**Krok 4: Určení množství paměti YARN v clusteru** – tyto informace jsou k dispozici v Ambari.</span><span class="sxs-lookup"><span data-stu-id="a0b96-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span></span>  <span data-ttu-id="a0b96-160">Přejděte do YARN a zobrazit kartu konfigurací.</span><span class="sxs-lookup"><span data-stu-id="a0b96-160">Navigate to YARN and view the Configs tab.</span></span>  <span data-ttu-id="a0b96-161">V tomto okně se zobrazí YARN paměti.</span><span class="sxs-lookup"><span data-stu-id="a0b96-161">The YARN memory is displayed in this window.</span></span>  
<span data-ttu-id="a0b96-162">Poznámka: když jste v okně, uvidíte také výchozí velikost YARN kontejneru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-162">Note: while you are in the window, you can also see the default YARN container size.</span></span>  <span data-ttu-id="a0b96-163">Velikost kontejneru YARN je stejný jako paměť na vykonavatele parametru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-163">The YARN container size is the same as memory per executor paramter.</span></span>

    Total YARN memory = nodes * YARN memory per node
<span data-ttu-id="a0b96-164">**Krok 5: Vypočítat num vykonavatelů**</span><span class="sxs-lookup"><span data-stu-id="a0b96-164">**Step 5: Calculate num-executors**</span></span>

<span data-ttu-id="a0b96-165">**Vypočítat omezení paměti** -parametr num vykonavatelů je omezené paměti nebo procesoru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-165">**Calculate memory constraint** - The num-executors parameter is constrained either by memory or by CPU.</span></span>  <span data-ttu-id="a0b96-166">Omezení paměti je určen podle množství dostupné paměti YARN pro vaši aplikaci.</span><span class="sxs-lookup"><span data-stu-id="a0b96-166">The memory constraint is determined by the amount of available YARN memory for your application.</span></span>  <span data-ttu-id="a0b96-167">Měli byste trvat celkové paměti YARN a vydělte vykonavatele paměti.</span><span class="sxs-lookup"><span data-stu-id="a0b96-167">You should take total YARN memory and divide that by executor-memory.</span></span>  <span data-ttu-id="a0b96-168">Omezení musí být zrušte škálovat pro počet aplikací, takže jsme rozdělit podle počtu aplikací.</span><span class="sxs-lookup"><span data-stu-id="a0b96-168">The constraint needs to be de-scaled for the number of apps so we divide by the number of apps.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
<span data-ttu-id="a0b96-169">**Výpočet procesoru omezení** – počítá se jako celkový virtuální jader dělený počet jader na vykonavatele omezení procesoru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-169">**Calculate CPU constraint** - The CPU constraint is calculated as the total virtual cores divided by the number of cores per executor.</span></span>  <span data-ttu-id="a0b96-170">Existují 2 virtuální jádra pro každou počet fyzických jader.</span><span class="sxs-lookup"><span data-stu-id="a0b96-170">There are 2 virtual cores for each physical core.</span></span>  <span data-ttu-id="a0b96-171">Podobně jako omezení paměti, máme dělení podle počtu aplikací.</span><span class="sxs-lookup"><span data-stu-id="a0b96-171">Similar to the memory constraint, we have divide by the number of apps.</span></span>

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
<span data-ttu-id="a0b96-172">**Nastavit počet vykonavatelů** – je určen parametr num vykonavatelů provedením minimum omezení paměti a procesoru omezení.</span><span class="sxs-lookup"><span data-stu-id="a0b96-172">**Set num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint.</span></span> 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
<span data-ttu-id="a0b96-173">Nastavení vyššího počtu num vykonavatelů nemusí se nutně zvýšit výkon.</span><span class="sxs-lookup"><span data-stu-id="a0b96-173">Setting a higher number of num-executors does not necessarily increase performance.</span></span>  <span data-ttu-id="a0b96-174">Měli byste zvážit přidání další vykonavatelů přidá, velmi starat se pro každý další vykonavatele, který může potenciálně snížit výkon.</span><span class="sxs-lookup"><span data-stu-id="a0b96-174">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span></span>  <span data-ttu-id="a0b96-175">Poče vykonavatelů ohraničená prostředků clusteru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-175">Num-executors is bounded by the cluster resources.</span></span>    

## <a name="example-calculation"></a><span data-ttu-id="a0b96-176">Příklad výpočtu</span><span class="sxs-lookup"><span data-stu-id="a0b96-176">Example Calculation</span></span>

<span data-ttu-id="a0b96-177">Řekněme, že aktuálně máte cluster skládá z 8 D4v2 uzly se systémem 2 aplikace, včetně toho, který chcete spustit.</span><span class="sxs-lookup"><span data-stu-id="a0b96-177">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including the one you are going to run.</span></span>  

<span data-ttu-id="a0b96-178">**Krok 1: Určení, kolik aplikace běží v clusteru** – víte, že máte 2 aplikace v clusteru, včetně toho, který chcete spustit.</span><span class="sxs-lookup"><span data-stu-id="a0b96-178">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including the one you are going to run.</span></span>  

<span data-ttu-id="a0b96-179">**Krok 2: Nastavení vykonavatele paměti** – v tomto příkladu jsme určit, že bude 6 GB paměti vykonavatele dostatečná pro úlohy náročné vstupně-výstupních operací.</span><span class="sxs-lookup"><span data-stu-id="a0b96-179">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span></span>  

    executor-memory = 6GB
<span data-ttu-id="a0b96-180">**Krok 3: Nastavte vykonavatele jader** – vzhledem k tomu, že je to úlohy náročné vstupně-výstupních operací, jsme můžete nastavit počet jader pro každý vykonavatele na 4.</span><span class="sxs-lookup"><span data-stu-id="a0b96-180">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set the number of cores for each executor to 4.</span></span>  <span data-ttu-id="a0b96-181">Nastavení jader na vykonavatele na větší než 4 může způsobit problémy s kolekce paměti.</span><span class="sxs-lookup"><span data-stu-id="a0b96-181">Setting cores per executor to larger than 4 may cause garbage collection problems.</span></span>  

    executor-cores = 4
<span data-ttu-id="a0b96-182">**Krok 4: Určení množství paměti YARN v clusteru** – jsme přejděte na Ambari a zjistěte, zda má každý D4v2 25 GB paměti YARN.</span><span class="sxs-lookup"><span data-stu-id="a0b96-182">**Step 4: Determine amount of YARN memory in cluster** – We navigate to Ambari to find out that each D4v2 has 25GB of YARN memory.</span></span>  <span data-ttu-id="a0b96-183">Vzhledem k tomu, že je 8 uzlů, dostupná paměť YARN se násobí hodnotou 8.</span><span class="sxs-lookup"><span data-stu-id="a0b96-183">Since there are 8 nodes, the available YARN memory is multiplied by 8.</span></span>

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
<span data-ttu-id="a0b96-184">**Krok 5: Vypočítat num vykonavatelů** – je určen parametr num vykonavatelů provedením minimální omezení paměti a procesoru omezení dělený počet aplikací běžících na Spark.</span><span class="sxs-lookup"><span data-stu-id="a0b96-184">**Step 5: Calculate num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint divided by the # of apps running on Spark.</span></span>    

<span data-ttu-id="a0b96-185">**Vypočítat omezení paměti** – omezení paměti se počítá jako celkovou velikost paměti YARN dělený paměť na prováděcího modulu.</span><span class="sxs-lookup"><span data-stu-id="a0b96-185">**Calculate memory constraint** – The memory constraint is calculated as the total YARN memory divided by the memory per executor.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
<span data-ttu-id="a0b96-186">**Výpočet procesoru omezení** – počítá se jako jádrech celkový yarn dělený počet jader na vykonavatele omezení procesoru.</span><span class="sxs-lookup"><span data-stu-id="a0b96-186">**Calculate CPU constraint** - The CPU constraint is calculated as the total yarn cores divided by the number of cores per executor.</span></span>
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
<span data-ttu-id="a0b96-187">**Sada num vykonavatelů**</span><span class="sxs-lookup"><span data-stu-id="a0b96-187">**Set num-executors**</span></span>

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    


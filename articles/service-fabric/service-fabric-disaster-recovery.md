---
title: "aaaAzure zotavení po havárii Service Fabric | Microsoft Docs"
description: "Azure Service Fabric nabízí hello možnosti potřebné toodeal ve všech typech havárie. Tento článek popisuje typy hello havárie, které můžou nastat a jak toodeal s nimi."
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: ab49c4b9-74a8-4907-b75b-8d2ee84c6d90
ms.service: service-fabric
ms.devlang: dotNet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: 04b8348fb63e8a1c76a8f722c4c8255b339908e2
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 10/06/2017
---
# <a name="disaster-recovery-in-azure-service-fabric"></a><span data-ttu-id="d1bdf-104">Zotavení po havárii v Azure Service Fabric</span><span class="sxs-lookup"><span data-stu-id="d1bdf-104">Disaster recovery in Azure Service Fabric</span></span>
<span data-ttu-id="d1bdf-105">Důležitou součástí doručování vysoká dostupnost zajišťuje, že služby přežijí všechny různých typů chyb.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-105">A critical part of delivering high-availability is ensuring that services can survive all different types of failures.</span></span> <span data-ttu-id="d1bdf-106">To je obzvláště důležité pro chyby, které neplánované a mimo váš dosah.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-106">This is especially important for failures that are unplanned and outside of your control.</span></span> <span data-ttu-id="d1bdf-107">Tento článek popisuje některé běžné selhání režimy, které může být havárie není-li modelovány a spravovat správně.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-107">This article describes some common failure modes that could be disasters if not modeled and managed correctly.</span></span> <span data-ttu-id="d1bdf-108">Také popisují akce a jejich zmírnění tootake, pokud přesto došlo k havárii.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-108">It also discuss mitigations and actions tootake if a disaster happened anyway.</span></span> <span data-ttu-id="d1bdf-109">cílem Hello je toolimit nebo eliminovat hello riziko výpadku nebo ztráty dat, když dojde k selhání, plánované nebo jinak, mohlo dojít.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-109">hello goal is toolimit or eliminate hello risk of downtime or data loss when they occur failures, planned or otherwise, occur.</span></span>

## <a name="avoiding-disaster"></a><span data-ttu-id="d1bdf-110">Zamezení po havárii</span><span class="sxs-lookup"><span data-stu-id="d1bdf-110">Avoiding disaster</span></span>
<span data-ttu-id="d1bdf-111">Primární cílem Service Fabric je toohelp modelu vašeho prostředí a vaše služby tak, že běžné typy selhání nejsou havárie.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-111">Service Fabric's primary goal is toohelp you model both your environment and your services in such a way that common failure types are not disasters.</span></span> 

<span data-ttu-id="d1bdf-112">Obecně existují dva typy po havárii nebo selhání scénáře:</span><span class="sxs-lookup"><span data-stu-id="d1bdf-112">In general there are two types of disaster/failure scenarios:</span></span>

1. <span data-ttu-id="d1bdf-113">Hardwarový nebo softwarový chyb</span><span class="sxs-lookup"><span data-stu-id="d1bdf-113">Hardware or software faults</span></span>
2. <span data-ttu-id="d1bdf-114">Provozní chyb</span><span class="sxs-lookup"><span data-stu-id="d1bdf-114">Operational faults</span></span>

### <a name="hardware-and-software-faults"></a><span data-ttu-id="d1bdf-115">Chyby hardwaru a softwaru</span><span class="sxs-lookup"><span data-stu-id="d1bdf-115">Hardware and software faults</span></span>
<span data-ttu-id="d1bdf-116">Hardware a software chyby mohou být nepředvídatelné.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-116">Hardware and software faults are unpredictable.</span></span> <span data-ttu-id="d1bdf-117">Hello chyb toosurvive nejjednodušší způsob, jak je spuštěna další kopie hello služby předané hranice selhání hardwaru nebo softwaru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-117">hello easiest way toosurvive faults is running more copies of hello service  spanned across hardware or software fault boundaries.</span></span> <span data-ttu-id="d1bdf-118">Například pokud vaše služba běží pouze na jednu konkrétní počítač, pak hello selhání tohoto jednoho počítače je po havárii pro danou službu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-118">For example, if your service is running only on one particular machine, then hello failure of that one machine is a disaster for that service.</span></span> <span data-ttu-id="d1bdf-119">Hello jednoduchý způsob tooavoid tento po havárii je tooensure, zda je ve skutečnosti spuštěna služba hello ve více počítačích.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-119">hello simple way tooavoid this disaster is tooensure that hello service is actually running on multiple machines.</span></span> <span data-ttu-id="d1bdf-120">Testování je také nutné tooensure hello selhání jeden počítač nemá přerušit hello službou.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-120">Testing is also necessary tooensure hello failure of one machine doesn't disrupt hello running service.</span></span> <span data-ttu-id="d1bdf-121">Plánování kapacity zajišťuje jinde vytvořením nahrazení instance a že snížení kapacity nemá přetížení hello zbývající služby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-121">Capacity planning ensures a replacement instance can be created elsewhere and that reduction in capacity doesn't overload hello remaining services.</span></span> <span data-ttu-id="d1bdf-122">Hello stejného vzoru funguje bez ohledu na to, co se pokoušíte tooavoid hello selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-122">hello same pattern works regardless of what you're trying tooavoid hello failure of.</span></span> <span data-ttu-id="d1bdf-123">Například.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-123">For example.</span></span> <span data-ttu-id="d1bdf-124">Pokud máte obavy o selhání hello sítě SAN, spuštěním napříč více sítě SAN.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-124">if you're concerned about hello failure of a SAN, you run across multiple SANs.</span></span> <span data-ttu-id="d1bdf-125">Pokud máte obavy o hello ztrátě rack serverů, můžete spustit napříč rackovými stojany.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-125">If you're concerned about hello loss of a rack of servers, you run across multiple racks.</span></span> <span data-ttu-id="d1bdf-126">Pokud máte obavy o ztrátě hello datových center, měli spustit služby napříč více oblastí Azure nebo datových centrech.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-126">If you're worried about hello loss of datacenters, your service should run across multiple Azure regions or datacenters.</span></span> 

<span data-ttu-id="d1bdf-127">Při spuštění v tomto typu rozložené režimu, jste stále o subjektu toosome typy souběžných selhání, ale jediný a i několik chyb určitého typu (například: jeden odkaz selhání virtuálního počítače nebo sítě) jsou zpracovávány automaticky (a proto už "havárie").</span><span class="sxs-lookup"><span data-stu-id="d1bdf-127">When running in this type of spanned mode, you're still subject toosome types of simultaneous failures, but single and even multiple failures of a particular type (ex: a single VM or network link failing) are automatically handled (and so no longer a "disaster").</span></span> <span data-ttu-id="d1bdf-128">Service Fabric nabízí mnoho mechanismy pro rozšíření hello clusteru a zpracovává zpět přináší selhání uzlů a služby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-128">Service Fabric provides many mechanisms for expanding hello cluster and handles bringing failed nodes and services back.</span></span> <span data-ttu-id="d1bdf-129">Service Fabric také umožňuje spouštět velký počet instancí služeb v pořadí tooavoid tyto typy neplánované výpadky z měnící do skutečné havárie.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-129">Service Fabric also allows running many instances of your services in order tooavoid these types of unplanned failures from turning into real disasters.</span></span>

<span data-ttu-id="d1bdf-130">Může být z důvodů, proč spuštění dostatečně velké na to toospan nasazení přes selhání není v rámci výpočetních procesů.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-130">There may be reasons why running a deployment large enough toospan over failures is not feasible.</span></span> <span data-ttu-id="d1bdf-131">Například může trvat více hardwarových prostředků než nejste ochotná toopay pro relativní toohello riziko selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-131">For example, it may take more hardware resources than you're not willing toopay for relative toohello chance of failure.</span></span> <span data-ttu-id="d1bdf-132">Při plánování práce s distribuovaných aplikací, může to být, stav replikace a další komunikaci směrování stojí napříč geografické vzdálenosti příčiny nepřijatelné latence.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-132">When dealing with distributed applications, it could be that additional communication hops or state replication costs across geographic distances causes unacceptable latency.</span></span> <span data-ttu-id="d1bdf-133">Místo, kde je tento řádek vykreslovat se liší pro jednotlivé aplikace.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-133">Where this line is drawn differs for each application.</span></span> <span data-ttu-id="d1bdf-134">Pro chyby softwaru konkrétně hello selhání může být ve službě hello pokoušíte tooscale.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-134">For software faults specifically, hello fault could be in hello service that you are trying tooscale.</span></span> <span data-ttu-id="d1bdf-135">Další kopie není v tomto případě zabránit hello po havárii, vzhledem k tomu, že stav selhání hello je korelační napříč všemi instancemi hello.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-135">In this case more copies don't prevent hello disaster, since hello failure condition is correlated across all hello instances.</span></span>

### <a name="operational-faults"></a><span data-ttu-id="d1bdf-136">Provozní chyb</span><span class="sxs-lookup"><span data-stu-id="d1bdf-136">Operational faults</span></span>
<span data-ttu-id="d1bdf-137">I v případě služby je rozloženy na celém světě hello s mnoha propouštění, může stále přetrvávají katastrofální události.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-137">Even if your service is spanned across hello globe with many redundancies, it can still experience disastrous events.</span></span> <span data-ttu-id="d1bdf-138">Pokud například někdo neúmyslně překonfigurujete hello název dns pro službu hello nebo odstraní přímý.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-138">For example, if someone accidentally reconfigures hello dns name for hello service, or deletes it outright.</span></span> <span data-ttu-id="d1bdf-139">Jako příklad předpokládejme měl stavové služby Service Fabric a někdo omylem odstranit tuto službu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-139">As an example, let's say you had a stateful Service Fabric service, and someone deleted that service accidentally.</span></span> <span data-ttu-id="d1bdf-140">Pokud se některé další omezení rizik, služby a všechny hello stavu, jako je nyní zmizel.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-140">Unless there's some other mitigation, that service and all of hello state it had is now gone.</span></span> <span data-ttu-id="d1bdf-141">Tyto typy provozu havárie ("bohužel") vyžadují různé způsoby zmírnění rizik a kroky pro obnovení než regulární neplánované výpadky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-141">These types of operational disasters ("oops") require different mitigations and steps for recovery than regular unplanned failures.</span></span> 

<span data-ttu-id="d1bdf-142">Hello doporučené způsoby tooavoid mají tyto typy provozu chyb</span><span class="sxs-lookup"><span data-stu-id="d1bdf-142">hello best ways tooavoid these types of operational faults are to</span></span>
1. <span data-ttu-id="d1bdf-143">omezit přístup provozní toohello prostředí</span><span class="sxs-lookup"><span data-stu-id="d1bdf-143">restrict operational access toohello environment</span></span>
2. <span data-ttu-id="d1bdf-144">výhradně nebezpečné operace auditu</span><span class="sxs-lookup"><span data-stu-id="d1bdf-144">strictly audit dangerous operations</span></span>
3. <span data-ttu-id="d1bdf-145">použít automatizace, zabránit ruční nebo mimo pásmo změny a ověřit konkrétní změny před prostředí skutečného hello před jejich přijetí</span><span class="sxs-lookup"><span data-stu-id="d1bdf-145">impose automation, prevent manual or out of band changes, and validate specific changes against hello actual environment before enacting them</span></span>
4. <span data-ttu-id="d1bdf-146">Zkontrolujte, zda jsou destruktivní operace "soft".</span><span class="sxs-lookup"><span data-stu-id="d1bdf-146">ensure that destructive operations are "soft".</span></span> <span data-ttu-id="d1bdf-147">Logicky operations není se projeví okamžitě nebo může být v rámci některé časové okno vrátit zpět</span><span class="sxs-lookup"><span data-stu-id="d1bdf-147">Soft operations don't take effect immediately or can be undone within some time window</span></span>

<span data-ttu-id="d1bdf-148">Service Fabric nabízí některé mechanismy tooprevent provozní chyb, jako je například poskytuje [na základě rolí](service-fabric-cluster-security-roles.md) přístup k ovládacímu prvku pro operace clusteru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-148">Service Fabric provides some mechanisms tooprevent operational faults, such as providing [role-based](service-fabric-cluster-security-roles.md) access control for cluster operations.</span></span> <span data-ttu-id="d1bdf-149">Většina těchto provozní chyb však vyžadují organizační úsilí a dalšími systémy.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-149">However, most of these operational faults require organizational efforts and other systems.</span></span> <span data-ttu-id="d1bdf-150">Service Fabric nabízejí některé mechanismus zbývajících provozní chyb, zejména zálohování a obnovení pro stavové služby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-150">Service Fabric does provide some mechanism for surviving operational faults, most notably backup and restore for stateful services.</span></span>

## <a name="managing-failures"></a><span data-ttu-id="d1bdf-151">Správa chyb</span><span class="sxs-lookup"><span data-stu-id="d1bdf-151">Managing failures</span></span>
<span data-ttu-id="d1bdf-152">cílem Hello Service Fabric je téměř vždy Automatická správa chyb.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-152">hello goal of Service Fabric is almost always automatic management of failures.</span></span> <span data-ttu-id="d1bdf-153">Nicméně, v pořadí toohandle některé typy chyb, musí mít další kód.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-153">However, in order toohandle some types of failures, services must have additional code.</span></span> <span data-ttu-id="d1bdf-154">Jiné typy chyb by _není_ automaticky řešit kvůli důvodům, zabezpečení a obchodní kontinuity.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-154">Other types of failures should _not_ be automatically addressed because of safety and business continuity reasons.</span></span> 

### <a name="handling-single-failures"></a><span data-ttu-id="d1bdf-155">Jeden selhání zpracování</span><span class="sxs-lookup"><span data-stu-id="d1bdf-155">Handling single failures</span></span>
<span data-ttu-id="d1bdf-156">Jednoho počítače může selhat pro nejrůznějším důvodů.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-156">Single machines can fail for all sorts of reasons.</span></span> <span data-ttu-id="d1bdf-157">Některé z nich se příčiny hardwaru, jako je napájení a sítě selhání hardwaru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-157">Some of these are hardware causes, like power supplies and networking hardware failures.</span></span> <span data-ttu-id="d1bdf-158">Jiné chyby jsou v softwaru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-158">Other failures are in software.</span></span> <span data-ttu-id="d1bdf-159">Mezi ně patří selhání hello skutečné operačního systému a samotnou službu hello.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-159">These include failures of hello actual operating system and hello service itself.</span></span> <span data-ttu-id="d1bdf-160">Service Fabric automaticky rozpozná tyto typy chyb, včetně případů, kdy hello počítač stal izolované od ostatních počítačů z důvodu toonetwork problémy.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-160">Service Fabric automatically detects these types of failures, including cases where hello machine becomes isolated from other machines due toonetwork issues.</span></span>

<span data-ttu-id="d1bdf-161">Bez ohledu na typ hello služby spuštěna jedna instance výsledky výpadek pro tuto službu Pokud z nějakého důvodu selže této jednu kopii hello kódu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-161">Regardless of hello type of service, running a single instance results in downtime for that service if that single copy of hello code fails for any reason.</span></span> 

<span data-ttu-id="d1bdf-162">V pořadí toohandle jediné chyby, hello nejjednodušší, musíte je tooensure, které jsou vaše služby spuštěné na více než jeden uzel ve výchozím nastavení.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-162">In order toohandle any single failure, hello simplest thing you can do is tooensure that your services run on more than one node by default.</span></span> <span data-ttu-id="d1bdf-163">Pro bezstavové služby, můžete to provést tak, že `InstanceCount` větší než 1.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-163">For stateless services, this can be accomplished by having an `InstanceCount` greater than 1.</span></span> <span data-ttu-id="d1bdf-164">Pro stavové služby, je vždy hello minimální doporučení `TargetReplicaSetSize` a `MinReplicaSetSize` aspoň 3.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-164">For stateful services, hello minimum recommendation is always a `TargetReplicaSetSize` and `MinReplicaSetSize` of at least 3.</span></span> <span data-ttu-id="d1bdf-165">Spuštění více kopií kódu služby zajišťuje, že vaše služba dokáže zpracovat žádné jediné chyby automaticky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-165">Running more copies of your service code ensures that your service can handle any single failure automatically.</span></span> 

### <a name="handling-coordinated-failures"></a><span data-ttu-id="d1bdf-166">Koordinované zpracování chyb</span><span class="sxs-lookup"><span data-stu-id="d1bdf-166">Handling coordinated failures</span></span>
<span data-ttu-id="d1bdf-167">Koordinované selhání může dojít v clusteru s podporou kvůli tooeither plánované nebo selhání neplánované infrastruktury a změny nebo změny plánované softwaru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-167">Coordinated failures can happen in a cluster due tooeither planned or unplanned infrastructure failures and changes, or planned software changes.</span></span> <span data-ttu-id="d1bdf-168">Service Fabric modely infrastruktury zón, které dojde k selhání koordinované jako domén selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-168">Service Fabric models infrastructure zones that experience coordinated failures as Fault Domains.</span></span> <span data-ttu-id="d1bdf-169">Oblasti, které budou mít změny koordinované softwaru jsou modelovat jako upgradu domény.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-169">Areas that will experience coordinated software changes are modeled as Upgrade Domains.</span></span> <span data-ttu-id="d1bdf-170">Další informace o doménách selhání a upgradu najdete v [tento dokument](service-fabric-cluster-resource-manager-cluster-description.md) definice a topologie clusteru, který popisuje.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-170">More information about fault and upgrade domains is in [this document](service-fabric-cluster-resource-manager-cluster-description.md) that describes cluster topology and definition.</span></span>

<span data-ttu-id="d1bdf-171">Ve výchozím nastavení považuje Service Fabric doménách selhání a upgradu, při plánování, které by měly běžet vaše služby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-171">By default Service Fabric considers fault and upgrade domains when planning where your services should run.</span></span> <span data-ttu-id="d1bdf-172">Ve výchozím nastavení Service Fabric pokusí tooensure, která vašim službám spustit mezi několik domén selhání a upgradu, pokud změny plánovaná nebo neplánovaná vašim službám zůstanou dostupné.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-172">By default, Service Fabric tries tooensure that your services run across several fault and upgrade domains so if planned or unplanned changes happen your services remain available.</span></span> 

<span data-ttu-id="d1bdf-173">Předpokládejme například že selhání zdroje napájení současně způsobí stojany toofail počítače.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-173">For example, let's say that failure of a power source causes a rack of machines toofail simultaneously.</span></span> <span data-ttu-id="d1bdf-174">S více kopií hello službu hello ztrátě velký počet počítačů v doméně selhání selhání se změní jenom další příklad jediné chyby pro danou službu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-174">With multiple copies of hello service running hello loss of many machines in fault domain failure turns into just another example of single failure for a given service.</span></span> <span data-ttu-id="d1bdf-175">Z tohoto důvodu Správa domén selhání je důležité tooensuring vysokou dostupnost vašich služeb.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-175">This is why managing fault domains is critical tooensuring high availability of your services.</span></span> <span data-ttu-id="d1bdf-176">Při spuštění v Azure Service Fabric, jsou automaticky spravované domény selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-176">When running Service Fabric in Azure, fault domains are managed automatically.</span></span> <span data-ttu-id="d1bdf-177">V jiných prostředích nemusí být.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-177">In other environments they may not be.</span></span> <span data-ttu-id="d1bdf-178">Pokud vytváříte vlastní clustery místně, že toomap a plánování rozložení domény selhání správně.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-178">If you're building your own clusters on premises, be sure toomap and plan your fault domain layout correctly.</span></span>

<span data-ttu-id="d1bdf-179">Domén upgradu jsou užitečné pro modelování oblasti, kde softwaru bude upgradován toobe v hello stejný čas.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-179">Upgrade Domains are useful for modeling areas where software is going toobe upgraded at hello same time.</span></span> <span data-ttu-id="d1bdf-180">Z toho důvodu upgradu domény definovat také často hello hranice, kde je softwaru během plánované upgrady ukončena.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-180">Because of this, Upgrade Domains also often define hello boundaries where software is taken down during planned upgrades.</span></span> <span data-ttu-id="d1bdf-181">Upgrady Service Fabric a vaše služby postupujte podle hello stejného modelu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-181">Upgrades of both Service Fabric and your services follow hello same model.</span></span> <span data-ttu-id="d1bdf-182">Další informace o vrácení upgrady, domén upgradu a hello Service Fabric stavu modelu, která pomáhá zabránit neúmyslnému změny v hello clusteru a služby, které mají vliv najdete v těchto dokumentů:</span><span class="sxs-lookup"><span data-stu-id="d1bdf-182">For more on rolling upgrades, upgrade domains, and hello Service Fabric health model that helps prevent unintended changes from impacting hello cluster and your service, see these documents:</span></span>

 - [<span data-ttu-id="d1bdf-183">Upgrade aplikace</span><span class="sxs-lookup"><span data-stu-id="d1bdf-183">Application Upgrade</span></span>](service-fabric-application-upgrade.md)
 - [<span data-ttu-id="d1bdf-184">Kurz upgradu aplikace</span><span class="sxs-lookup"><span data-stu-id="d1bdf-184">Application Upgrade Tutorial</span></span>](service-fabric-application-upgrade-tutorial.md)
 - [<span data-ttu-id="d1bdf-185">Model stavu prostředků infrastruktury služby</span><span class="sxs-lookup"><span data-stu-id="d1bdf-185">Service Fabric Health Model</span></span>](service-fabric-health-introduction.md)

<span data-ttu-id="d1bdf-186">Můžete vizualizovat hello rozložení pomocí mapy hello clusteru v clusteru [Service Fabric Explorer](service-fabric-visualizing-your-cluster.md):</span><span class="sxs-lookup"><span data-stu-id="d1bdf-186">You can visualize hello layout of your cluster using hello cluster map provided in [Service Fabric Explorer](service-fabric-visualizing-your-cluster.md):</span></span>

<span data-ttu-id="d1bdf-187"><center>
![Uzly rozloženy domén selhání v Service Fabric Exploreru][sfx-cluster-map]
</center></span><span class="sxs-lookup"><span data-stu-id="d1bdf-187"><center>
![Nodes spread across fault domains in Service Fabric Explorer][sfx-cluster-map]
</center></span></span>

> [!NOTE]
> <span data-ttu-id="d1bdf-188">Modelování oblasti nezdaří, vrácení upgrady, spuštěním mnoho instancí kódu služby a stav, tooensure pravidla umístění vaší služby spusťte napříč doménami selhání a upgradu a sledování stavu předdefinované jsou právě **některé** z hello Funkce, které poskytuje Service Fabric v pořadí tookeep normální provozní problémy a chyby z měnící do havárie.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-188">Modeling areas of failure, rolling upgrades, running many instances of your service code and state, placement rules tooensure your services run across fault and upgrade domains, and built-in health monitoring are just **some** of hello features that Service Fabric provides in order tookeep normal operational issues and failures from turning into disasters.</span></span> 
>

### <a name="handling-simultaneous-hardware-or-software-failures"></a><span data-ttu-id="d1bdf-189">Zpracování souběžných selhání hardwaru nebo softwaru</span><span class="sxs-lookup"><span data-stu-id="d1bdf-189">Handling simultaneous hardware or software failures</span></span>
<span data-ttu-id="d1bdf-190">Vyšší už jsme mluvili o jeden selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-190">Above we talked about single failures.</span></span> <span data-ttu-id="d1bdf-191">Jak vidíte, jsou právě udržováním více kopií hello kód (a stavu) spuštěná v doménách selhání a upgradu snadno toohandle pro bezstavové a stavové služby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-191">As you can see, are easy toohandle for both stateless and stateful services just by keeping more copies of hello code (and state) running across fault and upgrade domains.</span></span> <span data-ttu-id="d1bdf-192">Více souběžných náhodné chyby může také dojít.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-192">Multiple simultaneous random failures can also happen.</span></span> <span data-ttu-id="d1bdf-193">Jedná se o pravděpodobnější toolead tooan skutečné po havárii.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-193">These are more likely toolead tooan actual disaster.</span></span>


### <a name="random-failures-leading-tooservice-failures"></a><span data-ttu-id="d1bdf-194">Náhodné chyby úvodní tooservice selhání</span><span class="sxs-lookup"><span data-stu-id="d1bdf-194">Random failures leading tooservice failures</span></span>
<span data-ttu-id="d1bdf-195">Řekněme, že služba hello provedla `InstanceCount` 5 a několik uzlů, které jsou spuštěné tyto instance všechny chybné v hello stejný čas.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-195">Let's say that hello service had an `InstanceCount` of 5, and several nodes running those instances all failed at hello same time.</span></span> <span data-ttu-id="d1bdf-196">Service Fabric reaguje automaticky vytváření instancí nahrazení na jiných uzlech.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-196">Service Fabric responds by automatically creating replacement instances on other nodes.</span></span> <span data-ttu-id="d1bdf-197">Bude pokračovat, dokud hello služby je zpět tooits požadovaného počtu instancí vytváření nahrazení.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-197">It will continue creating replacements until hello service is back tooits desired instance count.</span></span> <span data-ttu-id="d1bdf-198">Například Řekněme došlo bezstavové služby s `InstanceCount`-1, což znamená, běží na všechny platné uzly v clusteru hello.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-198">As another example, let's say there was a stateless service with an `InstanceCount`of -1, meaning it runs on all valid nodes in hello cluster.</span></span> <span data-ttu-id="d1bdf-199">Řekněme, že některé z těchto instancí byly toofail.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-199">Let's say that some of those instances were toofail.</span></span> <span data-ttu-id="d1bdf-200">V takovém případě Service Fabric oznámení, že není v jeho požadovaný stav hello služby a pokusí toocreate hello instance na uzlech hello tam, kde jsou chybějící.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-200">In this case, Service Fabric notices that hello service is not in its desired state, and tries toocreate hello instances on hello nodes where they are missing.</span></span> 

<span data-ttu-id="d1bdf-201">Pro stavové služby hello situaci závisí na jestli hello služby obsahuje trvalé stavu, nebo ne.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-201">For stateful services hello situation depends on whether hello service has persisted state or not.</span></span> <span data-ttu-id="d1bdf-202">Také závisí na tom, kolik služba hello repliky provedla a kolik se nezdařilo.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-202">It also depends on how many replicas hello service had and how many failed.</span></span> <span data-ttu-id="d1bdf-203">Určení, zda došlo k havárii pro stavové služby a správu odpovídá tří fází:</span><span class="sxs-lookup"><span data-stu-id="d1bdf-203">Determining whether a disaster occurred for a stateful service and managing it follows three stages:</span></span>

1. <span data-ttu-id="d1bdf-204">Určení, zda existuje došlo ke ztrátě kvora nebo ne</span><span class="sxs-lookup"><span data-stu-id="d1bdf-204">Determining if there has been quorum loss or not</span></span>
 - <span data-ttu-id="d1bdf-205">Ztrátě kvora je vždy, když jsou většinou hello repliky stavové služby dolů na hello stejnou dobu, včetně hello primární.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-205">A quorum loss is any time a majority of hello replicas of a stateful service are down at hello same time, including hello Primary.</span></span>
2. <span data-ttu-id="d1bdf-206">Určení, zda ztrátě kvora hello je trvalé, či nikoliv</span><span class="sxs-lookup"><span data-stu-id="d1bdf-206">Determining if hello quorum loss is permanent or not</span></span>
 - <span data-ttu-id="d1bdf-207">Většina hello čas selhání je přechodný.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-207">Most of hello time, failures are transient.</span></span> <span data-ttu-id="d1bdf-208">Procesy, jsou restartovány, uzly se restartují, virtuální počítače jsou relaunched, retušovat síťové oddíly.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-208">Processes are restarted, nodes are restarted, VMs are relaunched, network partitions heal.</span></span> <span data-ttu-id="d1bdf-209">V některých případech ale selhání jsou trvalé.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-209">Sometimes though, failures are permanent.</span></span> 
    - <span data-ttu-id="d1bdf-210">Pro služby bez trvalý stav, selhání kvorum nebo více replik výsledků _okamžitě_ ve ztrátě kvora trvalé.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-210">For services without persisted state, a failure of a quorum or more of replicas results _immediately_ in permanent quorum loss.</span></span> <span data-ttu-id="d1bdf-211">Zjistí-li Service Fabric ztrátě kvora v stavové služby dočasnou, pokračuje hned dataloss toostep 3 deklarováním (potenciální).</span><span class="sxs-lookup"><span data-stu-id="d1bdf-211">When Service Fabric detects quorum loss in a stateful non-persistent service, it immediately proceeds toostep 3 by declaring (potential) dataloss.</span></span> <span data-ttu-id="d1bdf-212">Pokračováním toodataloss má smysl, protože Service Fabric ví, že neexistuje žádný bod v čeká na hello repliky toocome zpět, protože i v případě, že byly obnoveny by být prázdný.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-212">Proceeding toodataloss makes sense because Service Fabric knows that there's no point in waiting for hello replicas toocome back, because even if they were recovered they would be empty.</span></span>
    - <span data-ttu-id="d1bdf-213">Pro stavové služby trvalé způsobí selhání kvorum nebo více replik Service Fabric toostart čekání hello repliky toocome zpět a obnovit kvora.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-213">For stateful persistent services, a failure of a quorum or more of replicas causes Service Fabric toostart waiting for hello replicas toocome back and restore quorum.</span></span> <span data-ttu-id="d1bdf-214">To vede k výpadku služeb pro libovolný _zapíše_ toohello vliv služby hello oddílu (nebo "sady replik").</span><span class="sxs-lookup"><span data-stu-id="d1bdf-214">This results in a service outage for any _writes_ toohello affected partition (or "replica set") of hello service.</span></span> <span data-ttu-id="d1bdf-215">Ale čtení může být stále možné s omezenou konzistence záruky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-215">However, reads may still be possible with reduced consistency guarantees.</span></span> <span data-ttu-id="d1bdf-216">vzhledem k tomu, že budete pokračovat, je (potenciální) událost dataloss a představuje další rizika je nekonečno, Hello výchozí množství času, kterou Service Fabric čeká kvora toobe obnovit.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-216">hello default amount of time that Service Fabric waits for quorum toobe restored is infinite, since proceeding is a (potential) dataloss event and carries other risks.</span></span> <span data-ttu-id="d1bdf-217">Přepsání výchozího hello `QuorumLossWaitDuration` hodnotu je možné, ale není to doporučeno.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-217">Overriding hello default `QuorumLossWaitDuration` value is possible but is not recommended.</span></span> <span data-ttu-id="d1bdf-218">Místo toho v tuto chvíli všechny třeba se toorestore hello dolů repliky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-218">Instead at this time, all efforts should be made toorestore hello down replicas.</span></span> <span data-ttu-id="d1bdf-219">To vyžaduje přinesou hello uzlů, které jsou dolů zpět a zajistit, aby se znovu připojit hello jednotky, kde budou uloženy hello místní trvalý stav.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-219">This requires bringing hello nodes that are down back up, and ensuring that they can remount hello drives where they stored hello local persistent state.</span></span> <span data-ttu-id="d1bdf-220">Pokud ztrátě kvora hello je způsobena selhání procesu, Service Fabric automaticky pokusí toorecreate hello procesy a restartujte hello repliky v nich.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-220">If hello quorum loss is caused by process failure, Service Fabric automatically tries toorecreate hello processes and restart hello replicas inside them.</span></span> <span data-ttu-id="d1bdf-221">Pokud se to nezdaří, Service Fabric hlásí stav chyby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-221">If this fails, Service Fabric reports health errors.</span></span> <span data-ttu-id="d1bdf-222">Pokud tyto lze vyřešit pak hello repliky obvykle se vrátit.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-222">If these can be resolved then hello replicas usually come back.</span></span> <span data-ttu-id="d1bdf-223">V některých případech ale hello repliky nelze převést zpět.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-223">Sometimes, though, hello replicas can't be brought back.</span></span> <span data-ttu-id="d1bdf-224">Například jednotky hello všechny nezdařila nebo hello počítače fyzicky zničeno nějakým způsobem.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-224">For example, hello drives may all have failed, or hello machines physically destroyed somehow.</span></span> <span data-ttu-id="d1bdf-225">V těchto případech máme teď ztráty trvalé kvora.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-225">In these cases, we now have a permanent quorum loss event.</span></span> <span data-ttu-id="d1bdf-226">toostop Service Fabric tootell čekání hello dolů zpět, repliky toocome Správce clusteru musíte určit, které oddíly, které služby jsou vliv a volání hello `Repair-ServiceFabricPartition -PartitionId` nebo ` System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)` rozhraní API.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-226">tootell Service Fabric toostop waiting for hello down replicas toocome back, a cluster administrator must determine which partitions of which services are affected and call hello `Repair-ServiceFabricPartition -PartitionId` or ` System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)` API.</span></span>  <span data-ttu-id="d1bdf-227">Toto rozhraní API umožňuje zadání hello ID hello oddílu toomove mimo QuorumLoss a do potenciální dataloss.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-227">This API allows specifying hello ID of hello partition toomove out of QuorumLoss and into potential dataloss.</span></span>

> [!NOTE]
> <span data-ttu-id="d1bdf-228">Je _nikdy_ bezpečné toouse toto rozhraní API jinak než v cílové způsob, jak na konkrétní oddíly.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-228">It is _never_ safe toouse this API other than in a targeted way against specific partitions.</span></span> 
>

3. <span data-ttu-id="d1bdf-229">Určení, zda došlo ke ztrátě skutečná data a obnovení ze zálohy</span><span class="sxs-lookup"><span data-stu-id="d1bdf-229">Determining if there has been actual data loss, and restoring from backups</span></span>
  - <span data-ttu-id="d1bdf-230">Když Service Fabric volá hello `OnDataLossAsync` metoda je vždy z důvodu _by mohly vzbuzovat podezření_ dataloss.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-230">When Service Fabric calls hello `OnDataLossAsync` method it is always because of _suspected_ dataloss.</span></span> <span data-ttu-id="d1bdf-231">Service Fabric zajistí, že toto volání se doručí toohello _nejlepší_ zbývající repliky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-231">Service Fabric ensures that this call is delivered toohello _best_ remaining replica.</span></span> <span data-ttu-id="d1bdf-232">Toto je, podle toho, která repliky udělal hello většina průběh.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-232">This is whichever replica has made hello most progress.</span></span> <span data-ttu-id="d1bdf-233">Hello důvod vždy říkáme _by mohly vzbuzovat podezření_ dataloss je, že je možné, zbývající repliky hello ve skutečnosti má všechny stejného stavu jako v době hello primární snížila.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-233">hello reason we always say _suspected_ dataloss is that it is possible that hello remaining replica actually has all same state as hello Primary did when it went down.</span></span> <span data-ttu-id="d1bdf-234">Ale bez tohoto stavu toocompare ho, neexistuje žádný funkční způsob pro Service Fabric nebo operátory tooknow pro jistotu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-234">However, without that state toocompare it to, there's no good way for Service Fabric or operators tooknow for sure.</span></span> <span data-ttu-id="d1bdf-235">V tomto okamžiku Service Fabric také zná hello další repliky nejsou vracející se zpět.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-235">At this point, Service Fabric also knows hello other replicas are not coming back.</span></span> <span data-ttu-id="d1bdf-236">Který byl hello rozhodnutí provedeny, když jsme zastavil čeká na hello tooresolve ztráty kvora, sám sebe.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-236">That was hello decision made when we stopped waiting for hello quorum loss tooresolve itself.</span></span> <span data-ttu-id="d1bdf-237">Hello nejlepším řešením pro službu hello je obvykle toofreeze a počkejte konkrétní zásahů správce.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-237">hello best course of action for hello service is usually toofreeze and wait for specific administrative intervention.</span></span> <span data-ttu-id="d1bdf-238">Jaké jsou proto Typická implementace hello `OnDataLossAsync` metoda udělat?</span><span class="sxs-lookup"><span data-stu-id="d1bdf-238">So what does a typical implementation of hello `OnDataLossAsync` method do?</span></span>
  - <span data-ttu-id="d1bdf-239">Nejprve protokolu, který `OnDataLossAsync` byla spuštěna a spusťte vypnout všechny potřebné pro správu výstrahy.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-239">First, log that `OnDataLossAsync` has been triggered, and fire off any necessary administrative alerts.</span></span>
   - <span data-ttu-id="d1bdf-240">Obvykle v tomto okamžiku toopause a počkejte další rozhodnutí a toobe ručně prováděné akce provedena.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-240">Usually at this point, toopause and wait for further decisions and manual actions toobe taken.</span></span> <span data-ttu-id="d1bdf-241">Je to proto, že i když jsou k dispozici zálohování, které potřebují toobe připravený.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-241">This is because even if backups are available they may need toobe prepared.</span></span> <span data-ttu-id="d1bdf-242">Například pokud dva různé služby koordinaci informace, tyto zálohy může být nutné toobe upravit v pořadí tooensure, který je konzistentní po obnovení hello se stane, že informace hello tyto dvě služby zajímají.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-242">For example, if two different services coordinate information, those backups may need toobe modified in order tooensure that once hello restore happens that hello information those two services care about is consistent.</span></span> 
  - <span data-ttu-id="d1bdf-243">Často je zde také některé další telemetrií nebo výfukového ze služby hello.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-243">Often there is also some other telemetry or exhaust from hello service.</span></span> <span data-ttu-id="d1bdf-244">Tato metadata mohou být obsaženy v jiných služeb nebo v protokolech.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-244">This metadata may be contained in other services or in logs.</span></span> <span data-ttu-id="d1bdf-245">Tato informace může být použité potřebné toodetermine, kdyby všechny volání přijme a zpracuje v hello primární, které se nacházejí na replice konkrétní zálohování nebo replikované toothis hello.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-245">This information can be used needed toodetermine if there were any calls received and processed at hello primary that were not present in hello backup or replicated toothis particular replica.</span></span> <span data-ttu-id="d1bdf-246">To může být nutné toobe přehraná nebo je přidán toohello zálohování předtím, než je možné je obnovení.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-246">These may need toobe replayed or added toohello backup before restoration is feasible.</span></span>  
   - <span data-ttu-id="d1bdf-247">Porovnání hello zbývající toothat stavu repliky obsažené v všechny zálohy, které jsou k dispozici.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-247">Comparisons of hello remaining replica's state toothat contained in any backups that are available.</span></span> <span data-ttu-id="d1bdf-248">Pokud pomocí hello Service Fabric spolehlivé kolekcí, pak jsou nástroje a zpracuje k dispozici pro to, které jsou popsané v [v tomto článku](service-fabric-reliable-services-backup-restore.md).</span><span class="sxs-lookup"><span data-stu-id="d1bdf-248">If using hello Service Fabric reliable collections then there are tools and processes available for doing so, described in [this article](service-fabric-reliable-services-backup-restore.md).</span></span> <span data-ttu-id="d1bdf-249">cílem Hello je toosee Pokud stačí hello stavu v rámci hello repliky nebo jaké hello zálohování může být také chybí.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-249">hello goal is toosee if hello state within hello replica is sufficient, or also what hello backup may be missing.</span></span>
  - <span data-ttu-id="d1bdf-250">Jednou hello porovnání se provádí, a pokud potřebné hello obnovení dokončeno, hello kódu služby by měla vrátit hodnotu true, pokud nebyly provedeny žádné změny stavu.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-250">Once hello comparison is done, and if necessary hello restore completed, hello service code should return true if any state changes were made.</span></span> <span data-ttu-id="d1bdf-251">V případě repliky hello zjistíte, že byl hello nejlépe k dispozici kopii hello stavu a provedeny žádné změny, pak se vraťte hodnotu false.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-251">If hello replica determined that it was hello best available copy of hello state and made no changes, then return false.</span></span> <span data-ttu-id="d1bdf-252">Pravda označuje, že jakékoli _jiných_ zbývající repliky může být nyní nekonzistentní tímto tématem.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-252">True indicates that any _other_ remaining replicas may now be inconsistent with this one.</span></span> <span data-ttu-id="d1bdf-253">Bude být zrušen a znovu vytvořen z této repliky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-253">They will be dropped and rebuilt from this replica.</span></span> <span data-ttu-id="d1bdf-254">NEPRAVDA označuje, že nebyly provedeny žádné změny stavu, takže hello další repliky můžete ponechat co mají.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-254">False indicates that no state changes were made, so hello other replicas can keep what they have.</span></span> 

<span data-ttu-id="d1bdf-255">Je důležité, že autoři služby praxi potenciální dataloss a scénářích selhání, před služby jsou někdy nasazením v produkčním prostředí.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-255">It is critically important that service authors practice potential dataloss and failure scenarios before services are ever deployed in production.</span></span> <span data-ttu-id="d1bdf-256">tooprotect proti hello možnost dataloss, je důležité tooperiodically [zálohování stavu hello](service-fabric-reliable-services-backup-restore.md) všech geograficky redundantní úložiště tooa stavové služby.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-256">tooprotect against hello possibility of dataloss, it is important tooperiodically [back up hello state](service-fabric-reliable-services-backup-restore.md) of any of your stateful services tooa geo-redundant store.</span></span> <span data-ttu-id="d1bdf-257">Musí také zkontrolujte, zda máte možnost toorestore hello ho.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-257">You must also ensure that you have hello ability toorestore it.</span></span> <span data-ttu-id="d1bdf-258">Vzhledem k tomu, že zálohy mnoho různých služeb se provádějí v různou dobu, musíte po obnovení mít vašim službám konzistentní zobrazení vzájemně tooensure.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-258">Since backups of many different services are taken at different times, you need tooensure that after a restore your services have a consistent view of each other.</span></span> <span data-ttu-id="d1bdf-259">Představte si třeba situaci, kde jedna služba vygeneruje číslo a uloží ji pak odešle ji tooanother služba, která také ukládá ji.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-259">For example, consider a situation where one service generates a number and stores it, then sends it tooanother service that also stores it.</span></span> <span data-ttu-id="d1bdf-260">Po obnovení můžete zjistit hello druhý služba má hello číslo, ale hello nejprve neexistuje, protože jeho zálohování nezahrnuli tuto operaci.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-260">After a restore, you might discover that hello second service has hello number but hello first does not, because it's backup didn't include that operation.</span></span>

<span data-ttu-id="d1bdf-261">Pokud zjistíte, že zbývající hello repliky jsou nedostatečné toocontinue z ve scénáři dataloss a nemůže rekonstrukci stav služby z telemetrie nebo výfukového, hello četnost záloh určí vaší nejlepší plánovaného bodu možné obnovení (RPO) .</span><span class="sxs-lookup"><span data-stu-id="d1bdf-261">If you find out that hello remaining replicas are insufficient toocontinue from in a dataloss scenario, and you can't reconstruct service state from telemetry or exhaust, hello frequency of your backups determines your best possible recovery point objective (RPO).</span></span> <span data-ttu-id="d1bdf-262">Service Fabric nabízí celou řadu nástrojů pro testování různých scénářích selhání, včetně trvalé kvora a dataloss, které vyžadují obnovení ze zálohy.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-262">Service Fabric provides many tools for testing various failure scenarios, including permanent quorum and dataloss requiring restoration from a backup.</span></span> <span data-ttu-id="d1bdf-263">Tyto scénáře jsou zahrnuty jako součást nástrojů testovatelnosti Service Fabric spravuje hello selhání Analysis Service.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-263">These scenarios are included as a part of Service Fabric's testability tools, managed by hello Fault Analysis Service.</span></span> <span data-ttu-id="d1bdf-264">Další informace o těchto nástrojů a vzory je k dispozici [zde](service-fabric-testability-overview.md).</span><span class="sxs-lookup"><span data-stu-id="d1bdf-264">More info on those tools and patterns is available [here](service-fabric-testability-overview.md).</span></span> 

> [!NOTE]
> <span data-ttu-id="d1bdf-265">Systémových služeb může také dojít k ztráty kvora, s hello vlivem konkrétní toohello služby nejistá.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-265">System services can also suffer quorum loss, with hello impact being specific toohello service in question.</span></span> <span data-ttu-id="d1bdf-266">Pro instanci ztrátě kvora ve službě pojmenování hello ovlivňuje překlad IP adres, zatímco ztrátě kvora ve službě service manager převzetí služeb při selhání hello blokuje vytvoření nové služby a převzetí služeb při selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-266">For instance, quorum loss in hello naming service impacts name resolution, whereas quorum loss in hello failover manager service blocks new service creation and failovers.</span></span> <span data-ttu-id="d1bdf-267">Při hello Service Fabric systémových služeb podle hello stejný vzor jako vaší služby pro správu stavu, není doporučeno toomove mají pokusit o je mimo ztrátě kvora a do potenciální dataloss.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-267">While hello Service Fabric system services follow hello same pattern as your services for state management, it is not recommended that you should attempt toomove them out of Quorum Loss and into potential dataloss.</span></span> <span data-ttu-id="d1bdf-268">Hello doporučení se místo toho příliš[vyhledat podporu](service-fabric-support.md) toodetermine řešení, které je cílem tooyour konkrétní situaci.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-268">hello recommendation is instead too[seek support](service-fabric-support.md) toodetermine a solution that is targeted tooyour specific situation.</span></span>  <span data-ttu-id="d1bdf-269">Obvykle je vhodnější toosimply čekání do hello dolů návratový repliky.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-269">Usually it is preferable toosimply wait until hello down replicas return.</span></span>
>

## <a name="availability-of-hello-service-fabric-cluster"></a><span data-ttu-id="d1bdf-270">Dostupnost clusteru Service Fabric hello</span><span class="sxs-lookup"><span data-stu-id="d1bdf-270">Availability of hello Service Fabric cluster</span></span>
<span data-ttu-id="d1bdf-271">Obecně řečeno samotného clusteru Service Fabric hello je vysoce distribuovaném prostředí s žádný jediný bod selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-271">Generally speaking, hello Service Fabric cluster itself is a highly distributed environment with no single points of failure.</span></span> <span data-ttu-id="d1bdf-272">Selhání jednoho libovolného uzlu nezpůsobí dostupnosti nebo problémy se spolehlivosti pro hello cluster primárně, protože hello Service Fabric systémových služeb podle dříve stejné pokyny uvedenými hello: budou vždy spustit s tři nebo více replik ve výchozím nastavení a ty služby systému, které jsou bezstavové spouštět na všech uzlech.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-272">A failure of any one node will not cause availability or reliability issues for hello cluster, primarily because hello Service Fabric system services follow hello same guidelines provided earlier: they always run with three or more replicas by default, and those system services that are stateless run on all nodes.</span></span> <span data-ttu-id="d1bdf-273">Hello základní sítě Service Fabric a vrstvy detekce selhání jsou plně distribuován.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-273">hello underlying Service Fabric networking and failure detection layers are fully distributed.</span></span> <span data-ttu-id="d1bdf-274">Většina systémových služeb můžete znovu sestavit z metadat v clusteru hello nebo vědět, jak tooresynchronize jejich stavu z jiného místa.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-274">Most system services can be rebuilt from metadata in hello cluster, or know how tooresynchronize their state from other places.</span></span> <span data-ttu-id="d1bdf-275">Hello dostupnost clusteru hello mohou způsobit ohrožení, pokud systémových služeb do kvora případů ztráty jako ty, které jsou popsané výše.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-275">hello availability of hello cluster can become compromised if system services get into quorum loss situations like those described above.</span></span> <span data-ttu-id="d1bdf-276">V těchto případech nemusí být možné tooperform určité operace na clusteru hello jako spuštěním upgradu nebo nasazování nových služeb, ale samotný cluster hello je pořád zapnutý.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-276">In these cases you may not be able tooperform certain operations on hello cluster like starting an upgrade or deploying new services, but hello cluster itself is still up.</span></span> <span data-ttu-id="d1bdf-277">Služeb v již byla spuštěna zůstane spuštěný v těchto podmínkách, pokud potřebují zápisy toohello systému služby toocontinue funguje.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-277">Services on already running will remain running in these conditions unless they require writes toohello system services toocontinue functioning.</span></span> <span data-ttu-id="d1bdf-278">Například pokud hello Failover Manager je ve ztrátě kvora všechny služby bude pokračovat toorun, ale žádné služby, které nesplní nebude možné tooautomatically restartování, vzhledem k tomu, že to vyžaduje hello účast hello Správce převzetí služeb při selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-278">For example, if hello Failover Manager is in quorum loss all services will continue toorun, but any services that fail will not be able tooautomatically restart, since this requires hello involvement of hello Failover Manager.</span></span> 

### <a name="failures-of-a-datacenter-or-azure-region"></a><span data-ttu-id="d1bdf-279">Selhání datacenter nebo oblast Azure</span><span class="sxs-lookup"><span data-stu-id="d1bdf-279">Failures of a datacenter or Azure region</span></span>
<span data-ttu-id="d1bdf-280">Ve výjimečných případech může stát fyzické datového centra není dočasně k dispozici z důvodu tooloss napájení nebo připojením k síti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-280">In rare cases, a physical data center can become temporarily unavailable due tooloss of power or network connectivity.</span></span> <span data-ttu-id="d1bdf-281">V těchto případech clusterů Service Fabric a služeb na tomto datovém centru nebo v oblasti Azure k dispozici.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-281">In these cases, your Service Fabric clusters and services in that datacenter or Azure region will be unavailable.</span></span> <span data-ttu-id="d1bdf-282">Ale _vašich dat se zachová, i_.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-282">However, _your data is preserved_.</span></span> <span data-ttu-id="d1bdf-283">Pro clustery spuštěná v Azure, můžete zobrazit aktualizace na výpadky na hello [Azure stavové stránce][azure-status-dashboard].</span><span class="sxs-lookup"><span data-stu-id="d1bdf-283">For clusters running in Azure, you can view updates on outages on hello [Azure status page][azure-status-dashboard].</span></span> <span data-ttu-id="d1bdf-284">V hello vysoce nepravděpodobné událost, která fyzické datového centra je částečně nebo zcela zničení všech clusterů Service Fabric hostované existuje nebo hello služby v nich by mohly být ztraceny.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-284">In hello highly unlikely event that a physical data center is partially or fully destroyed, any Service Fabric clusters hosted there or hello services inside them could be lost.</span></span> <span data-ttu-id="d1bdf-285">To zahrnuje všechny stavu nejsou zálohovány mimo dané datacenter nebo oblasti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-285">This includes any state not backed up outside of that datacenter or region.</span></span>

<span data-ttu-id="d1bdf-286">Není k dispozici dvě různé strategie pro zbývajících hello trvalé nebo dlouhodobě selhání jednoho datového centra nebo oblasti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-286">There's two different strategies for surviving hello permanent or sustained failure of a single datacenter or region.</span></span> 

1. <span data-ttu-id="d1bdf-287">Spusťte samostatných clusterů Service Fabric v několika takových oblastech a využívat některé mechanismus pro převzetí služeb při selhání a navrácení služeb mezi těchto prostředích.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-287">Run separate Service Fabric clusters in multiple such regions, and utilize some mechanism for failover and fail-back between these environments.</span></span> <span data-ttu-id="d1bdf-288">Tento druh více clusteru aktivní aktivní nebo aktivní – pasivní modelu vyžaduje další operace správy a kód.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-288">This sort of multi-cluster active-active or active-passive model requires additional management and operations code.</span></span> <span data-ttu-id="d1bdf-289">Také je vyžadována koordinaci záloh z hello služby v jednom datacenter nebo oblast, aby byly k dispozici v dalších datových center nebo oblastech, pokud jeden selže.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-289">This also requires coordination of backups from hello services in one datacenter or region so that they are available in other datacenters or regions when one fails.</span></span> 
2. <span data-ttu-id="d1bdf-290">Spusťte jeden cluster Service Fabric, která přesahuje více datových centrech nebo oblasti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-290">Run a single Service Fabric cluster that spans multiple datacenters or regions.</span></span> <span data-ttu-id="d1bdf-291">minimální podporované konfigurace pro tento Hello je tři datových centrech nebo oblasti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-291">hello minimum supported configuration for this is three datacenters or regions.</span></span> <span data-ttu-id="d1bdf-292">Hello doporučený počet oblastí nebo datových centrech je pět.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-292">hello recommended number of regions or datacenters is five.</span></span> <span data-ttu-id="d1bdf-293">To vyžaduje složitější topologie clusteru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-293">This requires a more complex cluster topology.</span></span> <span data-ttu-id="d1bdf-294">Hello výhodou tohoto modelu je však, že selhání jednoho datového centra nebo oblasti je převeden po havárii na normální selhání.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-294">However, hello benefit of this model is that failure of one datacenter or region is converted from a disaster into a normal failure.</span></span> <span data-ttu-id="d1bdf-295">Tyto chyby mohou být zpracována hello mechanismy, které fungují pro clustery v jedné oblasti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-295">These failures can be handled by hello mechanisms that work for clusters within a single region.</span></span> <span data-ttu-id="d1bdf-296">Domén selhání, domén upgradu a pravidla pro umístění Service Fabric Ujistěte se, že úlohy distribuují tak, aby se tolerovat selhání normální.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-296">Fault domains, upgrade domains, and Service Fabric's placement rules ensure workloads are distributed so that they tolerate normal failures.</span></span> <span data-ttu-id="d1bdf-297">Další informace o zásadách, které vám mohou pomoci provoz služby v tomto typu clusteru, najdete v tématu na [zásady umístění](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)</span><span class="sxs-lookup"><span data-stu-id="d1bdf-297">For more information on policies that can help operate services in this type of cluster, read up on [placement policies](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)</span></span>

### <a name="random-failures-leading-toocluster-failures"></a><span data-ttu-id="d1bdf-298">Náhodné chyby úvodní toocluster selhání</span><span class="sxs-lookup"><span data-stu-id="d1bdf-298">Random failures leading toocluster failures</span></span>
<span data-ttu-id="d1bdf-299">Service Fabric má hello konceptu uzly počáteční hodnoty.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-299">Service Fabric has hello concept of Seed Nodes.</span></span> <span data-ttu-id="d1bdf-300">Jedná se o uzly, které udržují hello dostupnost hello základní clusteru.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-300">These are nodes that maintain hello availability of hello underlying cluster.</span></span> <span data-ttu-id="d1bdf-301">Tyto uzly pomoct tooensure hello clusteru zůstane až tím zřízením zapůjčení s ostatními uzly a slouží jako tiebreakers během určité druhy chyb v síti.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-301">These nodes help tooensure hello cluster remains up by establishing leases with other nodes and serving as tiebreakers during certain kinds of network failures.</span></span> <span data-ttu-id="d1bdf-302">Pokud náhodné chyby odebrat Většina uzlů hello počáteční hodnoty v hello clusteru a jejich zpět nedostaly, hello cluster automaticky vypne.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-302">If random failures remove a majority of hello seed nodes in hello cluster and they are not brought back, hello cluster automatically shuts down.</span></span> <span data-ttu-id="d1bdf-303">V Azure, jsou automaticky spravovány uzly počáteční hodnoty: jsou distribuovány prostřednictvím doménách selhání hello k dispozici a upgradu, pokud jeden počáteční uzel je odebrán z clusteru hello jiný bude vytvořena na příslušné místo.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-303">In Azure, Seed Nodes are automatically managed: they are distributed over hello available fault and upgrade domains, and if a single seed node is removed from hello cluster another one will be created in its place.</span></span> 

<span data-ttu-id="d1bdf-304">V samostatných clusterů Service Fabric a Azure je hello "Primární uzel typu" hello, ten, který spouští semen hello.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-304">In both standalone Service Fabric clusters and Azure, hello "Primary Node Type" is hello one that runs hello seeds.</span></span> <span data-ttu-id="d1bdf-305">Při definování typu primárního uzlu, Service Fabric se automaticky využít výhod hello počet uzlů zajištěna vytvořením uzly počáteční hodnoty too9 a 9 repliky jednotlivých hello systémových služeb.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-305">When defining a primary node type, Service Fabric will automatically take advantage of hello number of nodes provided by creating up too9 seed nodes and 9 replicas of each of hello system services.</span></span> <span data-ttu-id="d1bdf-306">Pokud sadu náhodné chyby používá současně se většina těchto replik služby systému, zadá hello systémových služeb ztráty kvora, jsme popsaný výše.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-306">If a set of random failures takes out a majority of those system service replicas simultaneously, hello system services will enter quorum loss, as we described above.</span></span> <span data-ttu-id="d1bdf-307">Pokud se Většina uzlů hello počáteční hodnoty jsou ztraceny, hello clusteru se zastaví krátce po.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-307">If a majority of hello seed nodes are lost, hello cluster will shut down soon after.</span></span>

## <a name="next-steps"></a><span data-ttu-id="d1bdf-308">Další kroky</span><span class="sxs-lookup"><span data-stu-id="d1bdf-308">Next steps</span></span>
- <span data-ttu-id="d1bdf-309">Zjistěte, jak toosimulate různých selháních pomocí hello [testovatelnosti framework](service-fabric-testability-overview.md)</span><span class="sxs-lookup"><span data-stu-id="d1bdf-309">Learn how toosimulate various failures using hello [testability framework](service-fabric-testability-overview.md)</span></span>
- <span data-ttu-id="d1bdf-310">Přečtěte si další prostředky pro zotavení po havárii a vysoká dostupnost.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-310">Read other disaster-recovery and high-availability resources.</span></span> <span data-ttu-id="d1bdf-311">Microsoft publikuje velké množství pokyny v těchto tématech.</span><span class="sxs-lookup"><span data-stu-id="d1bdf-311">Microsoft has published a large amount of guidance on these topics.</span></span> <span data-ttu-id="d1bdf-312">Při některé z těchto dokumentů naleznete toospecific techniky pro použití v jiných produktech, obsahují mnoho obecné osvědčené postupy, které můžete použít v kontextu. hello Service Fabric také:</span><span class="sxs-lookup"><span data-stu-id="d1bdf-312">While some of these documents refer toospecific techniques for use in other products, they contain many general best practices you can apply in hello Service Fabric context as well:</span></span>
  - [<span data-ttu-id="d1bdf-313">Kontrolní seznam k dostupnosti</span><span class="sxs-lookup"><span data-stu-id="d1bdf-313">Availability checklist</span></span>](../best-practices-availability-checklist.md)
  - [<span data-ttu-id="d1bdf-314">Provádění postupu zotavení po havárii</span><span class="sxs-lookup"><span data-stu-id="d1bdf-314">Performing a disaster recovery drill</span></span>](../sql-database/sql-database-disaster-recovery-drills.md)
  - <span data-ttu-id="d1bdf-315">[Zotavení po havárii a vysoká dostupnost pro aplikace Azure][dr-ha-guide]</span><span class="sxs-lookup"><span data-stu-id="d1bdf-315">[Disaster recovery and high availability for Azure applications][dr-ha-guide]</span></span>
- <span data-ttu-id="d1bdf-316">Informace o [možnostech podpory pro Service Fabric](service-fabric-support.md)</span><span class="sxs-lookup"><span data-stu-id="d1bdf-316">Learn about [Service Fabric support options](service-fabric-support.md)</span></span>

<!-- External links -->

[repair-partition-ps]: https://msdn.microsoft.com/library/mt163522.aspx
[azure-status-dashboard]:https://azure.microsoft.com/status/
[azure-regions]: https://azure.microsoft.com/regions/
[dr-ha-guide]: https://msdn.microsoft.com/library/azure/dn251004.aspx


<!-- Images -->

[sfx-cluster-map]: ./media/service-fabric-disaster-recovery/sfx-clustermap.png

---
title: "Zkopírujte aktivity výkonu a vyladění Průvodce | Microsoft Docs"
description: "Další informace o klíčových faktorů, které ovlivňují výkon přesun dat v Azure Data Factory při použití aktivity kopírování."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="1c0ff-103">Zkopírujte aktivity výkonu a vyladění Průvodce</span><span class="sxs-lookup"><span data-stu-id="1c0ff-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="1c0ff-104">Aktivita kopírování Azure Data Factory nabízí prvotřídní dat zabezpečeným, spolehlivým a vysoce výkonné načítání řešení.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="1c0ff-105">Ji budete kopie desítkami terabajtů dat pro každý den s bohatou různých cloudové a místní úložiště dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="1c0ff-106">Výkon při načítání dat svěží fast je klíč k zajištění, můžete se zaměřit na problém "velkých objemů dat" základní: vytváření řešení pro pokročilou analýzu a získávání hlubšímu porozumění z všechno, co data.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="1c0ff-107">Azure poskytuje sadu podnikové úrovni řešení pro úložiště a datového skladu dat a aktivity kopírování nabízí vysoce optimalizovaného data načítání prostředí, které se snadno konfiguraci a nastavení.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="1c0ff-108">Jenom jedna kopie aktivity můžete dosáhnout:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="1c0ff-109">Načítání dat do **Azure SQL Data Warehouse** v **1,2 GB/s**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="1c0ff-110">Návod s případu použití najdete v tématu [načíst 1 TB do Azure SQL Data Warehouse pomocí Azure Data Factory v části 15 minut](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="1c0ff-111">Načítání dat do **úložiště objektů Azure Blob** v **1.0 GB/s**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="1c0ff-112">Načítání dat do **Azure Data Lake Store** v **1.0 GB/s**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="1c0ff-113">Tento článek popisuje:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-113">This article describes:</span></span>

* <span data-ttu-id="1c0ff-114">[Výkon referenční čísla](#performance-reference) podporováno zdroj a jímka úložiště dat, které vám pomohou naplánovat projektu;</span><span class="sxs-lookup"><span data-stu-id="1c0ff-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="1c0ff-115">Funkce, které může zvýšit propustnost kopírování v různých scénářích, včetně [jednotky přesun dat v cloudu](#cloud-data-movement-units), [paralelní kopie](#parallel-copy), a [připravený kopie](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="1c0ff-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="1c0ff-116">[Ladění pokyny výkonu](#performance-tuning-steps) o tom, jak optimalizovat výkon a klíčové faktory, které může ovlivnit výkon kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="1c0ff-117">Pokud nejste obeznámeni s aktivitou kopírování obecně, přečtěte si téma [přesun dat pomocí aktivity kopírování](data-factory-data-movement-activities.md) před přečtení tohoto článku.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="1c0ff-118">Referenční dokumentace výkonu</span><span class="sxs-lookup"><span data-stu-id="1c0ff-118">Performance reference</span></span>

<span data-ttu-id="1c0ff-119">Jako odkaz níže uvedená tabulka zobrazuje číslo kopie propustnost v MB/s pro daný zdroj a jímka dvojice založené na interní testování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="1c0ff-120">Pro porovnání, také ukazuje, jak budou různí nastavení [jednotky přesun dat v cloudu](#cloud-data-movement-units) nebo [Brána pro správu dat škálovatelnost](data-factory-data-management-gateway-high-availability-scalability.md) (více uzlů brány) může pomoct na výkon kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Matice výkonu](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="1c0ff-122">**Všimněte si body:**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-122">**Points to note:**</span></span>
* <span data-ttu-id="1c0ff-123">Propustnost je vypočítána pomocí následujícího vzorce: [velikost dat číst ze zdroje] / [spustit doba trvání aktivity kopírování].</span><span class="sxs-lookup"><span data-stu-id="1c0ff-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="1c0ff-124">Referenční čísla výkonu v tabulce se měří pomocí [TPC-H](http://www.tpc.org/tpch/) datové sady v jedna kopie aktivity při spuštění.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="1c0ff-125">V úložištích dat Azure zdroj a jímka mají ve stejné oblasti Azure.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="1c0ff-126">Pro hybridní kopírování mezi místními a cloudovými úložiště dat, každý uzel brány byla spuštěna na počítači, který byl samostatné z místního úložiště dat s níže specifikace.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="1c0ff-127">Při spuštění jediné aktivity v brány, operace kopírování spotřebováno pouze malou část CPU, paměť či šířku pásma sítě testovací počítač.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="1c0ff-128">Další informace z [aspekt Brána pro správu dat](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="1c0ff-129">Procesor</span><span class="sxs-lookup"><span data-stu-id="1c0ff-129">CPU</span></span></td>
        <td><span data-ttu-id="1c0ff-130">32 jader 2,20 GHz Intel Xeon E5-2660 v2</span><span class="sxs-lookup"><span data-stu-id="1c0ff-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="1c0ff-131">Memory (Paměť)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-131">Memory</span></span></td>
        <td><span data-ttu-id="1c0ff-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="1c0ff-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="1c0ff-133">Síť</span><span class="sxs-lookup"><span data-stu-id="1c0ff-133">Network</span></span></td>
        <td><span data-ttu-id="1c0ff-134">Internetové rozhraní: 10 GB/s; rozhraní sítě intranet: 40 GB/s</span><span class="sxs-lookup"><span data-stu-id="1c0ff-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="1c0ff-135">Vyšší propustnost můžete dosáhnout využitím jednotky další přesun dat (DMUs) než výchozí maximální DMUs, které je 32 pro spuštění aktivity kopírování cloudu cloud.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="1c0ff-136">Například s 100 DMUs, můžete dosáhnout kopírování dat z objektu Blob Azure do Azure Data Lake Store v **1.0GBps**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="1c0ff-137">Najdete v článku [jednotky přesun dat v cloudu](#cloud-data-movement-units) část Podrobnosti o této funkci a podporovaném scénáři.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="1c0ff-138">Obraťte se na [podporu Azure](https://azure.microsoft.com/support/) požádat o další DMUs.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="1c0ff-139">Paralelní kopie</span><span class="sxs-lookup"><span data-stu-id="1c0ff-139">Parallel copy</span></span>
<span data-ttu-id="1c0ff-140">Můžete číst data ze zdroje nebo zapsat data do cílové **paralelně v rámci aktivity kopírování spustit**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="1c0ff-141">Tato funkce vylepšuje propustnost operace kopírování a snižuje dobu potřebnou k přesunutí dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="1c0ff-142">Toto nastavení se liší od **souběžnosti** vlastnost v definici aktivity.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="1c0ff-143">**Souběžnosti** vlastnost určuje počet **spouští souběžné aktivity kopírování** zpracováním dat ze systému windows jiné aktivitě (1: 00 do 2: 00, 2 AM 3 AM, AM 3 a 4 AM a tak dále).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="1c0ff-144">Tato možnost je užitečná při provádění historických zatížení.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="1c0ff-145">Paralelní kopie funkce se vztahuje na **jednotné aktivity při spuštění**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="1c0ff-146">Podívejme se na vzorový scénář.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="1c0ff-147">V následujícím příkladu třeba zpracovat více řezů v minulosti.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="1c0ff-148">Objekt pro vytváření dat běží instance aktivity kopírování (aktivita spustit) pro každý řez:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="1c0ff-149">Datový řez z okna první aktivitu (1: 00 do 2: 00) == > aktivita běžet 1</span><span class="sxs-lookup"><span data-stu-id="1c0ff-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="1c0ff-150">Datový řez z okna druhý aktivity (2: 00 do 3: 00) == > aktivita běžet 2</span><span class="sxs-lookup"><span data-stu-id="1c0ff-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="1c0ff-151">Datový řez z okna druhý aktivity (3: 00 do 4: 00) == > aktivita běžet 3</span><span class="sxs-lookup"><span data-stu-id="1c0ff-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="1c0ff-152">A tak dále.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-152">And so on.</span></span>

<span data-ttu-id="1c0ff-153">V tomto příkladu při **souběžnosti** hodnota nastavena na 2, **aktivita běžet 1** a **aktivita běžet 2** kopírování dat z okna dvě aktivity **souběžně** ke zlepšení výkonu přesun dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="1c0ff-154">Ale pokud více souborů jsou spojené s aktivity při spuštění 1, služba pro přesun dat zkopíruje soubory ze zdroje cílový jeden soubor současně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="1c0ff-155">Jednotky přesun dat cloudu</span><span class="sxs-lookup"><span data-stu-id="1c0ff-155">Cloud data movement units</span></span>
<span data-ttu-id="1c0ff-156">A **jednotky přesun dat cloudu (DMU)** je míra, která reprezentuje výkon (kombinaci procesoru, paměti a přidělení prostředků sítě) v objektu pro vytváření dat na jednu jednotku.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="1c0ff-157">DMU se dají používat v operace kopírování cloudu do cloudu, ale není v hybridní kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="1c0ff-158">Ve výchozím nastavení používá pro vytváření dat jeden cloud DMU provést spuštění jediné aktivity kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="1c0ff-159">Pokud chcete přepsat toto výchozí nastavení, zadejte hodnotu **cloudDataMovementUnits** vlastnost následujícím způsobem.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="1c0ff-160">Informace o úrovni výkonnější se mohou objevit, když konfigurujete další jednotky pro konkrétní kopie zdroj a jímka najdete v tématu [referenční dokumentace výkonu](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="1c0ff-161">**Povolené hodnoty** pro **cloudDataMovementUnits** vlastnost jsou 1 (výchozí), 2, 4, 8, 16, 32.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="1c0ff-162">**Skutečný počet cloudu DMUs** že kopírování se používá v době běhu je rovna nebo menší než nakonfigurovaná hodnota, v závislosti na vaší vzorek dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="1c0ff-163">Pokud potřebujete další cloudu DMUs pro vyšší propustnost, obraťte se na [podporu Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="1c0ff-164">Nastavení 8 a vyšší aktuálně funguje pouze tehdy, když jste **zkopírovat soubory z objektu Blob úložiště nebo Data Lake Store nebo Amazon S3 nebo cloudem FTP nebo cloudem SFTP do objektu Blob úložiště nebo Data Lake Store nebo Azure SQL Database**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="1c0ff-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="1c0ff-165">parallelCopies</span></span>
<span data-ttu-id="1c0ff-166">Můžete použít **parallelCopies** vlastnost označující paralelismus, který chcete použít aktivitu kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="1c0ff-167">Tato vlastnost si můžete představit jako maximální počet vláken v rámci aktivitu kopírování, která můžou číst ze zdroje nebo zapisovat do vašeho úložiště dat podřízený paralelně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="1c0ff-168">Objekt pro vytváření dat pro každou aktivitu kopírování, spuštění, určuje počet paralelních kopií, které chcete použít ke zkopírování dat ze zdroje dat, ukládání a k datům cílového úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="1c0ff-169">Výchozí počet paralelní kopie, které používá závisí na typu zdroj a jímka, který používáte.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="1c0ff-170">Zdroj a jímka</span><span class="sxs-lookup"><span data-stu-id="1c0ff-170">Source and sink</span></span> | <span data-ttu-id="1c0ff-171">Výchozí paralelní kopie počet určit službou</span><span class="sxs-lookup"><span data-stu-id="1c0ff-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="1c0ff-172">Kopírovat data mezi souborové úložiště (úložiště objektů Blob; Data Lake Store; Amazon S3; systému souborů na místě. místní službě HDFS)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="1c0ff-173">Mezi 1 a 32.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-173">Between 1 and 32.</span></span> <span data-ttu-id="1c0ff-174">Závisí na velikosti souborů a počet jednotek přesun dat cloudu (DMUs) používat ke kopírování dat mezi dvěma cloudové úložiště dat nebo fyzické konfigurace počítače brány, použít pro hybridní kopírování (pro kopírování dat do nebo z místnímu úložišti dat).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="1c0ff-175">Kopírování dat z **úložiště všechny zdroje dat do úložiště Azure Table**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="1c0ff-176">4</span><span class="sxs-lookup"><span data-stu-id="1c0ff-176">4</span></span> |
| <span data-ttu-id="1c0ff-177">Všechny ostatní zdroj a jímka páry</span><span class="sxs-lookup"><span data-stu-id="1c0ff-177">All other source and sink pairs</span></span> |<span data-ttu-id="1c0ff-178">1</span><span class="sxs-lookup"><span data-stu-id="1c0ff-178">1</span></span> |

<span data-ttu-id="1c0ff-179">Obvykle použije se výchozí chování měl dát nejlepší propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="1c0ff-180">Však k řízení zatížení na počítačích, které hostují vaše data ukládá, nebo k ladění výkonu kopie, můžete se rozhodnout přepsat výchozí hodnotu a zadejte hodnotu **parallelCopies** vlastnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="1c0ff-181">Hodnota musí být mezi 1 a 32 (obě včetně).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="1c0ff-182">Za běhu pro nejlepší výkon, používá aktivitu kopírování hodnotu, která je menší než nebo rovna hodnotě, který nastavíte.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="1c0ff-183">Všimněte si body:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-183">Points to note:</span></span>

* <span data-ttu-id="1c0ff-184">Při kopírování dat mezi úložišti na základě souborů **parallelCopies** určení stupně paralelního zpracování na úrovni souborů.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="1c0ff-185">Rozdělování v rámci jednoho souboru by se stalo pod automaticky a transparentně a je určený používat velikost bloku vhodné doporučené pro zadaná zdrojová datový typ úložiště pro načtení dat do paralelní a ortogonální k parallelCopies.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="1c0ff-186">Skutečný počet kopií paralelní služba pro přesun dat používá pro operace kopírování v době běhu je více než počet souborů, které máte.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="1c0ff-187">Pokud je kopie chování **mergeFile**, aktivity kopírování nemohou využívat paralelismus úrovni souborů.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="1c0ff-188">Pokud zadáte hodnotu **parallelCopies** vlastnost, zvažte zvýšení zatížení na zdroj a jímka datová úložiště a pro bránu, pokud je hybridní kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="1c0ff-189">K tomu dojde, zejména pokud máte více souběžných spustí stejný aktivity, které spouštění stejné úložiště dat nebo aktivity.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="1c0ff-190">Pokud si všimnete, že úložiště dat nebo brány je zahlcen zatížení, snížit **parallelCopies** hodnota, která má-li snížit zatížení.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="1c0ff-191">Při kopírování dat z úložiště, které nejsou na základě souborů do úložiště, které jsou na základě souborů, služba pro přesun dat ignoruje **parallelCopies** vlastnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="1c0ff-192">I když je zadán paralelismus, není použita v tomto případě.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="1c0ff-193">Můžete použít používá Brána pro správu dat. verze 1.11 nebo novější **parallelCopies** funkce při hybridní kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="1c0ff-194">Pro lepší využití tyto dvě vlastnosti a k vylepšení vašeho propustnost přesun dat, najdete v článku [ukázkové případy použití](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="1c0ff-195">Nemusíte konfigurovat **parallelCopies** využít výchozí chování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="1c0ff-196">Pokud nakonfigurujete a **parallelCopies** je příliš malá, více cloudu DMUs nemusí budou plně využívat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="1c0ff-197">Dopad fakturace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-197">Billing impact</span></span>
<span data-ttu-id="1c0ff-198">Má **důležité** pamatovat, že budou účtovat na základě celkové doby operace kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="1c0ff-199">Pokud úlohu kopírování se používá k trvat hodinu s jednotkou k jednomu cloudu a teď bude trvat 15 minut s čtyři jednotky cloudu, zůstane celkové faktury téměř stejný.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="1c0ff-200">Například můžete použít čtyři jednotky cloudu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-200">For example, you use four cloud units.</span></span> <span data-ttu-id="1c0ff-201">První jednotky cloudu stráví 10 minut, druhý, 10 minut, třetí jeden, 5 minut a čtvrtý jeden, 5 minut, všechny v jedné kopie aktivity spustit.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="1c0ff-202">Budou se vám účtovat dobu celkový kopírování (přesun dat), což je 10 + 10 + 5 + 5 = 30 minut.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="1c0ff-203">Pomocí **parallelCopies** nemá vliv na fakturace.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="1c0ff-204">Kopírování dvoufázové instalace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-204">Staged copy</span></span>
<span data-ttu-id="1c0ff-205">Při kopírování dat ze zdrojového úložiště dat do úložiště dat jímka, je možné používat úložiště objektů Blob jako dočasné pracovní úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="1c0ff-206">Pracovní je zvlášť užitečné v následujících případech:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="1c0ff-207">**Chcete pro načítání dat z různých úložišť dat do SQL Data Warehouse pomocí PolyBase**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="1c0ff-208">SQL Data Warehouse PolyBase používá jako mechanismus vysokou propustností načíst velké množství dat do SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="1c0ff-209">Ale zdrojová data musí být v úložišti objektů Blob a musí splňovat další kritéria.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="1c0ff-210">Při načítání dat z úložiště dat než úložiště objektů Blob, můžete aktivovat data kopírování prostřednictvím dočasné pracovní úložiště objektů Blob.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="1c0ff-211">V takovém případě objekt pro vytváření dat provádí transformace požadovaná data, chcete-li zajistit, aby splňoval požadavky PolyBase.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="1c0ff-212">Pak PolyBase používá k načtení dat do SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="1c0ff-213">Další podrobnosti najdete v tématu [PolyBase používá k načtení dat do Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="1c0ff-214">Návod s případu použití najdete v tématu [načíst 1 TB do Azure SQL Data Warehouse pomocí Azure Data Factory v části 15 minut](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="1c0ff-215">**Někdy trvá, než se přesouvat data hybridní (tedy kopírovat mezi místní data úložiště a Cloudová data uložit) přes pomalé síťové připojení**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="1c0ff-216">Chcete-li zvýšit výkon, dokáže komprimovat data na místní tak, aby trvá méně času pro přesun dat do pracovní úložiště dat v cloudu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="1c0ff-217">Před načtením do cílového úložiště dat, potom můžete dekomprimaci dat v úložišti pracovní.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="1c0ff-218">**Nechcete-li otevřít jiné porty než port 80 a portu 443 v bráně firewall kvůli podnikové zásady IT**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="1c0ff-219">Například při kopírování dat z úložiště dat místní jímky Azure SQL Database nebo jímky Azure SQL Data Warehouse, musíte aktivovat odchozí komunikaci TCP na portu 1433 pro bránu Windows firewall a váš podnikový firewall.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="1c0ff-220">V tomto scénáři využít výhod bránu a první kopírovat data do instance pracovní úložiště objektů Blob přes protokol HTTP nebo HTTPS na portu 443.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="1c0ff-221">Potom načtete data do SQL Database nebo SQL Data Warehouse z pracovní databáze úložiště objektů Blob.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="1c0ff-222">V tomto toku nemusíte povolit port 1433.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="1c0ff-223">Kopírování funguje jak dvoufázové instalace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-223">How staged copy works</span></span>
<span data-ttu-id="1c0ff-224">Při aktivaci pracovní funkce, nejprve dat je zkopírován ze zdrojového úložiště dat do pracovní úložiště dat (funkce přineste si vlastní).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="1c0ff-225">V dalším kroku data zkopírována z pracovní úložiště dat do úložiště dat jímky.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="1c0ff-226">Objekt pro vytváření dat automaticky spravuje toku dvoufázová za vás.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="1c0ff-227">Po dokončení přesunu dat, data Factory dočasná data z pracovní úložiště také vyčistí.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="1c0ff-228">Ve scénáři kopie cloudu (zdroj a jímka data, která jsou úložiště v cloudu) se nepoužije brány.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="1c0ff-229">Služba Data Factory provádí operace kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-229">The Data Factory service performs the copy operations.</span></span>

![Dvoufázové instalace kopírování: scénář cloudu](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="1c0ff-231">V hybridním scénáři kopírování (je místní zdroj a jímka je v cloudu), brány přesune data ze zdrojového úložiště dat do úložiště dat, které pracovní.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="1c0ff-232">Služba data Factory přesouvá data z pracovní úložiště dat do úložiště dat jímky.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="1c0ff-233">Kopírování dat z jiného úložiště dat cloudu k úložišti dat místní prostřednictvím přípravy je podporováno také s odstínech toku.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Dvoufázové instalace kopírování: hybridní scénář](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="1c0ff-235">Když aktivujete přesun dat s použitím pracovní úložiště, můžete zadat, zda chcete data, která mají být před přesunutím dat ze zdrojového úložiště dat k úložišti dat dočasné nebo pracovní zkomprimovat a pak dekomprimovat před přesouvání dat od jako dočasné nebo přípravu úložiště dat pro úložiště dat podřízený.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="1c0ff-236">V současné době nelze kopírovat data mezi dvěma místní úložišti dat pomocí pracovní úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="1c0ff-237">Očekáváme, že tuto možnost, chcete-li být brzy dostupná.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="1c0ff-238">Konfigurace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-238">Configuration</span></span>
<span data-ttu-id="1c0ff-239">Konfigurace **enableStaging** nastavení k určení, zda chcete data, která mají být dvoufázové instalace v úložišti objektů Blob před načtením do cílového úložiště dat v aktivitě kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="1c0ff-240">Když nastavíte **enableStaging** na hodnotu TRUE, zadejte další vlastnosti, které jsou uvedené v další tabulce.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="1c0ff-241">Pokud nemáte, je také potřeba vytvořit Azure Storage nebo úložiště sdíleného přístupu podpis propojené služby pro přípravu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="1c0ff-242">Vlastnost</span><span class="sxs-lookup"><span data-stu-id="1c0ff-242">Property</span></span> | <span data-ttu-id="1c0ff-243">Popis</span><span class="sxs-lookup"><span data-stu-id="1c0ff-243">Description</span></span> | <span data-ttu-id="1c0ff-244">Výchozí hodnota</span><span class="sxs-lookup"><span data-stu-id="1c0ff-244">Default value</span></span> | <span data-ttu-id="1c0ff-245">Požaduje se</span><span class="sxs-lookup"><span data-stu-id="1c0ff-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="1c0ff-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-246">**enableStaging**</span></span> |<span data-ttu-id="1c0ff-247">Zadejte, zda chcete zkopírovat data prostřednictvím jako dočasné pracovní úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="1c0ff-248">False</span><span class="sxs-lookup"><span data-stu-id="1c0ff-248">False</span></span> |<span data-ttu-id="1c0ff-249">Ne</span><span class="sxs-lookup"><span data-stu-id="1c0ff-249">No</span></span> |
| <span data-ttu-id="1c0ff-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-250">**linkedServiceName**</span></span> |<span data-ttu-id="1c0ff-251">Zadejte název [azurestorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) nebo [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) propojené služby, která odkazuje na instanci úložiště, který používáte jako dočasné pracovní úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="1c0ff-252">Úložiště nelze použít s sdílený přístupový podpis načíst data do SQL Data Warehouse pomocí PolyBase.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="1c0ff-253">Můžete ji v jiných scénářích.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="1c0ff-254">Není k dispozici</span><span class="sxs-lookup"><span data-stu-id="1c0ff-254">N/A</span></span> |<span data-ttu-id="1c0ff-255">Ano, když **enableStaging** nastaven na hodnotu TRUE</span><span class="sxs-lookup"><span data-stu-id="1c0ff-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="1c0ff-256">**Cesta**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-256">**path**</span></span> |<span data-ttu-id="1c0ff-257">Zadejte cestu úložiště objektů Blob, která má obsahovat pracovních dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="1c0ff-258">Pokud nezadáte cestu, služba vytvoří kontejner pro uložení dočasná data.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="1c0ff-259">Zadejte cestu, pouze v případě, že používáte úložiště s sdílený přístupový podpis, nebo vyžadujete dočasná data v konkrétní umístění.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="1c0ff-260">Není k dispozici</span><span class="sxs-lookup"><span data-stu-id="1c0ff-260">N/A</span></span> |<span data-ttu-id="1c0ff-261">Ne</span><span class="sxs-lookup"><span data-stu-id="1c0ff-261">No</span></span> |
| <span data-ttu-id="1c0ff-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="1c0ff-262">**enableCompression**</span></span> |<span data-ttu-id="1c0ff-263">Určuje, zda data by měl být komprimují předtím, než je zkopírován do cílové.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="1c0ff-264">Toto nastavení snižuje objem přenášených dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="1c0ff-265">False</span><span class="sxs-lookup"><span data-stu-id="1c0ff-265">False</span></span> |<span data-ttu-id="1c0ff-266">Ne</span><span class="sxs-lookup"><span data-stu-id="1c0ff-266">No</span></span> |

<span data-ttu-id="1c0ff-267">Zde je ukázka definice aktivitou kopírování pomocí vlastnosti, které jsou popsané v předchozí tabulce:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="1c0ff-268">Dopad fakturace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-268">Billing impact</span></span>
<span data-ttu-id="1c0ff-269">Budou se vám účtovat na základě dva kroky: kopírování doba trvání a zkopírujte typu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="1c0ff-270">Při použití pracovní během kopírování cloudu (kopírování dat z jiného úložiště dat cloudu do jiného úložiště dat v cloudu), vám budou účtovat [Součet kopie doba kroky 1 a 2] x [cloudové kopírování jednotkové ceny].</span><span class="sxs-lookup"><span data-stu-id="1c0ff-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="1c0ff-271">Při použití pracovní během hybridní kopírování (kopírování dat z místního úložiště dat do úložiště dat cloudu), budeme vám účtovat [kopírování hybridní doba trvání] x [cena za jednotku hybridního kopie] + [cloudu kopie trvání] x [cloudové kopírování jednotkové ceny].</span><span class="sxs-lookup"><span data-stu-id="1c0ff-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="1c0ff-272">Postup ladění výkonu</span><span class="sxs-lookup"><span data-stu-id="1c0ff-272">Performance tuning steps</span></span>
<span data-ttu-id="1c0ff-273">Doporučujeme, aby je provést tyto kroky pro optimalizaci výkonu služby Data Factory s aktivitou kopírování:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="1c0ff-274">**Stanovení základní úrovně**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-274">**Establish a baseline**.</span></span> <span data-ttu-id="1c0ff-275">Během fáze vývoje Otestujte svůj kanál pomocí aktivity kopírování proti data reprezentativní ukázka.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="1c0ff-276">Data Factory můžete využít [řezů modelu](data-factory-scheduling-and-execution.md) omezit množství dat, můžete pracovat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="1c0ff-277">Shromažďovat dobu provádění a vlastnosti výkonu pomocí **monitorování a správu aplikací**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="1c0ff-278">Zvolte **monitorování a správa** na domovské stránce objektu pro vytváření dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="1c0ff-279">Ve stromovém zobrazení, vyberte **výstupní datovou sadu**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="1c0ff-280">V **aktivity Windows** vyberte kopie aktivity při spuštění.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="1c0ff-281">**Aktivity Windows** uvádí dobu trvání aktivity kopírování a velikost dat, která se zkopírují.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="1c0ff-282">Propustnost je uvedena v **aktivity okno Průzkumníka**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="1c0ff-283">Další informace o aplikaci najdete v tématu [monitorování a Správa kanálů služby Azure Data Factory pomocí monitorování a správu aplikací](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Podrobnosti o spuštění aktivit](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="1c0ff-285">Později v článku, můžete porovnat výkon a konfiguraci váš scénář aktivity kopírování [referenční dokumentace výkonu](#performance-reference) z našich testů.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="1c0ff-286">**Diagnostika a optimalizace výkonu**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="1c0ff-287">Pokud zjistíte výkonu nevyhovuje vašim požadavkům, musíte určit kritické body.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="1c0ff-288">Potom optimalizace výkonu můžete odebrat nebo snížil dopad kritická místa.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="1c0ff-289">Úplný popis diagnostiku výkonu je nad rámec tohoto článku, ale tady jsou některé společné aspekty:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="1c0ff-290">Funkce výkonu:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-290">Performance features:</span></span>
     * [<span data-ttu-id="1c0ff-291">Paralelní kopie</span><span class="sxs-lookup"><span data-stu-id="1c0ff-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="1c0ff-292">Jednotky přesun dat cloudu</span><span class="sxs-lookup"><span data-stu-id="1c0ff-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="1c0ff-293">Kopírování dvoufázové instalace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="1c0ff-294">Škálovatelnost Brána pro správu dat</span><span class="sxs-lookup"><span data-stu-id="1c0ff-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="1c0ff-295">Brána správy dat</span><span class="sxs-lookup"><span data-stu-id="1c0ff-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="1c0ff-296">Zdroj</span><span class="sxs-lookup"><span data-stu-id="1c0ff-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="1c0ff-297">Podřízený</span><span class="sxs-lookup"><span data-stu-id="1c0ff-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="1c0ff-298">Serializace a deserializace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="1c0ff-299">Komprese</span><span class="sxs-lookup"><span data-stu-id="1c0ff-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="1c0ff-300">Mapování sloupce</span><span class="sxs-lookup"><span data-stu-id="1c0ff-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="1c0ff-301">Další důležité informace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="1c0ff-302">**Rozbalte položku konfigurace pro celou sadu dat**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="1c0ff-303">Až budete spokojeni s výsledky spuštění a výkon, můžete rozbalit definice a aktivní období kanálu, nepokrývají celou sadu dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="1c0ff-304">Důležité informace týkající se Brána pro správu dat</span><span class="sxs-lookup"><span data-stu-id="1c0ff-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="1c0ff-305">**Instalační program brány**: doporučujeme použít vyhrazený počítač na hostitele brány pro správu dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="1c0ff-306">V tématu [předpoklady pro použití brány pro správu dat](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="1c0ff-307">**Monitorování brány a nahoru nebo škálování**: jedné logické brány se jeden nebo více uzlů brány může sloužit více aktivity kopírování spustí ve stejnou dobu současně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="1c0ff-308">Skoro v reálném čase snímek využití prostředků (procesor, paměť, network(in/out) atd.) můžete zobrazit na počítači brány i počet souběžných úloh spuštěných versus limit na portálu Azure najdete v části [monitorování brány na portálu](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="1c0ff-309">Pokud máte třeba velkou na přesun dat hybridní buď velký počet souběžných kopie aktivity spustí nebo s velkým množstvím data ke zkopírování, zvažte pro [vertikální navýšení kapacity nebo škálovat. brána](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) tak, aby lépe využívat prostředek nebo pro zřízení více prostředků na základě kterých kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="1c0ff-310">Důležité informace pro zdroj</span><span class="sxs-lookup"><span data-stu-id="1c0ff-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="1c0ff-311">Obecné</span><span class="sxs-lookup"><span data-stu-id="1c0ff-311">General</span></span>
<span data-ttu-id="1c0ff-312">Ujistěte se, že příslušné úložiště dat není zahlcen jiné úlohy, které jsou spuštěné na nebo před ním.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="1c0ff-313">Pro úložiště dat společnosti Microsoft, najdete v části [sledování a ladění témata](#performance-reference) , které jsou specifické pro úložiště dat a pomáhá pochopit data ukládání výkonové charakteristiky, minimalizovat dobu odezvy a maximalizovat propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="1c0ff-314">Pokud zkopírujete data z Blob storage do SQL Data Warehouse, zvažte použití **PolyBase** pro zvýšení výkonu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="1c0ff-315">V tématu [PolyBase používá k načtení dat do Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) podrobnosti.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="1c0ff-316">Návod s případu použití najdete v tématu [načíst 1 TB do Azure SQL Data Warehouse pomocí Azure Data Factory v části 15 minut](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="1c0ff-317">Úložiště dat na základě souborů</span><span class="sxs-lookup"><span data-stu-id="1c0ff-317">File-based data stores</span></span>
<span data-ttu-id="1c0ff-318">*(Včetně úložiště objektů Blob, Data Lake Store, Amazon S3, systémy souborů na místě a místní HDFS)*</span><span class="sxs-lookup"><span data-stu-id="1c0ff-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="1c0ff-319">**Průměrná velikost souboru a počet souborů**: aktivita kopírování přenosy dat jeden soubor současně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="1c0ff-320">S stejné množství dat, se přesune je nižší, pokud dat obsahuje mnoho malých souborů než několik velkých souborů z důvodu fázi zavedení pro každý soubor celkovou propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="1c0ff-321">Pokud je to možné, kombinovat proto malé soubory do větší souborů k získání vyšší propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="1c0ff-322">**Soubor formátu a komprese**: Další způsoby, jak zvýšit výkon, najdete v článku [důležité informace týkající se serializace a deserializace](#considerations-for-serialization-and-deserialization) a [důležité informace týkající se komprese](#considerations-for-compression) oddíly.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="1c0ff-323">Pro **místní systém souborů** scénář, ve kterém **Brána pro správu dat** je potřeba, najdete v článku [důležité informace týkající se Brána pro správu dat](#considerations-for-data-management-gateway) části.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="1c0ff-324">Relační datové úložiště</span><span class="sxs-lookup"><span data-stu-id="1c0ff-324">Relational data stores</span></span>
<span data-ttu-id="1c0ff-325">*(Zahrnuje SQL Database; SQL Data Warehouse; Amazon Redshift; Databáze systému SQL Server; a Oracle, MySQL, DB2, Teradata, Sybase a PostgreSQL databáze atd.)*</span><span class="sxs-lookup"><span data-stu-id="1c0ff-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="1c0ff-326">**Vzorek dat**: schéma tabulky ovlivňuje kopie propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="1c0ff-327">Velikost velké řádku získáte lepší výkon než velikost řádku malé, zkopírujte stejný objem dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="1c0ff-328">Důvodem je, že databázi můžete načíst efektivněji méně dávek dat, která obsahují menší počet řádků.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="1c0ff-329">**Dotazu nebo uložené proceduře**: optimalizace logiku dotazu nebo uložené procedury, zadejte ve zdroji aktivity kopírování efektivněji načíst data.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="1c0ff-330">Pro **místní relační databáze**, jako je SQL Server a Oracle, které vyžadují použití **Brána pro správu dat**, najdete v článku [důležité informace týkající se Brána pro správu dat](#considerations-on-data-management-gateway) části.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="1c0ff-331">Důležité informace týkající se jímka</span><span class="sxs-lookup"><span data-stu-id="1c0ff-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="1c0ff-332">Obecné</span><span class="sxs-lookup"><span data-stu-id="1c0ff-332">General</span></span>
<span data-ttu-id="1c0ff-333">Ujistěte se, že příslušné úložiště dat není zahlcen jiné úlohy, které jsou spuštěné na nebo před ním.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="1c0ff-334">Úložiště dat společnosti Microsoft, najdete v části [sledování a ladění témata](#performance-reference) , které jsou specifické pro datová úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="1c0ff-335">Tato témata vám může pomoct pochopit vlastnosti výkonu úložiště dat a jak minimalizovat dobu odezvy a maximalizovat propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="1c0ff-336">Pokud chcete kopírovat data z **úložiště objektů Blob** k **SQL Data Warehouse**, zvažte použití **PolyBase** pro zvýšení výkonu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="1c0ff-337">V tématu [PolyBase používá k načtení dat do Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) podrobnosti.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="1c0ff-338">Návod s případu použití najdete v tématu [načíst 1 TB do Azure SQL Data Warehouse pomocí Azure Data Factory v části 15 minut](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="1c0ff-339">Úložiště dat na základě souborů</span><span class="sxs-lookup"><span data-stu-id="1c0ff-339">File-based data stores</span></span>
<span data-ttu-id="1c0ff-340">*(Včetně úložiště objektů Blob, Data Lake Store, Amazon S3, systémy souborů na místě a místní HDFS)*</span><span class="sxs-lookup"><span data-stu-id="1c0ff-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="1c0ff-341">**Zkopírujte chování**: Při kopírování dat z jiné na základě souborů datové úložiště, aktivity kopírování má tři možnosti prostřednictvím **copyBehavior** vlastnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="1c0ff-342">Zachovává hierarchie, vyrovná hierarchie nebo sloučí soubory.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="1c0ff-343">Buď se zachováním nebo vyrovnání hierarchie má žádné nebo téměř žádné nároky na výkon, ale sloučení souborů způsobí, že chcete zvýšit nároky na výkon.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="1c0ff-344">**Soubor formátu a komprese**: najdete v článku [důležité informace týkající se serializace a deserializace](#considerations-for-serialization-and-deserialization) a [důležité informace týkající se komprese](#considerations-for-compression) oddíly pro další způsoby, jak zlepšit výkon.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="1c0ff-345">**Úložiště objektů blob**: v současné době podporuje úložiště objektů Blob blokovat jenom objekty BLOB pro přenos dat optimalizované a propustnosti.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="1c0ff-346">Pro **systémy souborů místní** scénáře, které vyžadují použití **Brána pro správu dat**, najdete v článku [důležité informace týkající se Brána pro správu dat](#considerations-for-data-management-gateway) části.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="1c0ff-347">Relační datové úložiště</span><span class="sxs-lookup"><span data-stu-id="1c0ff-347">Relational data stores</span></span>
<span data-ttu-id="1c0ff-348">*(Zahrnuje SQL Database, SQL datového skladu, databáze systému SQL Server a Oracle – databáze)*</span><span class="sxs-lookup"><span data-stu-id="1c0ff-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="1c0ff-349">**Zkopírujte chování**: v závislosti na vlastnosti, které jste nastavili pro **sqlSink**, aktivity kopírování zapisuje data do cílové databáze různými způsoby.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="1c0ff-350">Ve výchozím nastavení připojí data přesun služba používá rozhraní hromadné kopírování API vložit data v režimu, který poskytuje nejlepší výkon.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="1c0ff-351">Pokud nakonfigurujete uložené procedury v jímce, platí databázi jednoho řádku dat najednou místo jako hromadného načtení.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="1c0ff-352">Výkon výrazně zahodí.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-352">Performance drops significantly.</span></span> <span data-ttu-id="1c0ff-353">Pokud sadu dat velká, v případě potřeby, zvažte možnost použití **sqlWriterCleanupScript** vlastnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="1c0ff-354">Pokud nakonfigurujete **sqlWriterCleanupScript** spouštět vlastnosti pro každou aktivitu kopírování, služba spustí skript a potom pomocí rozhraní API hromadné kopírování vložte data.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="1c0ff-355">Pokud chcete přepsat celou tabulku s nejnovější data, například můžete zadat skript, který nejprve odstranit všechny záznamy před hromadného načtení nová data ze zdroje.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="1c0ff-356">**Velikost dat vzor a batch**:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="1c0ff-357">Schéma tabulky ovlivňuje kopie propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="1c0ff-358">Ke zkopírování stejné množství dat, velikost velké řádku umožňuje lepší výkon než velikost malých řádku, protože databáze můžete potvrdit efektivněji méně dávky data.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="1c0ff-359">Aktivita kopírování vkládá data v řadě dávek.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="1c0ff-360">Můžete nastavit počet řádků v dávce pomocí **writeBatchSize** vlastnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="1c0ff-361">Pokud data obsahují malé řádky, můžete nastavit **writeBatchSize** vlastnost s vyšší hodnotou, abyste mohli využívat výhod nižší režijní náklady na dávky a vyšší propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="1c0ff-362">Pokud velikost řádku data velká, dávejte pozor, když zvýšíte **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="1c0ff-363">Vysoká hodnota může vést k selhání kopírování způsobené přetížení databáze.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="1c0ff-364">Pro **místní relační databáze** , jako třeba SQL Server a Oracle, které vyžadují použití **Brána pro správu dat**, najdete v článku [důležité informace týkající se Brána pro správu dat](#considerations-for-data-management-gateway) části.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="1c0ff-365">NoSQL úložiště</span><span class="sxs-lookup"><span data-stu-id="1c0ff-365">NoSQL stores</span></span>
<span data-ttu-id="1c0ff-366">*(Zahrnuje Table storage a Azure Cosmos DB)*</span><span class="sxs-lookup"><span data-stu-id="1c0ff-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="1c0ff-367">Pro **tabulky úložiště**:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-367">For **Table storage**:</span></span>
  * <span data-ttu-id="1c0ff-368">**Oddíl**: zápis dat do oddílů prokládaná výrazně snižuje výkon.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="1c0ff-369">Zdrojová data seřadit klíč oddílu tak, aby, vloží se data efektivně do oddílu jeden po druhém, nebo upravte logiku zapsat data do jediného oddílu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="1c0ff-370">Pro **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="1c0ff-371">**Velikost dávky**: **writeBatchSize** vlastnost nastaví počet paralelní požadavků ve službě Azure Cosmos DB vytvářet dokumenty.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="1c0ff-372">Lepšího výkonu můžete očekávat, když zvýšíte **writeBatchSize** protože další paralelní žádosti se odesílají do Azure Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="1c0ff-373">Podívejte se však omezení při zápisu Cosmos Azure DB (je chybová zpráva "rychlost požadavků je velká").</span><span class="sxs-lookup"><span data-stu-id="1c0ff-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="1c0ff-374">Různé faktory může způsobit omezení velikosti dokumentu, včetně počtu podmínky v dokumenty a cílovou kolekci zásady indexování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="1c0ff-375">K dosažení vyšší propustnost kopírování, zvažte použití lepší kolekci, například S3.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="1c0ff-376">Důležité informace týkající se serializace a deserializace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="1c0ff-377">Serializace a deserializace může dojít, když vaše vstupní datové sady nebo výstupní datové sady není soubor.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="1c0ff-378">V tématu [podporované formáty souborů a komprese](data-factory-supported-file-and-compression-formats.md) s informace o podporovaných formátech souborů pomocí aktivity kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="1c0ff-379">**Zkopírujte chování**:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-379">**Copy behavior**:</span></span>

* <span data-ttu-id="1c0ff-380">Kopírování souborů mezi úložišti dat na základě souborů:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="1c0ff-381">Pokud vstupní a výstupní datové sady oba mají stejné nebo žádné nastavení formátu souboru, služba pro přesun dat provede binární kopie bez jakýchkoli serializaci nebo deserializaci.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="1c0ff-382">Zobrazí vyšší propustnost ve srovnání s scénář, ve které se liší od sebe navzájem zdroj a jímka nastavení formátu souboru.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="1c0ff-383">Pokud vstupní a výstupní datové sady obě jsou ve formátu textu a pouze kódování typu je jiné, služba pro přesun dat pouze nepodporuje kódování převod.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="1c0ff-384">Neprovádí žádné serializace a deserializace, což způsobí, že některé výkonu režie ve srovnání s binární kopie.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="1c0ff-385">Pokud vstupní a výstupní datové sady oba mají jiné formáty souborů nebo různé konfigurace, jako oddělovače, služba pro přesun dat deserializuje zdroje dat do datového proudu, transformace a pak ho serializaci do formátu výstup, kterou jste uvedli.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="1c0ff-386">Tato operace výsledkem mnohem větších výkonu režie ve srovnání s dalšími scénáři.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="1c0ff-387">Při kopírování souborů z úložiště dat, který není na základě souborů (například z úložiště založené na souborech do relační úložiště), krok serializaci nebo deserializaci je povinný.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="1c0ff-388">Tento krok vede režijní náklady na významně zvýšit výkon.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="1c0ff-389">**Formát souboru**: formát souboru zvolíte může ovlivnit výkon kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="1c0ff-390">Například je Avro kompaktní binární formát, který ukládá metadata s daty.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="1c0ff-391">Rozsáhlá podpora má v ekosystému Hadoop pro zpracování a dotazování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="1c0ff-392">Je však nákladnější k serializaci a deserializaci, což vede k nižší propustnost kopie ve srovnání s textový formát Avro.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="1c0ff-393">Zkontrolujte výběr formátu souboru v rámci toku zpracování komplexní.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="1c0ff-394">Začněte s co tvoří dat je uložená v úložištích zdroj dat nebo extrahovat z externích systémů; nejlepší formát pro úložiště, analytického zpracování a dotazování; a jaký formát data mají být exportovány do datových tržišť nástrojů pro vytváření sestav a vizualizace nástroje.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="1c0ff-395">Někdy formát souboru, který je zhoršené pro čtení a zápisu výkon může být dobrou volbou, pokud byste zvážit celkové analytical proces.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="1c0ff-396">Důležité informace pro kompresi</span><span class="sxs-lookup"><span data-stu-id="1c0ff-396">Considerations for compression</span></span>
<span data-ttu-id="1c0ff-397">Pokud vstupní nebo výstupní datové sady je soubor, můžete nastavit aktivitu kopírování ke kompresi nebo dekompresi jako zapíše data do cílového umístění.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="1c0ff-398">Když zvolíte komprese, můžete udělat kompromis mezi vstupně výstupní (I/O) a procesoru.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="1c0ff-399">Komprese náklady na data, která je navíc v výpočetní prostředky.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="1c0ff-400">Ale na oplátku omezuje sítě vstupně-výstupních operací a úložiště.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="1c0ff-401">V závislosti na vašich dat se může zobrazit nárůst v celkovou propustnost kopírování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="1c0ff-402">**Kodeků**: aktivita kopírování podporuje typy kompresi Deflate, bzip2 a gzip.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="1c0ff-403">Azure HDInsight můžete využívat všechny tři typy zpracování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="1c0ff-404">Každý komprese kodek obsahuje výhody.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-404">Each compression codec has advantages.</span></span> <span data-ttu-id="1c0ff-405">Například bzip2 má nejnižší kopie propustnost, ale získáte nejlepší výkon dotazů Hive s bzip2, protože je možné rozdělit pro zpracování.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="1c0ff-406">GZIP je nejvíce vyrovnáváním možnost, a tím nejčastěji používají.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="1c0ff-407">Zvolte kodeků, který nejlépe vyhovuje danému typu klient server.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="1c0ff-408">**Úroveň**: můžete vybrat z dvě možnosti pro každý komprese kodeků: nejrychlejších komprimované a optimálně komprimované.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="1c0ff-409">Nejrychlejších možnost komprimovaný komprimaci dat, co nejrychleji i v případě, že bude výsledný soubor není komprimována optimálně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="1c0ff-410">Možnost optimálně komprimované stráví více času na komprese a výsledkem minimální množství dat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="1c0ff-411">Obě možnosti zobrazíte, který poskytuje lepší celkový výkon ve vašem případě můžete otestovat.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="1c0ff-412">**Zabývat**: Chcete-li kopírovat velké množství dat mezi místnímu úložišti a cloudu, zvažte použití úložiště objektů blob v mezičase s kompresí.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="1c0ff-413">Použití dočasné úložiště je užitečné, když šířku pásma sítě a služeb Azure je omezující faktor, který chcete sadu dat vstupní i výstupní datové sady v nekomprimované formě.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="1c0ff-414">Jedna kopie aktivity přesněji řečeno, lze rozdělit na dvě kopie aktivity.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="1c0ff-415">První aktivitu kopírování zkopíruje ze zdroje do objektu blob dočasné nebo pracovní v komprimované formě.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="1c0ff-416">Druhý aktivitě kopírování zkopíruje komprimovaná data z pracovní databáze a pak dekomprimuje při zapíše do jímky.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="1c0ff-417">Důležité informace týkající se mapování sloupců</span><span class="sxs-lookup"><span data-stu-id="1c0ff-417">Considerations for column mapping</span></span>
<span data-ttu-id="1c0ff-418">Můžete nastavit **columnMappings** vlastnosti v aktivitě kopírování mapy všechny nebo jen některé vstupní sloupce pro výstupní sloupce.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="1c0ff-419">Poté, co služba pro přesun dat načte data ze zdroje, musí se provést mapování sloupců na data před zapíše data do jímky.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="1c0ff-420">Další zpracování snižuje kopie propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="1c0ff-421">Pokud zdrojového úložiště dat dotazovatelné, například pokud je relační úložiště, jako je SQL Database nebo SQL Server, nebo pokud je úložiště typu NoSQL jako Table storage nebo Azure Cosmos DB, zvažte vkládání sloupec filtrování a změna logiku **dotazu** vlastnost místo použití mapování sloupců.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="1c0ff-422">Tímto způsobem projekce provádí služba pro přesun dat čte data ze zdrojového úložiště dat, kde je mnohem efektivnější.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="1c0ff-423">Další důležité informace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-423">Other considerations</span></span>
<span data-ttu-id="1c0ff-424">Pokud je velká velikost dat, kterou chcete zkopírovat, můžete upravit obchodní logiky na další oddíl data pomocí řezů mechanismu v datové továrně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="1c0ff-425">Poté naplánujte aktivitu kopírování ke spuštění častěji ke snížení velikosti dat pro každou aktivitu kopírování spustit.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="1c0ff-426">Buďte opatrní počet datových sad a kopie aktivity nutnosti Data Factory ke konektoru k úložišti dat stejné ve stejnou dobu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="1c0ff-427">Mnoho souběžných kopírování úlohy může omezit úložiště dat a vést ke snížení výkonu, kopie úlohy interní opakovaných pokusů a v některých případech selhání spuštění.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="1c0ff-428">Vzorový scénář: kopírování z místního SQL serveru do úložiště objektů Blob</span><span class="sxs-lookup"><span data-stu-id="1c0ff-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="1c0ff-429">**Scénář**: kanál vychází ke zkopírování dat z místního SQL serveru do úložiště objektů Blob ve formátu CSV.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="1c0ff-430">Chcete-li úlohu kopírování rychleji, by do formátu bzip2 komprimovat soubory CSV.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="1c0ff-431">**Test a analýzy**: propustnost aktivity kopírování je menší než 2 MB/s, což je mnohem nižší než srovnávacího testu výkonu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="1c0ff-432">**Analýza výkonu a ladění**: Chcete-li vyřešit problémy s výkonem, podíváme se na způsobu zpracování a přesunout data.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="1c0ff-433">**Čtení dat**: Brána otevře připojení k systému SQL Server a odešle dotaz.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="1c0ff-434">SQL Server reaguje odesílání datového proudu k bráně prostřednictvím intranetu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="1c0ff-435">**Serializuje a komprese dat**: Brána serializuje datový proud do formátu CSV a komprimaci dat do datového proudu bzip2.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="1c0ff-436">**Zápis dat**: brány odešle datový proud bzip2 do úložiště objektů Blob přes Internet.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="1c0ff-437">Jak vidíte, data se zpracovat a přesunout způsobem streamování sekvenční: SQL Server > LAN > brány > WAN > úložiště objektů Blob.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="1c0ff-438">**Celkový výkon jsou závislé na minimální propustnost přes kanál**.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Tok dat](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="1c0ff-440">Jeden nebo více následujících faktorů může způsobit kritická místa výkonu:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="1c0ff-441">**Zdroj**: samotný SQL Server má nízkou propustnost kvůli velkým zatížením.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="1c0ff-442">**Brána pro správu dat**:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="1c0ff-443">**LAN**: brány se nachází daleko od počítače systému SQL Server a má připojení s malou šířkou pásma.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="1c0ff-444">**Brána**: brány bylo dosaženo jeho omezení zatížení provádět následující operace:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="1c0ff-445">**Serializace**: serializaci do formátu CSV datový proud má pomalé propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="1c0ff-446">**Komprese**: jste zvolili pomalé kompresní kodek (například bzip2, což je 2,8 MB/s s i7 jádra).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="1c0ff-447">**WAN**: šířku pásma mezi podnikovou sítí a služeb Azure je nízká (například T1 = 1,544 kbps; T2 = 6,312 kb/s).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="1c0ff-448">**Jímky**: úložiště objektů Blob má nízkou propustnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="1c0ff-449">(Tento scénář nepravděpodobné, protože jeho SLA zaručuje minimálně 60 MB/s.)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="1c0ff-450">V takovém případě může komprese dat bzip2 zpomalení celého kanálu.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="1c0ff-451">Přepnutí na kodek pro kompresi gzip může usnadňují tyto potíže.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="1c0ff-452">Ukázkové scénáře: použití paralelních kopie</span><span class="sxs-lookup"><span data-stu-id="1c0ff-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="1c0ff-453">**Scénář I:** kopírovat 1 000 1 MB soubory z místní systém do úložiště objektů Blob souborů.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="1c0ff-454">**Analýzy a optimalizace výkonu**: pro příklad, pokud jste nainstalovali bránu na počítači čtyřjádrový, objekt pro vytváření dat používá 16 paralelní kopie k přesunutí souborů ze systému souborů do úložiště objektů Blob současně.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="1c0ff-455">Paralelní spuštění tohoto by měl mít za následek vysoké propustnosti.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="1c0ff-456">Také lze explicitně zadat počet paralelní kopie.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="1c0ff-457">Při kopírování mnoho malých souborů paralelní kopie výrazně pomoct propustnost pomocí prostředků efektivněji.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Scénář 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="1c0ff-459">**Scénář II**: kopírování 20 objekty BLOB 500 MB z úložiště objektů Blob do Data Lake Store Analytics a optimalizujte výkon.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="1c0ff-460">**Analýzy a optimalizace výkonu**: V tomto scénáři pro vytváření dat zkopíruje data z úložiště objektů Blob do Data Lake Store pomocí jedné kopie (**parallelCopies** nastavena na hodnotu 1) a data v cloudu jedním přesun jednotek.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="1c0ff-461">Propustnost zjistíte blízko, najdete v [výkonu referenčním oddílu](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="1c0ff-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Scénář 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="1c0ff-463">**Scénář III**: velikost jednotlivých souborů je větší než desítek MB a celkového objemu velký.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="1c0ff-464">**Analýzy a výkonu měnící**: zvýšení **parallelCopies** nevede k lepší výkon kopírování kvůli omezení prostředků DMU jeden cloud.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="1c0ff-465">Místo toho musíte zadat další cloudu DMUs získat další zdroje pro přesun dat provádění.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="1c0ff-466">Nezadávejte hodnotu **parallelCopies** vlastnost.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="1c0ff-467">Objekt pro vytváření dat zpracovává paralelismus za vás.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="1c0ff-468">V tomto případě, pokud jste nastavili **cloudDataMovementUnits** 4, propustnost o čtyřikrát dojde.</span><span class="sxs-lookup"><span data-stu-id="1c0ff-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Scénář 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="1c0ff-470">Referenční informace</span><span class="sxs-lookup"><span data-stu-id="1c0ff-470">Reference</span></span>
<span data-ttu-id="1c0ff-471">Zde jsou výkonu sledování a ladění odkazy pro některé podporované datové úložiště:</span><span class="sxs-lookup"><span data-stu-id="1c0ff-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="1c0ff-472">Úložiště Azure (včetně úložiště objektů Blob a Table storage): [cíle škálovatelnosti Azure Storage](../storage/common/storage-scalability-targets.md) a [kontrolní seznam výkonu a škálovatelnosti Azure Storage](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="1c0ff-473">Azure SQL Database: Můžete [sledovat výkon](../sql-database/sql-database-single-database-monitor.md) a zkontrolujte procento databáze transakce jednotky (DTU)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="1c0ff-474">Azure SQL Data Warehouse: Jeho schopnosti se měří v jednotky datového skladu (Dwu); v tématu [spravovat výpočetní výkon v Azure SQL Data Warehouse (přehled)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="1c0ff-475">Azure Cosmos DB: [úrovně výkonu v Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="1c0ff-476">Místní SQL Server: [monitorování a optimalizace výkonu](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="1c0ff-477">Místní souborový server: [optimalizace výkonu pro souborové servery](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="1c0ff-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>

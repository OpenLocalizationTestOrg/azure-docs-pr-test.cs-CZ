---
title: "Nastavení clusteru s podporou Windows RDMA ke spouštění aplikací MPI | Microsoft Docs"
description: "Zjistěte, jak vytvořit cluster Windows HPC Pack s velikostí H16r, H16mr, A8 nebo A9 virtuálních počítačů, které se použije ke spuštění aplikací MPI sítě Azure RDMA."
services: virtual-machines-windows
documentationcenter: 
author: dlepow
manager: timlt
editor: 
tags: azure-service-management,hpc-pack
ms.assetid: 7d9f5bc8-012f-48dd-b290-db81c7592215
ms.service: virtual-machines-windows
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: big-compute
ms.date: 06/01/2017
ms.author: danlep
ms.openlocfilehash: 19be1d693fe13af0f6c1ab0cb6f7bc829b9fad5a
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 08/03/2017
---
# <a name="set-up-a-windows-rdma-cluster-with-hpc-pack-to-run-mpi-applications"></a><span data-ttu-id="4890d-103">Nastavení clusteru s podporou Windows RDMA pomocí sady HPC Pack ke spouštění aplikací MPI</span><span class="sxs-lookup"><span data-stu-id="4890d-103">Set up a Windows RDMA cluster with HPC Pack to run MPI applications</span></span>
<span data-ttu-id="4890d-104">Nastavení clusteru s podporou Windows RDMA v Azure pomocí [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) a [vysokovýkonné výpočetní velikosti virtuálních počítačů](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) ke spouštění paralelních aplikací Message Passing Interface (MPI).</span><span class="sxs-lookup"><span data-stu-id="4890d-104">Set up a Windows RDMA cluster in Azure with [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) and [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) to run parallel Message Passing Interface (MPI) applications.</span></span> <span data-ttu-id="4890d-105">Při nastavování podporu rdma, systémem Windows Server uzly v clusteru služby HPC Pack aplikací MPI efektivně komunikují přes nízkou latencí a vysokou propustnost sítě v Azure, která je založena na technologii do paměti vzdáleného přímý přístup do (počítače RDMA).</span><span class="sxs-lookup"><span data-stu-id="4890d-105">When you set up RDMA-capable, Windows Server-based nodes in an HPC Pack cluster, MPI applications communicate efficiently over a low latency, high throughput network in Azure that is based on remote direct memory access (RDMA) technology.</span></span>

<span data-ttu-id="4890d-106">Pokud chcete spustit úlohy MPI na virtuální počítače s Linuxem, přístup k síti Azure RDMA najdete v tématu [nastavení clusteru s podporou Linux RDMA ke spuštění aplikací MPI](../../linux/classic/rdma-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="4890d-106">If you want to run MPI workloads on Linux VMs that access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

## <a name="hpc-pack-cluster-deployment-options"></a><span data-ttu-id="4890d-107">Možnosti nasazení clusteru HPC Pack</span><span class="sxs-lookup"><span data-stu-id="4890d-107">HPC Pack cluster deployment options</span></span>
<span data-ttu-id="4890d-108">Microsoft HPC Pack je nástroj zadaný bez dalších poplatků k vytvoření clusterů HPC místně nebo v Azure ke spouštění aplikací systému Windows nebo Linux HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-108">Microsoft HPC Pack is a tool provided at no additional cost to create HPC clusters on-premises or in Azure to run Windows or Linux HPC applications.</span></span> <span data-ttu-id="4890d-109">HPC Pack zahrnuje běhového prostředí pro implementaci společnosti Microsoft zprávu předávání rozhraní pro Windows (MS-MPI).</span><span class="sxs-lookup"><span data-stu-id="4890d-109">HPC Pack includes a runtime environment for the Microsoft implementation of the Message Passing Interface for Windows (MS-MPI).</span></span> <span data-ttu-id="4890d-110">Při použití s podporou RDMA instancí podporovaným operačním systémem Windows Server, HPC Pack nabízí efektivní možnost ke spouštění aplikací Windows MPI, které přístup k síti Azure RDMA.</span><span class="sxs-lookup"><span data-stu-id="4890d-110">When used with RDMA-capable instances running a supported Windows Server operating system, HPC Pack provides an efficient option to run Windows MPI applications that access the Azure RDMA network.</span></span> 

<span data-ttu-id="4890d-111">Tento článek představuje dva scénáře a odkazy na podrobné pokyny k nastavení clusteru s podporou Windows RDMA pomocí sady Microsoft HPC Pack.</span><span class="sxs-lookup"><span data-stu-id="4890d-111">This article introduces two scenarios and links to detailed guidance to set up a Windows RDMA cluster with Microsoft HPC Pack.</span></span> 

* <span data-ttu-id="4890d-112">Scénář 1.</span><span class="sxs-lookup"><span data-stu-id="4890d-112">Scenario 1.</span></span> <span data-ttu-id="4890d-113">Nasazení instance rolí pracovního procesu náročné (PaaS)</span><span class="sxs-lookup"><span data-stu-id="4890d-113">Deploy compute-intensive worker role instances (PaaS)</span></span>
* <span data-ttu-id="4890d-114">Scénář 2.</span><span class="sxs-lookup"><span data-stu-id="4890d-114">Scenario 2.</span></span> <span data-ttu-id="4890d-115">Nasaďte výpočetní uzly ve virtuálních počítačích náročné (IaaS)</span><span class="sxs-lookup"><span data-stu-id="4890d-115">Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>

<span data-ttu-id="4890d-116">Obecné požadavky pro používání náročné instancí se systémem Windows, najdete v části [vysokovýkonné výpočetní velikosti virtuálních počítačů](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="4890d-116">For general prerequisites to use compute-intensive instances with Windows, see [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>

## <a name="scenario-1-deploy-compute-intensive-worker-role-instances-paas"></a><span data-ttu-id="4890d-117">Scénář 1: Nasazení instance rolí pracovního procesu náročné (PaaS)</span><span class="sxs-lookup"><span data-stu-id="4890d-117">Scenario 1: Deploy compute-intensive worker role instances (PaaS)</span></span>
<span data-ttu-id="4890d-118">Z existujícího clusteru HPC Pack přidejte další výpočetní prostředky v instance rolí pracovního procesu systému Azure (Azure uzlů) spuštěna v rámci cloudové služby (PaaS).</span><span class="sxs-lookup"><span data-stu-id="4890d-118">From an existing HPC Pack cluster, add extra compute resources in Azure worker role instances (Azure nodes) running in a cloud service (PaaS).</span></span> <span data-ttu-id="4890d-119">Tato funkce, také nazývaná "rozšíření do služby Azure" ze sady HPC Pack podporuje celou řadu velikosti pro instance rolí pracovního procesu.</span><span class="sxs-lookup"><span data-stu-id="4890d-119">This feature, also called “burst to Azure” from HPC Pack, supports a range of sizes for the worker role instances.</span></span> <span data-ttu-id="4890d-120">Při přidávání uzlů Azure, zadejte jednu velikostí RDMA podporovat.</span><span class="sxs-lookup"><span data-stu-id="4890d-120">When adding the Azure nodes, specify one of the RDMA-capable sizes.</span></span>

<span data-ttu-id="4890d-121">Následují požadavky a kroky k rozšíření do RDMA podporovat instancemi Azure z existující (obvykle místní) clusteru.</span><span class="sxs-lookup"><span data-stu-id="4890d-121">Following are considerations and steps to burst to RDMA-capable Azure instances from an existing (typically on-premises) cluster.</span></span> <span data-ttu-id="4890d-122">Podobně jako postupy můžete použijte k přidání instance rolí pracovního procesu k hlavnímu uzlu HPC Pack, který je nasazen virtuální počítač Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-122">Use similar procedures to add worker role instances to an HPC Pack head node that is deployed in an Azure VM.</span></span>

> [!NOTE]
> <span data-ttu-id="4890d-123">Kurz k rozšíření do služby Azure pomocí sady HPC Pack, naleznete v části [nastavení hybridního clusteru pomocí sady HPC Pack](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="4890d-123">For a tutorial to burst to Azure with HPC Pack, see [Set up a hybrid cluster with HPC Pack](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span></span> <span data-ttu-id="4890d-124">Pozorně si projděte informace v následujících krocích, které platí konkrétně pro podporu rdma uzlů Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-124">Note the considerations in the following steps that apply specifically to RDMA-capable Azure nodes.</span></span>
> 
> 

![Rozšíření do služby Azure][burst]

### <a name="steps"></a><span data-ttu-id="4890d-126">Kroky</span><span class="sxs-lookup"><span data-stu-id="4890d-126">Steps</span></span>
1. <span data-ttu-id="4890d-127">**Nasaďte a nakonfigurujte hlavnímu uzlu HPC Pack 2012 R2**</span><span class="sxs-lookup"><span data-stu-id="4890d-127">**Deploy and configure an HPC Pack 2012 R2 head node**</span></span>
   
    <span data-ttu-id="4890d-128">Stáhněte si nejnovější balíček instalace sady HPC Pack z [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span><span class="sxs-lookup"><span data-stu-id="4890d-128">Download the latest HPC Pack installation package from the [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span> <span data-ttu-id="4890d-129">Požadavky a pokyny k přípravě nasazení Azure shluků najdete v tématu [rozšíření do instancí pracovního procesu Azure pomocí sady Microsoft HPC Pack](https://technet.microsoft.com/library/gg481749.aspx).</span><span class="sxs-lookup"><span data-stu-id="4890d-129">For requirements and instructions to prepare for an Azure burst deployment, see [Burst to Azure Worker Instances with Microsoft HPC Pack](https://technet.microsoft.com/library/gg481749.aspx).</span></span>
2. <span data-ttu-id="4890d-130">**Konfigurovat certifikát pro správu v rámci předplatného Azure**</span><span class="sxs-lookup"><span data-stu-id="4890d-130">**Configure a management certificate in the Azure subscription**</span></span>
   
    <span data-ttu-id="4890d-131">Konfigurujte certifikát k zabezpečení připojení mezi Azure a hlavního uzlu.</span><span class="sxs-lookup"><span data-stu-id="4890d-131">Configure a certificate to secure the connection between the head node and Azure.</span></span> <span data-ttu-id="4890d-132">Možnosti a postupy najdete v tématu [scénáře konfigurace certifikátu pro správu Azure pro HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span><span class="sxs-lookup"><span data-stu-id="4890d-132">For options and procedures, see [Scenarios to Configure the Azure Management Certificate for HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span></span> <span data-ttu-id="4890d-133">Pro testovací nasazení nainstaluje HPC Pack výchozí Microsoft HPC Azure certifikát pro správu můžete rychle nahrát do vašeho předplatného Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-133">For test deployments, HPC Pack installs a Default Microsoft HPC Azure Management Certificate you can quickly upload to your Azure subscription.</span></span>
3. <span data-ttu-id="4890d-134">**Vytvořte novou cloudovou službu a účet úložiště**</span><span class="sxs-lookup"><span data-stu-id="4890d-134">**Create a new cloud service and a storage account**</span></span>
   
    <span data-ttu-id="4890d-135">Použití portálu Azure k vytvoření cloudové služby a účet úložiště pro nasazení v oblasti, kde jsou k dispozici podporu rdma instance.</span><span class="sxs-lookup"><span data-stu-id="4890d-135">Use the Azure portal to create a cloud service and a storage account for the deployment in a region where the RDMA-capable instances are available.</span></span>
4. <span data-ttu-id="4890d-136">**Vytvořit šablonu Azure uzlu**</span><span class="sxs-lookup"><span data-stu-id="4890d-136">**Create an Azure node template**</span></span>
   
    <span data-ttu-id="4890d-137">Použití v uzlu Průvodce vytvořením šablony ve Správci clusteru HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-137">Use the Create Node Template Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="4890d-138">Pokyny najdete v tématu [vytvořit šablonu Azure uzlu](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) v "Kroky k nasazení Azure uzly s Microsoft HPC Pack".</span><span class="sxs-lookup"><span data-stu-id="4890d-138">For steps, see [Create an Azure node template](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) in “Steps to Deploy Azure Nodes with Microsoft HPC Pack”.</span></span>
   
    <span data-ttu-id="4890d-139">Pro počáteční testy doporučujeme nakonfigurujete zásady ruční dostupnosti v šabloně.</span><span class="sxs-lookup"><span data-stu-id="4890d-139">For initial tests, we suggest configuring a manual availability policy in the template.</span></span>
5. <span data-ttu-id="4890d-140">**Přidat uzly do clusteru**</span><span class="sxs-lookup"><span data-stu-id="4890d-140">**Add nodes to the cluster**</span></span>
   
    <span data-ttu-id="4890d-141">Pomocí Průvodce přidáním uzlu ve Správci clusteru HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-141">Use the Add Node Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="4890d-142">Další informace najdete v tématu [Azure přidat uzly do clusteru Windows HPC](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span><span class="sxs-lookup"><span data-stu-id="4890d-142">For more information, see [Add Azure Nodes to the Windows HPC Cluster](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span></span>
   
    <span data-ttu-id="4890d-143">Při zadávání velikost uzlů, vyberte jednu z podporující RDMA velikosti instance.</span><span class="sxs-lookup"><span data-stu-id="4890d-143">When specifying the size of the nodes, select one of the RDMA-capable instance sizes.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="4890d-144">V každé shluků Azure nasazení s instancí náročné HPC Pack automaticky nasadí minimálně dvě instance RDMA podporovat (například A8) jako proxy uzly, kromě instance rolí pracovního procesu systému Azure, které zadáte.</span><span class="sxs-lookup"><span data-stu-id="4890d-144">In each burst to Azure deployment with the compute-intensive instances, HPC Pack automatically deploys a minimum of two RDMA-capable instances (such as A8) as proxy nodes, in addition to the Azure worker role instances you specify.</span></span> <span data-ttu-id="4890d-145">Uzly proxy serveru používat jádra, které jsou přiděleny předplatné a platit poplatky společně s instancí role pracovního procesu systému Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-145">The proxy nodes use cores that are allocated to the subscription and incur charges along with the Azure worker role instances.</span></span>
   > 
   > 
6. <span data-ttu-id="4890d-146">**Spuštění (zřídit) uzly a přiřaďte je online ke spuštění úloh**</span><span class="sxs-lookup"><span data-stu-id="4890d-146">**Start (provision) the nodes and bring them online to run jobs**</span></span>
   
    <span data-ttu-id="4890d-147">Vyberte je a používat **spustit** akce ve Správci clusteru HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-147">Select the nodes and use the **Start** action in HPC Cluster Manager.</span></span> <span data-ttu-id="4890d-148">Jakmile je zřizování dokončeno, vyberte je a používat **přepnout do režimu Online** akce ve Správci clusteru HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-148">When provisioning is complete, select the nodes and use the **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="4890d-149">Uzly jsou připravené ke spuštění úloh.</span><span class="sxs-lookup"><span data-stu-id="4890d-149">The nodes are ready to run jobs.</span></span>
7. <span data-ttu-id="4890d-150">**Odesílání úloh do clusteru**</span><span class="sxs-lookup"><span data-stu-id="4890d-150">**Submit jobs to the cluster**</span></span>
   
   <span data-ttu-id="4890d-151">Pomocí nástrojů odeslání úlohy HPC Pack ke spuštění úloh clusteru.</span><span class="sxs-lookup"><span data-stu-id="4890d-151">Use HPC Pack job submission tools to run cluster jobs.</span></span> <span data-ttu-id="4890d-152">V tématu [sady Microsoft HPC Pack: Správa úloh](http://technet.microsoft.com/library/jj899585.aspx).</span><span class="sxs-lookup"><span data-stu-id="4890d-152">See [Microsoft HPC Pack: Job Management](http://technet.microsoft.com/library/jj899585.aspx).</span></span>
8. <span data-ttu-id="4890d-153">**Zastavit (deprovision) uzly**</span><span class="sxs-lookup"><span data-stu-id="4890d-153">**Stop (deprovision) the nodes**</span></span>
   
   <span data-ttu-id="4890d-154">Po dokončení probíhající úlohy, odpojit, uzly a použít **Zastavit** akce ve Správci clusteru HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-154">When you are done running jobs, take the nodes offline and use the **Stop** action in HPC Cluster Manager.</span></span>

## <a name="scenario-2-deploy-compute-nodes-in-compute-intensive-vms-iaas"></a><span data-ttu-id="4890d-155">Scénář 2: Nasaďte výpočetní uzly ve virtuálních počítačích náročné (IaaS)</span><span class="sxs-lookup"><span data-stu-id="4890d-155">Scenario 2: Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>
<span data-ttu-id="4890d-156">V tomto scénáři nasazení hlavního uzlu HPC Pack a výpočetní uzly clusteru na virtuálních počítačích v virtuální sítě Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-156">In this scenario, you deploy the HPC Pack head node and cluster compute nodes on VMs in an Azure virtual network.</span></span> <span data-ttu-id="4890d-157">HPC Pack nabízí několik [možnosti nasazení ve virtuálních počítačích Azure](../../linux/hpcpack-cluster-options.md), včetně skriptů automatizované nasazení a šablony Azure rychlý start.</span><span class="sxs-lookup"><span data-stu-id="4890d-157">HPC Pack provides several [deployment options in Azure VMs](../../linux/hpcpack-cluster-options.md), including automated deployment scripts and Azure quickstart templates.</span></span> <span data-ttu-id="4890d-158">Jako příklad následující požadavky a kroky průvodce vám umožní používat [skript nasazení HPC Pack IaaS](hpcpack-cluster-powershell-script.md) k automatizaci nasazení clusteru HPC Pack 2012 R2 v Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-158">As an example, the following considerations and steps guide you to use the [HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md) to automate the deployment of an HPC Pack 2012 R2 cluster in Azure.</span></span>

![Cluster ve virtuálních počítačích Azure][iaas]

### <a name="steps"></a><span data-ttu-id="4890d-160">Kroky</span><span class="sxs-lookup"><span data-stu-id="4890d-160">Steps</span></span>
1. <span data-ttu-id="4890d-161">**Vytvoření hlavního uzlu clusteru a výpočetní uzel virtuální počítače tak, že spustíte skript nasazení HPC Pack IaaS na klientském počítači**</span><span class="sxs-lookup"><span data-stu-id="4890d-161">**Create a cluster head node and compute node VMs by running the HPC Pack IaaS deployment script on a client computer**</span></span>
   
    <span data-ttu-id="4890d-162">Stáhněte balíček HPC Pack IaaS nasazení skriptu [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span><span class="sxs-lookup"><span data-stu-id="4890d-162">Download the HPC Pack IaaS Deployment Script package from the [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span>
   
    <span data-ttu-id="4890d-163">Příprava klientského počítače, vytvořte konfigurační soubor skriptu a spusťte skript, viz [vytvoření clusteru prostředí HPC pomocí skriptu pro nasazení HPC Pack IaaS](hpcpack-cluster-powershell-script.md).</span><span class="sxs-lookup"><span data-stu-id="4890d-163">To prepare the client computer, create the script configuration file, and run the script, see [Create an HPC Cluster with the HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md).</span></span> 
   
    <span data-ttu-id="4890d-164">Nasazení podporující RDMA výpočetní uzly, pozorně si projděte následující další informace:</span><span class="sxs-lookup"><span data-stu-id="4890d-164">To deploy RDMA-capable compute nodes, note the following additional considerations:</span></span>
   
   * <span data-ttu-id="4890d-165">**Virtuální síť**: Zadejte novou virtuální síť v oblasti, ve kterém je k dispozici podporu rdma velikost instance, kterou chcete použít.</span><span class="sxs-lookup"><span data-stu-id="4890d-165">**Virtual network**: Specify a new virtual network in a region in which the RDMA-capable instance size you want to use is available.</span></span>
   * <span data-ttu-id="4890d-166">**Operační systém Windows Server**: pro podporu připojení RDMA, zadejte operační systém Windows Server 2012 R2 nebo Windows Server 2012 pro výpočetní uzel virtuálních počítačů.</span><span class="sxs-lookup"><span data-stu-id="4890d-166">**Windows Server operating system**: To support RDMA connectivity, specify a Windows Server 2012 R2 or Windows Server 2012 operating system for the compute node VMs.</span></span>
   * <span data-ttu-id="4890d-167">**Cloudové služby**: doporučujeme, abyste nasazení vaší hlavního uzlu v rámci jednoho cloudové služby a výpočetní uzly v rámci různých cloudové služby.</span><span class="sxs-lookup"><span data-stu-id="4890d-167">**Cloud services**: We recommend deploying your head node in one cloud service and your compute nodes in a different cloud service.</span></span>
   * <span data-ttu-id="4890d-168">**HEAD velikost uzlu**: pro tento scénář, zvažte velikost alespoň A4 (Extra velký) pro hlavní uzel.</span><span class="sxs-lookup"><span data-stu-id="4890d-168">**Head node size**: For this scenario, consider a size of at least A4 (Extra Large) for the head node.</span></span>
   * <span data-ttu-id="4890d-169">**Rozšíření HpcVmDrivers**: skript nasazení nainstaluje agenta virtuálního počítače Azure a rozšíření HpcVmDrivers automaticky při nasazení velikosti A8 a A9 výpočetní uzly s operačním systémem Windows Server.</span><span class="sxs-lookup"><span data-stu-id="4890d-169">**HpcVmDrivers extension**: The deployment script installs the Azure VM Agent and the HpcVmDrivers extension automatically when you deploy size A8 or A9 compute nodes with a Windows Server operating system.</span></span> <span data-ttu-id="4890d-170">HpcVmDrivers nainstaluje ovladače na výpočetním uzlu virtuální počítače, aby se mohli připojit k síti RDMA.</span><span class="sxs-lookup"><span data-stu-id="4890d-170">HpcVmDrivers installs drivers on the compute node VMs so they can connect to the RDMA network.</span></span> <span data-ttu-id="4890d-171">Na virtuálních počítačích podporující RDMA H-series musíte ručně nainstalovat rozšíření HpcVmDrivers.</span><span class="sxs-lookup"><span data-stu-id="4890d-171">On RDMA-capable H-series VMs, you must manually install the HpcVmDrivers extension.</span></span> <span data-ttu-id="4890d-172">V tématu [vysokovýkonné výpočetní velikosti virtuálních počítačů](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="4890d-172">See [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
   * <span data-ttu-id="4890d-173">**Konfiguraci sítě s clustery**: skript nasazení automaticky nastaví clusteru HPC Pack topologie 5 (do všech uzlů v podnikové síti).</span><span class="sxs-lookup"><span data-stu-id="4890d-173">**Cluster network configuration**: The deployment script automatically sets up the HPC Pack cluster in Topology 5 (all nodes on the Enterprise network).</span></span> <span data-ttu-id="4890d-174">Tato topologie je vyžadována pro všechna nasazení clusteru HPC Pack ve virtuálních počítačích.</span><span class="sxs-lookup"><span data-stu-id="4890d-174">This topology is required for all HPC Pack cluster deployments in VMs.</span></span> <span data-ttu-id="4890d-175">Později neměňte topologie sítě clusteru.</span><span class="sxs-lookup"><span data-stu-id="4890d-175">Do not change the cluster network topology later.</span></span>
2. <span data-ttu-id="4890d-176">**Aby výpočetní uzly online ke spuštění úloh**</span><span class="sxs-lookup"><span data-stu-id="4890d-176">**Bring the compute nodes online to run jobs**</span></span>
   
    <span data-ttu-id="4890d-177">Vyberte je a používat **přepnout do režimu Online** akce ve Správci clusteru HPC.</span><span class="sxs-lookup"><span data-stu-id="4890d-177">Select the nodes and use the **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="4890d-178">Uzly jsou připravené ke spuštění úloh.</span><span class="sxs-lookup"><span data-stu-id="4890d-178">The nodes are ready to run jobs.</span></span>
3. <span data-ttu-id="4890d-179">**Odesílání úloh do clusteru**</span><span class="sxs-lookup"><span data-stu-id="4890d-179">**Submit jobs to the cluster**</span></span>
   
    <span data-ttu-id="4890d-180">Připojení k hlavnímu uzlu k odesílání úloh nebo nastavení místním počítači k tomu.</span><span class="sxs-lookup"><span data-stu-id="4890d-180">Connect to the head node to submit jobs, or set up an on-premises computer to do this.</span></span> <span data-ttu-id="4890d-181">Informace najdete v tématu [odeslání úlohy HPC cluster v Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="4890d-181">For information, see [Submit Jobs to an HPC cluster in Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
4. <span data-ttu-id="4890d-182">**Uzly převést do režimu offline a zastavení (zrušit přidělení) je**</span><span class="sxs-lookup"><span data-stu-id="4890d-182">**Take the nodes offline and stop (deallocate) them**</span></span>
   
    <span data-ttu-id="4890d-183">Po dokončení probíhající úlohy, ve Správci clusteru HPC trvat uzlu do režimu offline.</span><span class="sxs-lookup"><span data-stu-id="4890d-183">When you are done running jobs, take the nodes offline in HPC Cluster Manager.</span></span> <span data-ttu-id="4890d-184">Poté použijte nástroje pro správu Azure, abyste je vypnout.</span><span class="sxs-lookup"><span data-stu-id="4890d-184">Then, use Azure management tools to shut them down.</span></span>

## <a name="run-mpi-applications-on-the-cluster"></a><span data-ttu-id="4890d-185">Spouštění aplikací MPI v clusteru</span><span class="sxs-lookup"><span data-stu-id="4890d-185">Run MPI applications on the cluster</span></span>
### <a name="example-run-mpipingpong-on-an-hpc-pack-cluster"></a><span data-ttu-id="4890d-186">Příklad: Spusťte mpipingpong v clusteru HPC Pack</span><span class="sxs-lookup"><span data-stu-id="4890d-186">Example: Run mpipingpong on an HPC Pack cluster</span></span>
<span data-ttu-id="4890d-187">Pokud chcete ověřit nasazení služby HPC Pack instancí podporu rdma, spusťte HPC Pack **mpipingpong** příkazu v clusteru.</span><span class="sxs-lookup"><span data-stu-id="4890d-187">To verify an HPC Pack deployment of the RDMA-capable instances, run the HPC Pack **mpipingpong** command on the cluster.</span></span> <span data-ttu-id="4890d-188">**mpipingpong** odesílá pakety dat mezi uzly spárované opakovaně k výpočtu latence a propustnosti měření a statistiku sítě aplikací, které podporují RDMA.</span><span class="sxs-lookup"><span data-stu-id="4890d-188">**mpipingpong** sends packets of data between paired nodes repeatedly to calculate latency and throughput measurements and statistics for the RDMA-enabled application network.</span></span> <span data-ttu-id="4890d-189">Tento příklad ukazuje typický vzor pro spuštění úlohu MPI (v tomto případě **mpipingpong**) pomocí clusteru **mpiexec** příkaz.</span><span class="sxs-lookup"><span data-stu-id="4890d-189">This example shows a typical pattern for running an MPI job (in this case, **mpipingpong**) by using the cluster **mpiexec** command.</span></span>

<span data-ttu-id="4890d-190">Tento příklad předpokládá, že jste přidali uzlů Azure v konfiguraci "shluků do Azure" ([scénáři 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span><span class="sxs-lookup"><span data-stu-id="4890d-190">This example assumes you added Azure nodes in a “burst to Azure” configuration ([Scenario 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span></span> <span data-ttu-id="4890d-191">Pokud jste nasadili HPC Pack v clusteru virtuálních počítačů Azure, budete muset upravit syntaxe příkazu k zadejte skupinu jiný uzel a nastavení proměnných prostředí další směrovat síťový provoz v síti RDMA.</span><span class="sxs-lookup"><span data-stu-id="4890d-191">If you deployed HPC Pack on a cluster of Azure VMs, you’ll need to modify the command syntax to specify a different node group and set additional environment variables to direct network traffic to the RDMA network.</span></span>

<span data-ttu-id="4890d-192">Spuštění mpipingpong v clusteru:</span><span class="sxs-lookup"><span data-stu-id="4890d-192">To run mpipingpong on the cluster:</span></span>

1. <span data-ttu-id="4890d-193">Z hlavního uzlu nebo správnou konfiguraci klientských počítačích otevřete příkazový řádek.</span><span class="sxs-lookup"><span data-stu-id="4890d-193">On the head node or on a properly configured client computer, open a Command Prompt.</span></span>
2. <span data-ttu-id="4890d-194">K zjištění přibližné hodnoty latence mezi páry uzlů v nasazení Azure shluků ze čtyř uzlů, zadejte následující příkaz se odeslat úlohu spustit mpipingpong s velikost malých paketu a velký počet iterací:</span><span class="sxs-lookup"><span data-stu-id="4890d-194">To estimate latency between pairs of nodes in an Azure burst deployment of four nodes, type the following command to submit a job to run mpipingpong with a small packet size and many iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 1:100000 -op -s nul
    ```
   
    <span data-ttu-id="4890d-195">Příkaz vrátí ID úlohy, které je odeslána.</span><span class="sxs-lookup"><span data-stu-id="4890d-195">The command returns the ID of the job that is submitted.</span></span>
   
    <span data-ttu-id="4890d-196">Pokud jste nasadili cluster HPC Pack nasazena na virtuálních počítačích Azure, zadejte skupinu uzlu, který obsahuje výpočetní uzel virtuálních počítačích nasazených v jednom cloudové služby a upravit **mpiexec** příkaz takto:</span><span class="sxs-lookup"><span data-stu-id="4890d-196">If you deployed the HPC Pack cluster deployed on Azure VMs, specify a node group that contains compute node VMs deployed in a single cloud service, and modify the **mpiexec** command as follows:</span></span>
   
    ```Command
    job submit /nodegroup:vmcomputenodes /numnodes:4 mpiexec -c 1 -affinity -env MSMPI_DISABLE_SOCK 1 -env MSMPI_PRECONNECT all -env MPICH_NETMASK 172.16.0.0/255.255.0.0 mpipingpong -p 1:100000 -op -s nul
    ```
3. <span data-ttu-id="4890d-197">Po dokončení úlohy k zobrazení výstupu (v tomto případě se výstup úlohy 1 úlohy), zadejte následující příkaz</span><span class="sxs-lookup"><span data-stu-id="4890d-197">When the job completes, to view the output (in this case, the output of task 1 of the job), type the following</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
    <span data-ttu-id="4890d-198">kde &lt; *JobID* &gt; je ID úlohu, která byla odeslána.</span><span class="sxs-lookup"><span data-stu-id="4890d-198">where &lt;*JobID*&gt; is the ID of the job that was submitted.</span></span>
   
    <span data-ttu-id="4890d-199">Výstup obsahuje latence výsledky podobné následujícím.</span><span class="sxs-lookup"><span data-stu-id="4890d-199">The output includes latency results similar to the following.</span></span>
   
    ![Latence pong příkazu ping][pingpong1]
4. <span data-ttu-id="4890d-201">K zjištění přibližné hodnoty propustnost mezi páry uzlů Azure shluků, zadejte následující příkaz k odeslání spuštění úlohy **mpipingpong** s velikostí velkých paketů a několik iterací:</span><span class="sxs-lookup"><span data-stu-id="4890d-201">To estimate throughput between pairs of Azure burst nodes, type the following command to submit a job to run **mpipingpong** with a large packet size and a few iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 4000000:1000 -op -s nul
    ```
   
    <span data-ttu-id="4890d-202">Příkaz vrátí ID úlohy, které je odeslána.</span><span class="sxs-lookup"><span data-stu-id="4890d-202">The command returns the ID of the job that is submitted.</span></span>
   
    <span data-ttu-id="4890d-203">V clusteru HPC Pack nasazena na virtuálních počítačích Azure upravte příkaz jak jsme uvedli v kroku 2.</span><span class="sxs-lookup"><span data-stu-id="4890d-203">On an HPC Pack cluster deployed on Azure VMs, modify the command as noted in step 2.</span></span>
5. <span data-ttu-id="4890d-204">Po dokončení úlohy k zobrazení výstupu (v tomto případě se výstup úlohy 1 úlohy), zadejte následující příkaz:</span><span class="sxs-lookup"><span data-stu-id="4890d-204">When the job completes, to view the output (in this case, the output of task 1 of the job), type the following:</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
   <span data-ttu-id="4890d-205">Výstup obsahuje propustnost výsledky podobné následujícím.</span><span class="sxs-lookup"><span data-stu-id="4890d-205">The output includes throughput results similar to the following.</span></span>
   
   ![Propustnost pong příkazu ping][pingpong2]

### <a name="mpi-application-considerations"></a><span data-ttu-id="4890d-207">Aspekty aplikací MPI</span><span class="sxs-lookup"><span data-stu-id="4890d-207">MPI application considerations</span></span>
<span data-ttu-id="4890d-208">Tady jsou důležité informace týkající se s aplikací MPI HPC Pack v Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-208">Following are considerations for running MPI applications with HPC Pack in Azure.</span></span> <span data-ttu-id="4890d-209">Některé platí pouze pro nasazení Azure uzlů (Přidat v konfiguraci "shluků do Azure" instance role pracovního procesu.).</span><span class="sxs-lookup"><span data-stu-id="4890d-209">Some apply only to deployments of Azure nodes (worker role instances added in a “burst to Azure” configuration).</span></span>

* <span data-ttu-id="4890d-210">Instance role pracovního procesu v rámci cloudové služby jsou pravidelně znovu poskytnuto bez upozornění v Azure (například za účelem údržby systému nebo v případě, kdy selže instance).</span><span class="sxs-lookup"><span data-stu-id="4890d-210">Worker role instances in a cloud service are periodically reprovisioned without notice by Azure (for example, for system maintenance, or in case an instance fails).</span></span> <span data-ttu-id="4890d-211">Pokud instance je znovu poskytnuto, když je spuštěná úloha MPI, instance ztratí svoje data a vrátí do stavu, pokud bylo poprvé nasazeno, což může způsobit selhání úlohy MPI.</span><span class="sxs-lookup"><span data-stu-id="4890d-211">If an instance is reprovisioned while it is running an MPI job, the instance loses its data and returns to the state when it was first deployed, which can cause the MPI job to fail.</span></span> <span data-ttu-id="4890d-212">Další uzly, které používáte pro jednu úlohu MPI a tím déle má být úloha spuštěna, tím spíš, jedna z instancí je znovu poskytnuto když úloha běží.</span><span class="sxs-lookup"><span data-stu-id="4890d-212">The more nodes that you use for a single MPI job, and the longer the job runs, the more likely that one of the instances is reprovisioned while a job is running.</span></span> <span data-ttu-id="4890d-213">To taky zvážit, když určíte jako souborový server do jednoho uzlu v nasazení.</span><span class="sxs-lookup"><span data-stu-id="4890d-213">Also consider this if you designate a single node in the deployment as a file server.</span></span>
* <span data-ttu-id="4890d-214">Ke spouštění úloh MPI v Azure, nemusíte používat podporu rdma instance.</span><span class="sxs-lookup"><span data-stu-id="4890d-214">To run MPI jobs in Azure, you don't have to use the RDMA-capable instances.</span></span> <span data-ttu-id="4890d-215">Můžete použít libovolnou velikost instance, která je podporována sadou HPC Pack.</span><span class="sxs-lookup"><span data-stu-id="4890d-215">You can use any instance size that is supported by HPC Pack.</span></span> <span data-ttu-id="4890d-216">Podporuje RDMA instance jsou však doporučováno pro spouštění poměrně rozsáhlé úlohy MPI, které jsou citlivá na latenci a šířku pásma sítě, která se připojuje uzly.</span><span class="sxs-lookup"><span data-stu-id="4890d-216">However, the RDMA-capable instances are recommended for running relatively large-scale MPI jobs that are sensitive to the latency and the bandwidth of the network that connects the nodes.</span></span> <span data-ttu-id="4890d-217">Pokud používáte jiné velikosti pro spouštění úloh MPI citlivý na latenci a šířky pásma, doporučujeme spustit malé přenosy, ve kterých běží jeden úkol na pouze několik uzlů.</span><span class="sxs-lookup"><span data-stu-id="4890d-217">If you use other sizes to run latency- and bandwidth-sensitive MPI jobs, we recommend running small jobs, in which a single task runs on only a few nodes.</span></span>
* <span data-ttu-id="4890d-218">Aplikace nasazené do instancemi Azure se vztahují licenční podmínky, které jsou přidružené k aplikaci.</span><span class="sxs-lookup"><span data-stu-id="4890d-218">Applications deployed to Azure instances are subject to the licensing terms associated with the application.</span></span> <span data-ttu-id="4890d-219">Zkontrolujte s dodavateli komerčních aplikací se vždy pro licencování a dalších omezení při spouštění v cloudu.</span><span class="sxs-lookup"><span data-stu-id="4890d-219">Check with the vendor of any commercial application for licensing or other restrictions for running in the cloud.</span></span> <span data-ttu-id="4890d-220">Ne všichni dodavatelé nabízejí licencování formou průběžných plateb.</span><span class="sxs-lookup"><span data-stu-id="4890d-220">Not all vendors offer pay-as-you-go licensing.</span></span>
* <span data-ttu-id="4890d-221">Azure instancí potřebovat další instalační program přístup k místní uzlů, sdílených složek a licenčních serverů.</span><span class="sxs-lookup"><span data-stu-id="4890d-221">Azure instances need further setup to access on-premises nodes, shares, and license servers.</span></span> <span data-ttu-id="4890d-222">Například pokud chcete povolit uzlů Azure pro přístup licenčnímu serveru místní, můžete nakonfigurovat virtuální síť Azure site-to-site.</span><span class="sxs-lookup"><span data-stu-id="4890d-222">For example, to enable the Azure nodes to access an on-premises license server, you can configure a site-to-site Azure virtual network.</span></span>
* <span data-ttu-id="4890d-223">Ke spouštění aplikací MPI s instancemi Azure, zaregistrovat každou aplikaci MPI s bránou Windows Firewall v instancích spuštěním **hpcfwutil** příkaz.</span><span class="sxs-lookup"><span data-stu-id="4890d-223">To run MPI applications on Azure instances, register each MPI application with Windows Firewall on the instances by running the **hpcfwutil** command.</span></span> <span data-ttu-id="4890d-224">To umožňuje komunikaci MPI proběhla na portu, který se přiřadí dynamicky bránou firewall.</span><span class="sxs-lookup"><span data-stu-id="4890d-224">This allows MPI communications to take place on a port that is assigned dynamically by the firewall.</span></span>
  
  > [!NOTE]
  > <span data-ttu-id="4890d-225">Pro shluků Azure nasazení můžete také nakonfigurovat příkaz výjimky brány firewall na automatické spuštění na všechny nové uzly Azure, které jsou přidány do clusteru.</span><span class="sxs-lookup"><span data-stu-id="4890d-225">For burst to Azure deployments, you can also configure a firewall exception command to run automatically on all new Azure nodes that are added to your cluster.</span></span> <span data-ttu-id="4890d-226">Po spuštění **hpcfwutil** příkazů a ověřte, že vaše aplikace funguje, přidejte příkaz do spouštěcí skript pro Azure uzly.</span><span class="sxs-lookup"><span data-stu-id="4890d-226">After you run the **hpcfwutil** command and verify that your application works, add the command to a startup script for your Azure nodes.</span></span> <span data-ttu-id="4890d-227">Další informace najdete v tématu [pomocí spouštěcího skriptu pro Azure uzly](https://technet.microsoft.com/library/jj899632.aspx).</span><span class="sxs-lookup"><span data-stu-id="4890d-227">For more information, see [Use a Startup Script for Azure Nodes](https://technet.microsoft.com/library/jj899632.aspx).</span></span>
  > 
  > 
* <span data-ttu-id="4890d-228">HPC Pack používá proměnnou prostředí clusteru CCP_MPI_NETMASK zadat rozsah adres přijatelné pro MPI komunikaci.</span><span class="sxs-lookup"><span data-stu-id="4890d-228">HPC Pack uses the CCP_MPI_NETMASK cluster environment variable to specify a range of acceptable addresses for MPI communication.</span></span> <span data-ttu-id="4890d-229">Spouštění v prostředí HPC Pack 2012 R2, proměnné prostředí clusteru CCP_MPI_NETMASK ovlivňuje pouze MPI komunikace mezi výpočetní uzly clusteru připojené k doméně (místně nebo ve virtuálních počítačích Azure).</span><span class="sxs-lookup"><span data-stu-id="4890d-229">Starting in HPC Pack 2012 R2, the CCP_MPI_NETMASK cluster environment variable only affects MPI communication between domain-joined cluster compute nodes (either on-premises or in Azure VMs).</span></span> <span data-ttu-id="4890d-230">Proměnná je ignorován v uzlech přidat v shluku do konfigurace služby Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-230">The variable is ignored by nodes added in a burst to Azure configuration.</span></span>
* <span data-ttu-id="4890d-231">Úloh MPI nelze spustit napříč instancemi Azure, které jsou nasazeny v různých cloudové služby (například v shluků na jiný uzel šablony nebo virtuálního počítače Azure výpočetní uzly nasazené v několika cloudových služeb Azure nasazení).</span><span class="sxs-lookup"><span data-stu-id="4890d-231">MPI jobs can't run across Azure instances that are deployed in different cloud services (for example, in burst to Azure deployments with different node templates, or Azure VM compute nodes deployed in multiple cloud services).</span></span> <span data-ttu-id="4890d-232">Pokud máte více nasazení Azure uzlu zahájených šablonami jiného uzlu, úlohy MPI musíte spustit na jen jednu sadu uzlů Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-232">If you have multiple Azure node deployments that are started with different node templates, the MPI job must run on only one set of Azure nodes.</span></span>
* <span data-ttu-id="4890d-233">Při přidání uzlů Azure do clusteru a jejich převedení do online režimu, služba Plánovač úloh HPC okamžitě se pokusí spustit úlohy na uzlech.</span><span class="sxs-lookup"><span data-stu-id="4890d-233">When you add Azure nodes to your cluster and bring them online, the HPC Job Scheduler Service immediately tries to start jobs on the nodes.</span></span> <span data-ttu-id="4890d-234">Pokud jenom část úlohu můžete spustit v Azure, ujistěte se, aktualizovat nebo vytvoření šablony úloh můžete definovat, jaké typy úloh můžete spustit v Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-234">If only a portion of your workload can run on Azure, ensure that you update or create job templates to define what job types can run on Azure.</span></span> <span data-ttu-id="4890d-235">Aby se zajistilo, že úlohy, odeslané s šablonu úlohy spustit jen u uzlů Azure, například přidání vlastnost uzlu skupiny do šablony úlohy a vyberte AzureNodes jako požadovaná hodnota.</span><span class="sxs-lookup"><span data-stu-id="4890d-235">For example, to ensure that jobs submitted with a job template only run on Azure nodes, add the Node Groups property to the job template and select AzureNodes as the required value.</span></span> <span data-ttu-id="4890d-236">Pokud chcete vytvořit vlastní skupiny pro Azure uzly, použijte rutinu Add-HpcGroup prostředí HPC PowerShell.</span><span class="sxs-lookup"><span data-stu-id="4890d-236">To create custom groups for your Azure nodes, use the Add-HpcGroup HPC PowerShell cmdlet.</span></span>

## <a name="next-steps"></a><span data-ttu-id="4890d-237">Další kroky</span><span class="sxs-lookup"><span data-stu-id="4890d-237">Next steps</span></span>
* <span data-ttu-id="4890d-238">Jako alternativu k použití HPC Pack vývoj pomocí služby Azure Batch ke spouštění aplikací MPI na spravovaný fond výpočetních uzlů v Azure.</span><span class="sxs-lookup"><span data-stu-id="4890d-238">As an alternative to using HPC Pack, develop with the Azure Batch service to run MPI applications on managed pools of compute nodes in Azure.</span></span> <span data-ttu-id="4890d-239">V tématu [pomocí úkolů s více instancemi ke spouštění aplikací rozhraní MPI (Message Passing) ve službě Azure Batch](../../../batch/batch-mpi.md).</span><span class="sxs-lookup"><span data-stu-id="4890d-239">See [Use multi-instance tasks to run Message Passing Interface (MPI) applications in Azure Batch](../../../batch/batch-mpi.md).</span></span>
* <span data-ttu-id="4890d-240">Pokud chcete spouštět aplikace, které přístup k síti Azure RDMA najdete v tématu Linux MPI [nastavení clusteru s podporou Linux RDMA ke spuštění aplikací MPI](../../linux/classic/rdma-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="4890d-240">If you want to run Linux MPI applications that access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

<!--Image references-->
[burst]:media/hpcpack-rdma-cluster/burst.png
[iaas]:media/hpcpack-rdma-cluster/iaas.png
[pingpong1]:media/hpcpack-rdma-cluster/pingpong1.png
[pingpong2]:media/hpcpack-rdma-cluster/pingpong2.png
